{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"UNI-D\u00b2","text":"<p>Discrete diffusion models operate in discrete state spaces (tokens, labels, programs, etc.) by scheduling noise and denoising transitions with carefully designed transition kernels instead of continuous Gaussian noise. </p> <p>This repository centralizes tooling, datasets, experiments, and evaluation pipelines so researchers have a reliable, extendible codebase for discrete diffusion variants in text and structured domains.</p>"},{"location":"#highlights","title":"Highlights","text":"<ul> <li>Unified Entry Point: Hydra + Lightning workflow for experimenting with MDLM, UDLM, BD3LM, FlexMDM, GIDD, SEDD, PartitionMDLM, and CANDI.</li> <li>Comprehensive Sampling: Helpers for absorbing, autoregressive, block, and flexible sampling strategies.</li> <li>Reproducibility: Scripts to reproduce training recipes for datasets like LM1B, OpenWebText, and Text8.</li> </ul>"},{"location":"#papers-implemented","title":"Papers Implemented","text":"<ol> <li>MDLM \u2013 Sahoo et al. (NeurIPS 2024)</li> <li>UDLM \u2013 Schiff et al. (arXiv 2024)</li> <li>FlexMDM \u2013 Kim et al. (arXiv 2025)</li> <li>Block Diffusion \u2013 Arriola et al. (arXiv 2025)</li> <li>GIDD \u2013 von R\u00fctte et al. (arXiv 2025)</li> <li>SEDD \u2013 Lou et al. (arXiv 2023)</li> <li>PartitionMDLM \u2013 Deschenaux et al. (arXiv 2025)</li> <li>CANDI \u2013 Pynadath et al. (arXiv 2025)</li> <li>EB-Sampler \u2013 Ben-Hamu et al. (arXiv 2025)</li> </ol>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install -e .\n</code></pre> <p>For systems with Flash Attention (CUDA 11.4+), install it after the editable install to boost throughput:</p> <pre><code>pip install flash-attn --no-build-isolation\n</code></pre> <p>For optimized cross-entropy computation on CUDA devices:</p> <pre><code>pip install liger-kernel\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#1-training","title":"1. Training","text":"<p>Run the Hydra-powered CLI. Here is a minimal example for training MDLM on OpenWebText:</p> <pre><code>PYTHONPATH=src python -u -m discrete_diffusion \\\n  data=owt \\\n  model=small \\\n  algo=mdlm \\\n  loader.batch_size=32 \\\n  trainer.devices=8 \\\n  hydra.run.dir=./outputs/owt/mdlm\n</code></pre>"},{"location":"#2-sampling","title":"2. Sampling","text":"<p>Once you have a checkpoint, use the generation script:</p> <pre><code>PYTHONPATH=src python -m discrete_diffusion.evaluations.generate_samples \\\n  checkpoint_path=outputs/owt/mdlm/checkpoints/last.ckpt \\\n  num_samples=16 \\\n  num_steps=2000\n</code></pre>"},{"location":"#extending","title":"Extending","text":"<p>Want to implement a new discrete diffusion method? Check out our Extension Guides to learn how to add custom algorithms, forward processes, noise schedules, and models.</p>"},{"location":"architecture/","title":"Architecture Guide","text":"<p>This guide explains the core components of the UNI-D\u00b2 library.</p>"},{"location":"architecture/#overview","title":"Overview","text":"<p>The library follows a modular design where Algorithms coordinate training and inference by combining interchangeable components. A LightningModule (Algorithm) orchestrates the interaction between components and defines the specific loss computation logic, connecting the Forward Process (noise), Noise Schedule (timing), Backbone Model (denoising), and Sampler (generation).</p>"},{"location":"architecture/#key-abstractions","title":"Key Abstractions","text":""},{"location":"architecture/#algorithms","title":"Algorithms","text":"<p>Algorithms (e.g., <code>AbsorbingState</code>, <code>Uniform</code>) are LightningModules that manage the training loop, optimization, and metric logging. They bind the forward process, noise schedule, and backbone model together to define the specific diffusion logic and loss computation.</p>"},{"location":"architecture/#forward-processes","title":"Forward Processes","text":"<p>The <code>ForwardProcess</code> abstraction applies noise to data to produce latent states $x_t$ given $x_0$. It defines the transition distribution $q(x_t|x_0)$, handling masking or corruption strategies independent of the training loop.</p>"},{"location":"architecture/#noise-schedules","title":"Noise Schedules","text":"<p><code>NoiseSchedule</code> defines the continuous-time dynamics of the diffusion process, providing attenuation factors $\\alpha(t)$ and derivatives $\\alpha'(t)$. It controls the rate of information destruction, supporting various schedules like cosine, linear, or geometric.</p>"},{"location":"architecture/#models","title":"Models","text":"<p>Models (e.g., <code>DIT</code>) are the neural network backbones responsible for predicting $x_0$ or scores from noisy inputs $x_t$ and time embeddings. They are agnostic to the specific diffusion algorithm and simply map noisy states and noise levels to denoised predictions.</p>"},{"location":"architecture/#samplers","title":"Samplers","text":"<p>Samplers define the reverse diffusion process, converting the model's predictions into a sequence of generated tokens. They implement strategies like posterior computation to iteratively refine random noise back into coherent data.</p>"},{"location":"contributing/","title":"Contributing to UNI-D\u00b2","text":"<p>Thank you for your interest in contributing! We aim to build a standard OSS library for discrete diffusion. Please keep code minimal, clean, and concise.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>Clone the repository and install the package in editable mode:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository and create your branch from <code>main</code>.</li> <li>If you add a new feature, you must add corresponding documentation.</li> <li>Submit a Pull Request with a clear description of your changes.</li> </ol>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>We use MkDocs with Material for MkDocs for documentation.</p> <p>To build the documentation locally:</p> <ol> <li> <p>Install documentation dependencies:    <pre><code>pip install -e \".[dev]\"\n</code></pre></p> </li> <li> <p>Serve the documentation:    <pre><code>mkdocs serve\n</code></pre></p> </li> </ol> <p>This will start a local server at <code>http://127.0.0.1:8000/</code> where you can preview changes.</p> <ol> <li>To build the static site:    <pre><code>mkdocs build\n</code></pre></li> </ol>"},{"location":"examples/bd3lm/","title":"Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models","text":"<p>Reference: arXiv:2503.09573</p> <p>Block Diffusion interpolates between discrete denoising diffusion and autoregressive models to support flexible-length generation and improve inference efficiency. It uses a block-based approach with KV caching and parallel token sampling, setting a new state-of-the-art among diffusion models on language modeling benchmarks.</p>"},{"location":"examples/bd3lm/#usage","title":"Usage","text":"<p>Train on OpenWebText:</p> <pre><code>bash examples/bd3lm/owt.sh\n</code></pre>"},{"location":"examples/bd3lm/#citation","title":"Citation","text":"<pre><code>@misc{arriola2025block,\n      title={Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models}, \n      author={Marianne Arriola and Aaron Gokaslan and Justin T. Chiu and Zhihan Yang and Zhixuan Qi and Jiaqi Han and Subham Sekhar Sahoo and Volodymyr Kuleshov},\n      year={2025},\n      eprint={2503.09573},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n</code></pre>"},{"location":"examples/candi/","title":"CANDI: Hybrid Discrete-Continuous Diffusion Models","text":"<p>Reference: arXiv:2510.22510</p> <p>CANDI addresses a fundamental limitation of continuous diffusion on discrete data by introducing \"token identifiability\" as an analytical lens. The method identifies two corruption mechanisms\u2014discrete identity corruption and continuous rank degradation\u2014that scale differently with vocabulary size, creating temporal dissonance. CANDI decouples discrete and continuous corruption processes, enabling simultaneous learning of both conditional structure and continuous geometry.</p>"},{"location":"examples/candi/#usage","title":"Usage","text":"<p>Train on OpenWebText:</p> <pre><code>bash examples/candi/owt.sh\n</code></pre>"},{"location":"examples/candi/#key-configuration","title":"Key Configuration","text":"Parameter Default Description <code>noise.r_min</code> 0.05 Minimum rank percentile for noise schedule <code>noise.r_max</code> 0.25 Maximum rank percentile for noise schedule <code>model.mixed_coeff</code> 0.5 Coefficient for biasing between mask/substitution <code>model.length</code> 1024 Sequence length <code>optim.lr</code> 3e-4 Learning rate <code>lr_scheduler</code> constant_warmup LR scheduler with warmup"},{"location":"examples/candi/#citation","title":"Citation","text":"<pre><code>@misc{pynadath2025candi,\n      title={CANDI: Hybrid Discrete-Continuous Diffusion Models},\n      author={Patrick Pynadath and Jiaxin Shi and Ruqi Zhang},\n      year={2025},\n      eprint={2510.22510},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n</code></pre>"},{"location":"examples/flexmdm/","title":"FlexMDM: Any-Order Flexible Length Masked Diffusion","text":"<p>Reference: arXiv:2509.01025</p> <p>FlexMDM extends masked diffusion models to support flexible-length generation while retaining any-order inference capabilities. By inserting mask tokens and unmasking them using a stochastic interpolant framework, it models length statistics with high fidelity and achieves superior performance on tasks like math and code infilling compared to fixed-length baselines.</p>"},{"location":"examples/flexmdm/#usage","title":"Usage","text":"<p>Train on OpenWebText:</p> <pre><code>bash examples/flexmdm/owt.sh\n</code></pre>"},{"location":"examples/flexmdm/#citation","title":"Citation","text":"<pre><code>@misc{kim2025anyorder,\n      title={Any-Order Flexible Length Masked Diffusion}, \n      author={Jaeyeon Kim and Lee Cheuk-Kit and Carles Domingo-Enrich and Yilun Du and Sham Kakade and Timothy Ngotiaoco and Sitan Chen and Michael Albergo},\n      year={2025},\n      eprint={2509.01025},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n</code></pre>"},{"location":"examples/gidd/","title":"Generalized Interpolating Discrete Diffusion (GIDD)","text":"<p>Reference: arXiv:2503.04482</p> <p>GIDD generalizes masked diffusion by deriving a new family of interpolating discrete diffusion processes that offer greater flexibility in designing noising processes. By leveraging a novel diffusion ELBO and combining masking with uniform noise, it enables the model to correct its own mistakes and improves sample quality.</p>"},{"location":"examples/gidd/#usage","title":"Usage","text":"<p>Train on OpenWebText:</p> <pre><code>bash examples/gidd/owt.sh\n</code></pre>"},{"location":"examples/gidd/#citation","title":"Citation","text":"<pre><code>@misc{rutte2025generalized,\n      title={Generalized Interpolating Discrete Diffusion}, \n      author={Dimitri von R\u00fctte and Janis Fluri and Yuhui Ding and Antonio Orvieto and Bernhard Sch\u00f6lkopf and Thomas Hofmann},\n      year={2025},\n      eprint={2503.04482},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n</code></pre>"},{"location":"examples/mdlm/","title":"MDLM: Simple and Effective Masked Diffusion Language Models","text":"<p>Reference: arXiv:2406.07524</p> <p>MDLM simplifies masked diffusion for language modeling by removing complex reparameterizations. It uses a standard forward process that independently masks tokens and a reverse process that directly predicts the unmasked tokens. This approach achieves state-of-the-art perplexity among diffusion models, competitive with autoregressive baselines.</p>"},{"location":"examples/mdlm/#usage","title":"Usage","text":"<p>Train on OpenWebText:</p> <pre><code>bash examples/mdlm/owt.sh\n</code></pre>"},{"location":"examples/mdlm/#citation","title":"Citation","text":"<pre><code>@misc{sahoo2024simple,\n      title={Simple and Effective Masked Diffusion Language Models}, \n      author={Subham Sekhar Sahoo and Marianne Arriola and Yair Schiff and Aaron Gokaslan and Edgar Marroquin and Justin T Chiu and Alexander Rush and Volodymyr Kuleshov},\n      year={2024},\n      eprint={2406.07524},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n</code></pre>"},{"location":"examples/pgm/","title":"PGM: Partition Generative Modeling","text":"<p>Reference: arXiv:2505.18883</p> <p>PGM combines the strengths of autoregressive and masked generative models by partitioning tokens into two groups and using sparse attention to block information flow between them. This allows the model to process previously generated tokens only during sampling while retaining parallel and any-order generation capabilities, leading to significant improvements in sampling latency and throughput.</p>"},{"location":"examples/pgm/#usage","title":"Usage","text":"<p>Train on OpenWebText:</p> <pre><code>bash examples/pgm/owt.sh\n</code></pre>"},{"location":"examples/pgm/#citation","title":"Citation","text":"<pre><code>@misc{deschenaux2025partition,\n      title={Partition Generative Modeling: Masked Modeling Without Masks}, \n      author={Justin Deschenaux and Lan Tran and Caglar Gulcehre},\n      year={2025},\n      eprint={2505.18883},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n</code></pre>"},{"location":"examples/sedd/","title":"SEDD: Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution","text":"<p>Reference: arXiv:2310.16834</p> <p>SEDD bridges the gap between score matching and discrete data by proposing score entropy, a novel loss that extends score principles to discrete spaces. This method allowed discrete diffusion models to beat existing paradigms and compete with autoregressive models.</p>"},{"location":"examples/sedd/#usage","title":"Usage","text":"<p>Train on OpenWebText:</p> <pre><code>bash examples/sedd/owt.sh\n</code></pre>"},{"location":"examples/sedd/#citation","title":"Citation","text":"<pre><code>@misc{lou2023discrete,\n      title={Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution}, \n      author={Aaron Lou and Chenlin Meng and Stefano Ermon},\n      year={2023},\n      eprint={2310.16834},\n      archivePrefix={arXiv},\n      primaryClass={stat.ML}\n}\n</code></pre>"},{"location":"examples/udlm/","title":"UDLM: Uniform Discrete Diffusion Language Model","text":"<p>Reference: arXiv:2412.10193</p> <p>UDLM uses uniform noise corruption with a novel continuous-time variational lower bound, enabling state-of-the-art performance among uniform noising methods. The forward process corrupts tokens towards a uniform distribution, and the model learns to reverse this process by minimizing a continuous-time ELBO.</p>"},{"location":"examples/udlm/#usage","title":"Usage","text":"<p>Train on text8:</p> <pre><code>bash examples/udlm/text8.sh\n</code></pre>"},{"location":"examples/udlm/#citation","title":"Citation","text":"<pre><code>@misc{schiff2024uniform,\n      title={Uniform Discrete Diffusion Language Model}, \n      author={Yair Schiff and others},\n      year={2024},\n      eprint={2412.10193},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}\n</code></pre>"},{"location":"extension_guides/","title":"Extension Guides","text":"<p>Complete guides for extending the discrete diffusion library with custom components.</p>"},{"location":"extension_guides/#available-guides","title":"Available Guides","text":""},{"location":"extension_guides/#core-components","title":"Core Components","text":"<ol> <li> <p>Custom Algorithm: Implement a new discrete diffusion method</p> <ul> <li>Inherit from base classes</li> <li>Override key methods</li> <li>Register and configure</li> </ul> </li> <li> <p>Custom Forward Process: Create custom noise patterns</p> <ul> <li>Implement forward diffusion $q(x_t|x_0)$</li> <li>Integrate with noise schedules</li> <li>Support custom sampling</li> </ul> </li> <li> <p>Custom Noise Schedule: Define custom time-dependent noise</p> <ul> <li>Implement $\\alpha(t)$ and $\\alpha'(t)$</li> <li>Handle boundary conditions</li> <li>Integrate with algorithms</li> </ul> </li> <li> <p>Custom Model: Add new backbone architectures</p> <ul> <li>Define model interface</li> <li>Support time conditioning</li> <li>Register and configure</li> </ul> </li> </ol>"},{"location":"extension_guides/#next-steps","title":"Next Steps","text":"<p>Choose the guide for the component you want to extend and follow along with the complete example. All guides assume you're working from the repository root.</p>"},{"location":"extension_guides/01_custom_algorithm/","title":"Guide: Implementing a Custom Algorithm","text":"<p>This guide explains how to create a new discrete diffusion algorithm by subclassing the library's base classes.</p>"},{"location":"extension_guides/01_custom_algorithm/#overview","title":"Overview","text":"<p>Algorithms in this library are LightningModules that orchestrate the training loop. They compose: - A Backbone Model (predicts denoising) - A Noise Schedule (defines $\\alpha_t$) - A Forward Process (defines $q(x_t | x_0)$) - A Sampler (generates samples)</p> <p>To add a custom algorithm, you typically need to: 1. Subclass <code>TrainerBase</code>, <code>Diffusion</code>, or <code>AbsorbingState</code> 2. Implement the loss computation logic (<code>nll_per_token</code>) 3. Implement output processing (<code>_process_model_output</code>) 4. Create a Hydra configuration file</p>"},{"location":"extension_guides/01_custom_algorithm/#step-1-choose-a-base-class","title":"Step 1: Choose a Base Class","text":"<ul> <li><code>TrainerBase</code>: Minimal wrapper around PyTorch Lightning. Use for non-diffusion methods (like AR).</li> <li><code>Diffusion</code>: Adds continuous-time diffusion logic (<code>_sample_t</code>, <code>compute_posterior</code>). Use for general diffusion.</li> <li><code>AbsorbingState</code>: Specializes <code>Diffusion</code> for masking-based methods. Handles mask token management.</li> </ul>"},{"location":"extension_guides/01_custom_algorithm/#step-2-implement-the-algorithm","title":"Step 2: Implement the Algorithm","text":"<p>Create a new file <code>src/discrete_diffusion/algorithms/my_custom_algo.py</code>.</p> <pre><code>import torch\nimport torch.nn.functional as F\nfrom discrete_diffusion.algorithms.base import AbsorbingState\n\nclass MyCustomAlgo(AbsorbingState):\n    \"\"\"\n    A custom discrete diffusion algorithm that implements a specific\n    loss weighting or parameterization.\n    \"\"\"\n\n    def __init__(self, config, tokenizer):\n        # Initialize base class (sets up model, noise, forward_process)\n        super().__init__(config, tokenizer)\n\n        # Add custom hyperparameters\n        self.custom_lambda = config.algo.get('lambda', 1.0)\n        self._validate_configuration()\n\n    def _validate_configuration(self):\n        super()._validate_configuration()\n        # Ensure compatible components\n        assert self.config.algo.parameterization == 'subs'\n\n    def _process_model_output(self, model_output, xt, sigma):\n        \"\"\"\n        Convert raw model logits into log-probabilities.\n\n        Args:\n            model_output: [batch, seq_len, vocab_size]\n            xt: [batch, seq_len]\n            sigma: [batch]\n        \"\"\"\n        # 1. Mask out invalid tokens (like the mask token itself if desired)\n        model_output[:, :, self.mask_id] = self.neg_infinity\n\n        # 2. Compute log_softmax\n        log_probs = model_output.log_softmax(dim=-1)\n\n        # 3. Enforce absorbing state constraint:\n        #    If xt is NOT masked, probability mass must be concentrated on xt\n        unmasked = (xt != self.mask_id)\n        log_probs[unmasked] = self.neg_infinity\n        log_probs[unmasked, xt[unmasked]] = 0.0\n\n        return log_probs\n\n    def nll_per_token(self, log_x_theta, xt, x0, alpha_t, dalpha_t, low_var=False):\n        \"\"\"\n        Compute the per-token negative log-likelihood (loss).\n\n        Args:\n            log_x_theta: Log probabilities from model [batch, seq_len, vocab]\n            xt: Noisy input tokens [batch, seq_len]\n            x0: Target clean tokens [batch, seq_len]\n            alpha_t: Signal retention [batch, 1]\n            dalpha_t: Derivative of alpha_t [batch, 1]\n            low_var: Boolean flag for low-variance loss\n        \"\"\"\n        # 1. Select log-prob of the ground truth token\n        #    log_x_theta shape: [B, L, V] -&gt; gather -&gt; [B, L]\n        log_p_theta = torch.gather(\n            log_x_theta, \n            dim=-1, \n            index=x0.unsqueeze(-1)\n        ).squeeze(-1)\n\n        # 2. Compute Weighting\n        if low_var:\n            # Simple cross-entropy\n            weight = -1.0 \n        else:\n            # Continuous-time diffusion weighting: alpha'(t) / (1 - alpha(t))\n            # Note: dalpha_t is usually negative\n            weight = dalpha_t / (1.0 - alpha_t + 1e-8)\n\n        # 3. Apply custom logic (e.g., importance sampling, curriculum)\n        loss = weight * log_p_theta * self.custom_lambda\n\n        return loss\n</code></pre>"},{"location":"extension_guides/01_custom_algorithm/#step-3-create-configuration","title":"Step 3: Create Configuration","text":"<p>Add a Hydra config file in <code>configs/algo/my_custom_algo.yaml</code>.</p> <p>The <code>_target_</code> field tells Hydra which class to instantiate.</p> <pre><code># configs/algo/my_custom_algo.yaml\ndefaults:\n  - /forward_process: absorbing\n  - /noise_schedule: log_linear\n\n# FULL CLASSPATH is critical here:\n_target_: discrete_diffusion.algorithms.my_custom_algo.MyCustomAlgo\n\nname: my_custom_algo\nbackbone: dit\nparameterization: subs\ntime_conditioning: false\n\n# Custom parameters\nlambda: 1.5\n</code></pre>"},{"location":"extension_guides/01_custom_algorithm/#step-4-run-training","title":"Step 4: Run Training","text":"<p>You can now run your algorithm by specifying the <code>algo</code> config group:</p> <pre><code>python -m discrete_diffusion \\\n    algo=my_custom_algo \\\n    data=text8 \\\n    model=small \\\n    trainer.max_steps=1000\n</code></pre>"},{"location":"extension_guides/01_custom_algorithm/#key-methods-to-override","title":"Key Methods to Override","text":"Method Purpose <code>__init__</code> Custom setup. Always call <code>super().__init__</code>. <code>_process_model_output</code> Required. Transform raw logits to valid log-probs. <code>nll_per_token</code> Required. Define the loss function. <code>generate_samples</code> Optional. Implement custom sampling if the generic sampler isn't sufficient."},{"location":"extension_guides/01_custom_algorithm/#common-pitfalls","title":"Common Pitfalls","text":"<ol> <li>Vocab Size: <code>AbsorbingState</code> may add a mask token. Ensure your model handles <code>vocab_size + 1</code>.</li> <li>NaN Losses: Check <code>nll_per_token</code> denominators (<code>1 - alpha_t</code>).</li> <li>Hydra Target: Ensure <code>_target_</code> path matches your directory structure exactly.</li> </ol>"},{"location":"extension_guides/02_custom_forward_process/","title":"Guide: Implementing a Custom Forward Process","text":"<p>This guide explains how to create a custom Forward Process. The forward process defines how clean data $x_0$ is corrupted into noisy data $x_t$ during training.</p>"},{"location":"extension_guides/02_custom_forward_process/#overview","title":"Overview","text":"<p>The forward process $q(x_t | x_0)$ operates on token sequences. It takes a clean batch of tokens and a batch of timesteps, and applies noise according to a Noise Schedule.</p> <p>Common processes include: - Absorbing: Replace tokens with <code>[MASK]</code>. - Uniform: Replace tokens with random vocabulary items. - SEDD: Score-Entropy Discrete Diffusion noise.</p>"},{"location":"extension_guides/02_custom_forward_process/#step-1-create-the-class","title":"Step 1: Create the Class","text":"<p>Create a new file <code>src/discrete_diffusion/forward_process/dropout_noise.py</code>. Subclass <code>ForwardProcess</code>.</p> <pre><code>import torch\nfrom discrete_diffusion.forward_process.base import ForwardProcess\nfrom discrete_diffusion.noise_schedules.base import NoiseSchedule\nfrom discrete_diffusion.forward_process.utils import _mask_token_id\n\nclass DropoutForwardProcess(ForwardProcess):\n    \"\"\"\n    A custom forward process that acts like dropout:\n    Tokens are replaced with a special token (or mask) with probability (1 - alpha_t).\n    \"\"\"\n\n    def __init__(self, tokenizer, schedule: NoiseSchedule):\n        super().__init__(tokenizer, schedule)\n        # You can define a custom noise token, or reuse the mask token\n        self.noise_token_id = _mask_token_id(tokenizer)\n\n    @torch.no_grad()\n    def forward(self, input_ids: torch.Tensor, t: torch.Tensor):\n        \"\"\"\n        Apply noise to input_ids based on timestep t.\n\n        Args:\n            input_ids: Clean token IDs [batch, seq_len]\n            t: Timesteps [batch] in [0, 1]\n\n        Returns:\n            noised_ids: [batch, seq_len]\n            (Optional) metadata: You can return extra info if your algorithm needs it\n        \"\"\"\n        # 1. Get signal retention probability alpha_t\n        #    Shape: [batch, 1]\n        alpha_t = self.schedule.alpha_t(t).view(-1, 1)\n\n        # 2. Determine noise probability\n        p_noise = 1.0 - alpha_t\n\n        # 3. Sample mask: 1 where we should add noise\n        #    Use float comparison for probability\n        rand_vals = torch.rand_like(input_ids, dtype=torch.float32)\n        noise_mask = rand_vals &lt; p_noise\n\n        # 4. Apply noise\n        #    Where mask is True, replace with noise_token_id\n        noised_ids = torch.where(\n            noise_mask,\n            torch.tensor(self.noise_token_id, device=input_ids.device),\n            input_ids\n        )\n\n        return noised_ids\n</code></pre>"},{"location":"extension_guides/02_custom_forward_process/#step-2-register-the-process","title":"Step 2: Register the Process","text":"<p>Open <code>src/discrete_diffusion/forward_process/registry.py</code> and add your new class to the builder.</p> <pre><code># src/discrete_diffusion/forward_process/registry.py\nfrom .dropout_noise import DropoutForwardProcess  # Import your class\n\ndef build_forward_process(config, tokenizer, schedule):\n    # ... existing code ...\n\n    name = config.algo.forward_process.name\n\n    if name == 'dropout':\n        return DropoutForwardProcess(tokenizer, schedule)\n\n    # ... existing code ...\n</code></pre>"},{"location":"extension_guides/02_custom_forward_process/#step-3-configure","title":"Step 3: Configure","text":"<p>Update your algorithm config to use the new process.</p> <pre><code># configs/algo/my_custom_algo.yaml\n\nforward_process:\n  name: dropout\n</code></pre>"},{"location":"extension_guides/02_custom_forward_process/#advanced-block-wise-or-structured-noise","title":"Advanced: Block-Wise or Structured Noise","text":"<p>If your process is more complex (e.g., masking contiguous blocks), you can implement that logic in <code>forward</code>.</p> <p>For example, <code>BlockAbsorbingForwardProcess</code> returns additional metadata (like per-token timesteps). If you do this, ensure your Algorithm and Sampler are designed to handle the extra return values.</p> <pre><code>    def forward(self, input_ids, t):\n        # ... complex logic ...\n        return xt, mask_prob, per_token_t\n</code></pre>"},{"location":"extension_guides/03_custom_noise_schedule/","title":"Guide: Implementing a Custom Noise Schedule","text":"<p>This guide explains how to define a custom Noise Schedule. The noise schedule determines the rate at which information is destroyed during the forward process.</p>"},{"location":"extension_guides/03_custom_noise_schedule/#overview","title":"Overview","text":"<p>A noise schedule provides two key functions of time $t \\in [0, 1]$: 1. $\\alpha(t)$: The signal retention probability.    - $\\alpha(0) = 1$ (Clean data)    - $\\alpha(1) \\approx 0$ (Pure noise) 2. $\\alpha'(t)$: The time derivative $\\frac{d\\alpha}{dt}$.    - Used for weighting the training loss in continuous-time diffusion.</p>"},{"location":"extension_guides/03_custom_noise_schedule/#step-1-create-the-class","title":"Step 1: Create the Class","text":"<p>Create a new file <code>src/discrete_diffusion/noise_schedules/polynomial.py</code>. Subclass <code>NoiseSchedule</code>.</p> <pre><code>import torch\nfrom discrete_diffusion.noise_schedules.base import NoiseSchedule\n\nclass PolynomialNoiseSchedule(NoiseSchedule):\n    \"\"\"\n    A polynomial decay schedule:\n    alpha(t) = (1 - t)^power\n\n    We add a small epsilon to prevent numerical instability at t=1.\n    \"\"\"\n\n    def __init__(self, power: float = 2.0, eps: float = 1e-3):\n        super().__init__()\n        self.power = float(power)\n        self.eps = float(eps)\n\n    def alpha_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute alpha(t).\n\n        Formula: alpha(t) = (1 - t)^p * (1 - eps) + eps\n        This ensures alpha(0)=1 and alpha(1)=eps.\n        \"\"\"\n        # Ensure t is in [0, 1] if needed, though usually handled by caller\n        term = (1 - t).pow(self.power)\n        return term * (1 - self.eps) + self.eps\n\n    def alpha_prime_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute d/dt alpha(t).\n\n        d/dt [ (1-t)^p * (1-eps) + eps ]\n        = (1-eps) * p * (1-t)^(p-1) * (-1)\n        = -p * (1-eps) * (1-t)^(p-1)\n        \"\"\"\n        coeff = -self.power * (1 - self.eps)\n        term = (1 - t).pow(self.power - 1)\n        return coeff * term\n</code></pre>"},{"location":"extension_guides/03_custom_noise_schedule/#step-2-register-the-schedule","title":"Step 2: Register the Schedule","text":"<p>Open <code>src/discrete_diffusion/noise_schedules/registry.py</code> and add your new class.</p> <pre><code># src/discrete_diffusion/noise_schedules/registry.py\nfrom .polynomial import PolynomialNoiseSchedule\n\ndef build_noise_schedule(config, tokenizer=None):\n    # ... existing code ...\n\n    name = config.algo.noise_schedule.name\n    params = config.algo.noise_schedule\n\n    if name == 'polynomial':\n        return PolynomialNoiseSchedule(\n            power=params.get('power', 2.0),\n            eps=params.get('eps', 1e-3)\n        )\n\n    # ... existing code ...\n</code></pre>"},{"location":"extension_guides/03_custom_noise_schedule/#step-3-configure","title":"Step 3: Configure","text":"<p>Update your config to use the new schedule.</p> <pre><code># configs/algo/my_custom_algo.yaml\n\nnoise_schedule:\n  name: polynomial\n  power: 3.0\n  eps: 1e-4\n</code></pre>"},{"location":"extension_guides/04_custom_model/","title":"Guide: Implementing a Custom Model (Backbone)","text":"<p>This guide explains how to add a new neural network architecture (backbone) to the library.</p>"},{"location":"extension_guides/04_custom_model/#overview","title":"Overview","text":"<p>The backbone model predicts the denoising distribution. It takes the noisy tokens $x_t$ and the noise level $\\sigma_t$ (or time $t$) as input, and outputs logits over the vocabulary.</p>"},{"location":"extension_guides/04_custom_model/#step-1-define-the-interface","title":"Step 1: Define the Interface","text":"<p>Your model class must implement the following <code>forward</code> signature:</p> <pre><code>def forward(self, x_t: torch.Tensor, sigma: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Args:\n        x_t: [batch, seq_len] LongTensor of token IDs\n        sigma: [batch] FloatTensor of noise levels (or None if not time-conditioned)\n\n    Returns:\n        logits: [batch, seq_len, vocab_size] FloatTensor\n    \"\"\"\n</code></pre>"},{"location":"extension_guides/04_custom_model/#step-2-implement-the-model","title":"Step 2: Implement the Model","text":"<p>Create a new file <code>src/discrete_diffusion/models/my_transformer.py</code>.</p> <pre><code>import torch\nimport torch.nn as nn\n\nclass MyTransformer(nn.Module):\n    def __init__(self, config, vocab_size: int):\n        super().__init__()\n        self.config = config\n        dim = config.model.hidden_size\n\n        # 1. Embeddings\n        self.token_emb = nn.Embedding(vocab_size, dim)\n        self.pos_emb = nn.Parameter(torch.randn(1, config.model.length, dim))\n\n        # 2. Time Conditioning (Optional)\n        self.time_conditioning = config.algo.time_conditioning\n        if self.time_conditioning:\n            self.time_mlp = nn.Sequential(\n                nn.Linear(1, dim),\n                nn.SiLU(),\n                nn.Linear(dim, dim)\n            )\n\n        # 3. Main Body (e.g., PyTorch Transformer)\n        layer = nn.TransformerEncoderLayer(\n            d_model=dim, \n            nhead=config.model.n_heads,\n            dim_feedforward=dim * 4,\n            dropout=config.model.dropout,\n            batch_first=True\n        )\n        self.encoder = nn.TransformerEncoder(layer, num_layers=config.model.n_blocks)\n\n        # 4. Output Projection\n        self.head = nn.Linear(dim, vocab_size)\n\n        # 5. Weight Tying (Optional but recommended)\n        if config.model.get('tie_word_embeddings', False):\n            self.head.weight = self.token_emb.weight\n\n    def forward(self, x_t, sigma):\n        # Embed tokens\n        x = self.token_emb(x_t) + self.pos_emb[:, :x_t.size(1), :]\n\n        # Inject time info\n        if self.time_conditioning and sigma is not None:\n            # Project sigma to embedding dimension\n            t_emb = self.time_mlp(sigma.view(-1, 1)) # [B, D]\n            x = x + t_emb.unsqueeze(1) # Add to all tokens\n\n        # Process\n        x = self.encoder(x)\n\n        # Project to logits\n        logits = self.head(x)\n        return logits\n</code></pre>"},{"location":"extension_guides/04_custom_model/#step-3-register-the-model","title":"Step 3: Register the Model","text":"<p>Open <code>src/discrete_diffusion/models/registry.py</code> and add your builder function.</p> <pre><code># src/discrete_diffusion/models/registry.py\nfrom .my_transformer import MyTransformer\n\ndef _build_my_transformer(config, vocab_size):\n    return MyTransformer(config, vocab_size)\n\n_BACKBONE_BUILDERS = {\n    # ...\n    'my-transformer': _build_my_transformer,\n}\n</code></pre>"},{"location":"extension_guides/04_custom_model/#step-4-configure","title":"Step 4: Configure","text":"<p>Update your config to use the new backbone name.</p> <pre><code># configs/algo/my_algo.yaml\nbackbone: my-transformer\n\n# configs/model/small.yaml\nhidden_size: 512\nn_heads: 8\nn_blocks: 6\ndropout: 0.1\nlength: 1024\ntie_word_embeddings: true\n</code></pre>"},{"location":"extension_guides/04_custom_model/#advanced-blockpartition-inputs","title":"Advanced: Block/Partition Inputs","text":"<p>If your algorithm (like BD3LM) uses block indices, your model signature needs to accept them:</p> <pre><code>def forward(self, x_t, group_idxs, sigma):\n    # ... use group_idxs for block-wise attention ...\n</code></pre> <p>Ensure you update the registry builder to pass <code>config</code> appropriately if your model needs to know about blocking strategies.</p>"},{"location":"reference/algorithms/ar/","title":"Autoregressive","text":""},{"location":"reference/algorithms/ar/#discrete_diffusion.algorithms.ar","title":"<code>discrete_diffusion.algorithms.ar</code>","text":"<p>AR algorithm implementation extracted from :mod:<code>algorithms.algo</code>.</p>"},{"location":"reference/algorithms/base/","title":"Algorithms Base","text":""},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base","title":"<code>discrete_diffusion.algorithms.base</code>","text":""},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.AbsorbingState","title":"<code>AbsorbingState</code>","text":"<p>               Bases: <code>Diffusion</code></p> <p>Base class for absorbing state diffusion models (e.g. MDLM).</p> <p>Handles mask token management and forward process instantiation for masking-based methods.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>class AbsorbingState(Diffusion):\n  \"\"\"Base class for absorbing state diffusion models (e.g. MDLM).\n\n  Handles mask token management and forward process instantiation for\n  masking-based methods.\n  \"\"\"\n  def __init__(self, config, tokenizer):\n    # NOTE: Ideally, we should do \n    # vocab_size = len(tokenizer), so that we account\n    # for the special tokens added in data/loaders.py.\n    # But we use tokenizer.vocab_size so as to to be\n    # consistent with the prior checkpoints.\n    self.mask_id, vocab_size = ensure_mask_token(tokenizer)\n    super().__init__(config, tokenizer, vocab_size=vocab_size)\n    self.save_hyperparameters()\n\n    # Instantiate forward process using Hydra\n    fp_cfg = getattr(self.config.algo, 'forward_process', None)\n    if fp_cfg is None or not hasattr(fp_cfg, '_target_'):\n      raise ValueError(\n        \"Forward process must be configured with '_target_' field. \"\n        \"Example: forward_process._target_=discrete_diffusion.forward_process.AbsorbingForwardProcess\"\n      )\n    fp_config = omegaconf.OmegaConf.create(fp_cfg)\n    self._forward_process = hydra.utils.instantiate(\n      fp_config,\n      tokenizer=self.tokenizer,\n      schedule=self.noise,\n      _recursive_=False\n    )\n\n  def _validate_configuration(self):\n    super()._validate_configuration()\n    if self.parameterization in {'score', 'mean'}:\n      assert self.time_conditioning\n    assert not (self.parameterization == 'mean' and self.T == 0)\n    if self.T &gt; 0:\n      assert self.parameterization in {'mean', 'subs'}\n\n  def q_xt(self, x, t):\n    \"\"\"Computes the noisy sample xt by delegating to the configured forward process.\n\n    Args:\n        x: Clean input tokens [batch, length].\n        t: Time values [batch] or float.\n\n    Returns:\n        Tensor: Noisy tokens xt.\n    \"\"\"\n    if not isinstance(t, torch.Tensor):\n      t = torch.as_tensor(t, device=x.device, dtype=torch.float32)\n    elif t.device != x.device:\n      t = t.to(device=x.device)\n    out = self._forward_process(x, t)\n    xt = out[0] if isinstance(out, (tuple, list)) else out\n    if self.ignore_bos:\n      xt[:, 0] = x[:, 0]\n    return xt\n\n  def prior_sample(self, *batch_dims):\n    size = batch_dims[0] if len(batch_dims) == 1 and isinstance(batch_dims[0], (tuple, list)) else batch_dims\n    return torch.full(tuple(size), self.mask_id, dtype=torch.int64, device=self.device)\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.AbsorbingState.q_xt","title":"<code>q_xt(x, t)</code>","text":"<p>Computes the noisy sample xt by delegating to the configured forward process.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Clean input tokens [batch, length].</p> required <code>t</code> <p>Time values [batch] or float.</p> required <p>Returns:</p> Name Type Description <code>Tensor</code> <p>Noisy tokens xt.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>def q_xt(self, x, t):\n  \"\"\"Computes the noisy sample xt by delegating to the configured forward process.\n\n  Args:\n      x: Clean input tokens [batch, length].\n      t: Time values [batch] or float.\n\n  Returns:\n      Tensor: Noisy tokens xt.\n  \"\"\"\n  if not isinstance(t, torch.Tensor):\n    t = torch.as_tensor(t, device=x.device, dtype=torch.float32)\n  elif t.device != x.device:\n    t = t.to(device=x.device)\n  out = self._forward_process(x, t)\n  xt = out[0] if isinstance(out, (tuple, list)) else out\n  if self.ignore_bos:\n    xt[:, 0] = x[:, 0]\n  return xt\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.Diffusion","title":"<code>Diffusion</code>","text":"<p>               Bases: <code>TrainerBase</code></p> <p>Base class for diffusion-based algorithms.</p> <p>Implements continuous-time diffusion logic including time sampling, sigma processing, and generic NLL computation.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>class Diffusion(TrainerBase):\n  \"\"\"Base class for diffusion-based algorithms.\n\n  Implements continuous-time diffusion logic including time sampling,\n  sigma processing, and generic NLL computation.\n  \"\"\"\n  def _validate_configuration(self):\n    super()._validate_configuration()\n    assert self.loss_type in {'elbo', 'low_var'}\n\n  def _process_model_input(self, x0, valid_tokens):\n    return x0, valid_tokens\n\n  def nll(self, x0,\n          current_accumulation_step=None, train_mode=False):\n    \"\"\"Implements diffusion-style NLL evaluation.\"\"\"\n    t = self._sample_t(x0.shape[0], current_accumulation_step)\n    assert t.shape[0] == x0.shape[0]\n    if self.T &gt; 0:\n      t = (t * self.T).to(torch.int)\n      t = t / self.T\n      t += (1 / self.T)\n\n    alpha_t = self.noise.alpha_t(t)\n    dalpha_t = self.noise.alpha_prime_t(t)\n    alpha_t = alpha_t.unsqueeze(-1)\n    dalpha_t = dalpha_t.unsqueeze(-1)\n    assert alpha_t.ndim == 2\n    sigma = self._sigma_from_alphat(alpha_t)\n\n    xt = self.q_xt(x0, t)\n    # Optional next-token shift: align logits[..., :-1, :] with targets[..., 1:]\n    if getattr(self, 'shift_loss_targets', False):\n      # MD4-style: compute CE on raw logits, mask to xt==mask, weight by dalpha/(1-alpha).\n      # 1) Get raw logits from backbone (bypass post-processing)\n      raw_logits = self.backbone(xt, sigma)\n      # 2) Apply next-token shift to align logits and targets, also shift xt\n      raw_logits, x0, xt = utils.shift_for_next_token(raw_logits, x0, xt)\n      # 3) Per-token CE (use log_softmax to avoid adding new imports)\n      ce = - raw_logits.log_softmax(-1).gather(-1, x0.unsqueeze(-1)).squeeze(-1)\n      # 4) Mask to only count positions where xt was masked\n      mask_positions = (xt == self.mask_id).to(ce.dtype)\n      masked_neg_ce = mask_positions * (-ce)\n      # 5) Weight by alpha_prime / (1 - alpha)\n      weighting = dalpha_t / (1 - alpha_t)\n      while weighting.dim() &lt; masked_neg_ce.dim():\n        weighting = weighting.unsqueeze(-1)\n      return weighting * masked_neg_ce\n    else:\n      log_x_theta = self.forward(xt, sigma=sigma)\n      return self.nll_per_token(\n        log_x_theta=log_x_theta,\n        xt=xt,\n        x0=x0,\n        alpha_t=alpha_t,\n        dalpha_t=dalpha_t,\n        low_var=train_mode and self.loss_type == 'low_var')\n\n  def _process_sigma(self, sigma):\n    assert sigma.ndim == 2\n    sigma = sigma.mean(-1).squeeze()\n    if sigma.ndim == 0:\n      sigma = sigma.unsqueeze(0)\n    if not self.time_conditioning:\n      sigma = torch.zeros_like(sigma)\n    assert sigma.ndim == 1, sigma.shape\n    return sigma\n\n  def _sample_t(self, n, accum_step):\n    if accum_step is not None:\n      # During training\n      batch_dim = n\n      n = self.config.loader.global_batch_size\n    _eps_t = torch.rand(n, device=self.device)\n    if self.antithetic_sampling:\n      offset = torch.arange(n, device=self.device) / n\n      _eps_t = (_eps_t / n + offset) % 1\n    t = (1 - self.sampling_eps) * _eps_t + self.sampling_eps\n    if accum_step is not None:\n      t = t.chunk(self.trainer.num_nodes)[self.trainer.node_rank]\n      t = t.chunk(self.trainer.num_devices)[self.trainer.local_rank]\n      t = t.chunk(self.trainer.accumulate_grad_batches)[\n        accum_step]\n      # corner case for the last datapoint\n      t = t[:batch_dim]\n    return t\n\n  def _sigma_from_alphat(self, alpha_t):\n    return -torch.log(alpha_t)\n\n  def _reconstruction_loss(self, x0):\n    t0 = torch.zeros(1, x0.shape[0], dtype=self.dtype, device=self.device)\n    sigma_t0 = self._sigma_from_alphat(self.noise.alpha_t(t0))\n    model_output_t0 = self.forward(x0, sigma_t0)\n    return -torch.gather(input=model_output_t0, dim=-1, index=x0[:, :, None]).squeeze(-1)\n\n  def nll_per_token(self, model_output, xt, x0, alpha_t, dalpha_t, low_var):\n    \"\"\"Compute per-token negative log likelihood.\n\n    Args:\n        model_output: Model predictions (logits or scores).\n        xt: Noisy input tokens.\n        x0: Target clean tokens.\n        alpha_t: Signal schedule value at time t.\n        dalpha_t: Derivative of alpha_t at time t.\n        low_var: Whether to use low-variance loss formulation.\n\n    Returns:\n        Tensor: Per-token NLL.\n    \"\"\"\n    raise NotImplementedError\n\n  def _get_score(self, x, sigma, group_idxs=None):\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.Diffusion.nll","title":"<code>nll(x0, current_accumulation_step=None, train_mode=False)</code>","text":"<p>Implements diffusion-style NLL evaluation.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>def nll(self, x0,\n        current_accumulation_step=None, train_mode=False):\n  \"\"\"Implements diffusion-style NLL evaluation.\"\"\"\n  t = self._sample_t(x0.shape[0], current_accumulation_step)\n  assert t.shape[0] == x0.shape[0]\n  if self.T &gt; 0:\n    t = (t * self.T).to(torch.int)\n    t = t / self.T\n    t += (1 / self.T)\n\n  alpha_t = self.noise.alpha_t(t)\n  dalpha_t = self.noise.alpha_prime_t(t)\n  alpha_t = alpha_t.unsqueeze(-1)\n  dalpha_t = dalpha_t.unsqueeze(-1)\n  assert alpha_t.ndim == 2\n  sigma = self._sigma_from_alphat(alpha_t)\n\n  xt = self.q_xt(x0, t)\n  # Optional next-token shift: align logits[..., :-1, :] with targets[..., 1:]\n  if getattr(self, 'shift_loss_targets', False):\n    # MD4-style: compute CE on raw logits, mask to xt==mask, weight by dalpha/(1-alpha).\n    # 1) Get raw logits from backbone (bypass post-processing)\n    raw_logits = self.backbone(xt, sigma)\n    # 2) Apply next-token shift to align logits and targets, also shift xt\n    raw_logits, x0, xt = utils.shift_for_next_token(raw_logits, x0, xt)\n    # 3) Per-token CE (use log_softmax to avoid adding new imports)\n    ce = - raw_logits.log_softmax(-1).gather(-1, x0.unsqueeze(-1)).squeeze(-1)\n    # 4) Mask to only count positions where xt was masked\n    mask_positions = (xt == self.mask_id).to(ce.dtype)\n    masked_neg_ce = mask_positions * (-ce)\n    # 5) Weight by alpha_prime / (1 - alpha)\n    weighting = dalpha_t / (1 - alpha_t)\n    while weighting.dim() &lt; masked_neg_ce.dim():\n      weighting = weighting.unsqueeze(-1)\n    return weighting * masked_neg_ce\n  else:\n    log_x_theta = self.forward(xt, sigma=sigma)\n    return self.nll_per_token(\n      log_x_theta=log_x_theta,\n      xt=xt,\n      x0=x0,\n      alpha_t=alpha_t,\n      dalpha_t=dalpha_t,\n      low_var=train_mode and self.loss_type == 'low_var')\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.Diffusion.nll_per_token","title":"<code>nll_per_token(model_output, xt, x0, alpha_t, dalpha_t, low_var)</code>","text":"<p>Compute per-token negative log likelihood.</p> <p>Parameters:</p> Name Type Description Default <code>model_output</code> <p>Model predictions (logits or scores).</p> required <code>xt</code> <p>Noisy input tokens.</p> required <code>x0</code> <p>Target clean tokens.</p> required <code>alpha_t</code> <p>Signal schedule value at time t.</p> required <code>dalpha_t</code> <p>Derivative of alpha_t at time t.</p> required <code>low_var</code> <p>Whether to use low-variance loss formulation.</p> required <p>Returns:</p> Name Type Description <code>Tensor</code> <p>Per-token NLL.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>def nll_per_token(self, model_output, xt, x0, alpha_t, dalpha_t, low_var):\n  \"\"\"Compute per-token negative log likelihood.\n\n  Args:\n      model_output: Model predictions (logits or scores).\n      xt: Noisy input tokens.\n      x0: Target clean tokens.\n      alpha_t: Signal schedule value at time t.\n      dalpha_t: Derivative of alpha_t at time t.\n      low_var: Whether to use low-variance loss formulation.\n\n  Returns:\n      Tensor: Per-token NLL.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.TrainerBase","title":"<code>TrainerBase</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>Base Trainer class for discrete diffusion models.</p> <p>Handles initialization of backbone, noise schedule, and sampler, as well as Lightning hooks for training and validation loops.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>class TrainerBase(L.LightningModule):\n  \"\"\"Base Trainer class for discrete diffusion models.\n\n  Handles initialization of backbone, noise schedule, and sampler, as well as\n  Lightning hooks for training and validation loops.\n  \"\"\"\n  def __init__(self, config, tokenizer: transformers.PreTrainedTokenizer, vocab_size=None):\n    super().__init__()\n    self.save_hyperparameters()\n    self.config = config\n    self.ignore_bos = getattr(self.config.algo, 'ignore_bos', False)\n    self.loss_type = getattr(self.config.algo, 'loss_type', None)\n    self.tokenizer = tokenizer\n    if vocab_size is None:\n      self.vocab_size = len(self.tokenizer)\n    else:\n      self.vocab_size = vocab_size\n    self.sampler = self.config.sampling.predictor\n    self.antithetic_sampling = self.config.training.antithetic_sampling\n    self.parameterization = self.config.algo.parameterization\n    self._sampler_cfg = self._resolve_sampler_config()\n    self._sampler = None\n\n    target = self.config.model._target_\n    instantiate_config = omegaconf.OmegaConf.create({'_target_': target})\n    self.backbone = hydra.utils.instantiate(\n      instantiate_config,\n      self.config,\n      self.vocab_size,\n      _recursive_=False\n    )\n    self.model = self.backbone\n\n    self.T = self.config.algo.T\n    self.num_tokens = self.config.model.length\n    self.softplus = torch.nn.Softplus()\n    self.p_nucleus = self.config.sampling.p_nucleus\n    # Noise schedule - use Hydra instantiation\n    # HybridDiffusion needs tokenizer passed at runtime\n    if hasattr(self.config.noise, '_target_') and 'HybridDiffusion' in self.config.noise._target_:\n      self.noise = hydra.utils.instantiate(self.config.noise, tokenizer=self.tokenizer)\n    else:\n      self.noise = hydra.utils.instantiate(self.config.noise)\n\n    self.metrics = Metrics()\n\n    self._prepare_ema()\n    self.lr = self.config.optim.lr\n    self.sampling_eps = self.config.training.sampling_eps\n    self.time_conditioning = self.config.algo.time_conditioning\n    if config.neg_infinity_mode == 'large-finite':\n      self.neg_infinity = -1000000.0\n    elif config.neg_infinity_mode == 'true-inf':\n      self.neg_infinity = -float('inf')\n    else:\n      raise ValueError(f\"neg_infinity_mode must be 'large-finite' or 'true-inf', got '{config.neg_infinity_mode}'\")\n    self.fast_forward_epochs = None\n    self.fast_forward_batches = None\n\n  def _prepare_ema(self):\n    if self.config.training.ema &gt; 0:\n      self.ema = create_ema(self._get_parameters(), decay=self.config.training.ema)\n    else:\n      self.ema = None\n\n  def _validate_configuration(self):\n    if self.config.algo.parameterization == 'ar':\n      assert not self.config.algo.time_conditioning\n      assert self.config.prior.type == 'none'\n\n    if self.parameterization in {'score', 'mean'}:\n      assert self.time_conditioning\n    if self.T &gt; 0:\n      assert self.parameterization != 'score'\n\n  def to(self, *args, **kwargs):\n    self = super().to(*args, **kwargs) \n    self.metrics.to(*args, **kwargs)\n    return self\n\n  def q_xt(self, x, t):\n    raise NotImplementedError\n\n  def _get_parameters(self):\n    return itertools.chain(self.backbone.parameters(), self.noise.parameters())\n\n  def _eval_mode(self):\n    if self.ema:\n      self.ema.store(self._get_parameters())\n      self.ema.copy_to(self._get_parameters())\n    self.backbone.eval()\n    self.noise.eval()\n\n  def _train_mode(self):\n    if self.ema:\n      self.ema.restore(self._get_parameters())\n    self.backbone.train()\n    self.noise.train()\n\n  def on_load_checkpoint(self, checkpoint):\n    if self.ema:\n      self.ema.load_state_dict(checkpoint['ema'])\n    # Copied from:\n    # https://github.com/Dao-AILab/flash-attention/blob/main/training/src/datamodules/language_modeling_hf.py#L41\n    self.fast_forward_epochs = checkpoint['loops'][\n      'fit_loop']['epoch_progress']['current']['completed']\n    self.fast_forward_batches = checkpoint['loops'][\n      'fit_loop']['epoch_loop.batch_progress'][\n        'current']['completed']\n\n  def on_save_checkpoint(self, checkpoint):\n    if self.ema:\n      checkpoint['ema'] = self.ema.state_dict()\n    # Copied from:\n    # https://github.com/Dao-AILab/flash-attention/blob/main/training/src/tasks/seq.py\n    # ['epoch_loop.batch_progress']['total']['completed']\n    # is 1 iteration behind, so we're using the optimizer's progress.\n    checkpoint['loops']['fit_loop'][\n      'epoch_loop.batch_progress']['total'][\n        'completed'] = checkpoint['loops']['fit_loop'][\n          'epoch_loop.automatic_optimization.optim_progress'][\n            'optimizer']['step']['total'][\n              'completed'] * self.trainer.accumulate_grad_batches\n    checkpoint['loops']['fit_loop'][\n      'epoch_loop.batch_progress']['current'][\n        'completed'] = checkpoint['loops']['fit_loop'][\n          'epoch_loop.automatic_optimization.optim_progress'][\n            'optimizer']['step']['current'][\n              'completed'] * self.trainer.accumulate_grad_batches\n    # _batches_that_stepped tracks the number of global steps,\n    # not the number of local steps, so we don't multiply with\n    # self.trainer.accumulate_grad_batches here.\n    checkpoint['loops']['fit_loop'][\n      'epoch_loop.state_dict'][\n        '_batches_that_stepped'] = checkpoint['loops']['fit_loop'][\n          'epoch_loop.automatic_optimization.optim_progress'][\n            'optimizer']['step']['total']['completed']\n\n  def on_train_start(self):\n    if self.ema:\n      self.ema.move_shadow_params_to_device(self.device)\n\n  def optimizer_step(self, *args, **kwargs):\n    super().optimizer_step(*args, **kwargs)\n    if self.ema: self.ema.update(self._get_parameters())\n\n  def _process_sigma(self, sigma):\n    raise NotImplementedError\n\n  def _process_model_output(self, model_output, xt, sigma):\n    \"\"\"Process raw model output into log-probabilities or scores.\n\n    Args:\n        model_output: Raw output from the backbone model.\n        xt: Noisy input tokens.\n        sigma: Noise level.\n\n    Returns:\n        Tensor: Processed output (e.g. log-probs).\n    \"\"\"\n    raise NotImplementedError\n\n  def forward(self, xt, sigma, group_idxs=None):\n    sigma = self._process_sigma(sigma)\n    with torch.amp.autocast('cuda', dtype=torch.float32):\n      if group_idxs is None:\n        model_output = self.backbone(xt, sigma)\n      else:\n        model_output = self.backbone(xt, group_idxs, sigma)\n    return self._process_model_output(model_output=model_output, xt=xt, sigma=sigma)\n\n  def _loss(self, x0, valid_tokens,\n            current_accumulation_step=None,\n            train_mode=False):\n    \"\"\"Generic loss aggregation for all trainer modules.\"\"\"\n    input_tokens, valid_tokens = self._process_model_input(x0, valid_tokens)\n    loss = self.nll(input_tokens, current_accumulation_step, train_mode)\n    assert loss.ndim == 2\n    if self.ignore_bos:\n      loss[:, 0] = 0\n      valid_tokens[:, 0] = 0\n    if (getattr(self, 'shift_loss_targets', False)\n        and valid_tokens.size(-1) == loss.size(-1) + 1):\n      valid_tokens = valid_tokens[:, 1:]\n\n    nlls = (loss * valid_tokens).sum()\n    num_tokens = valid_tokens.sum()\n    token_nll = nlls / num_tokens\n\n    return Loss(loss=token_nll,\n                nlls=nlls,\n                num_tokens=num_tokens)\n\n  def on_train_epoch_start(self):\n    self.metrics.reset()\n    assert self.metrics.train_nlls.nll.mean_value == 0\n    assert self.metrics.train_nlls.nll.weight == 0\n\n  def training_step(self, batch, batch_idx):\n    current_accumulation_step = (\n      batch_idx % self.trainer.accumulate_grad_batches)\n    losses = self._loss(batch['input_ids'], batch['attention_mask'], current_accumulation_step, train_mode=True)\n    self.metrics.update_train(losses.nlls, losses.num_tokens)\n    self.log(name='trainer/loss', value=losses.loss, on_step=True, on_epoch=False, sync_dist=True, prog_bar=True)\n    return losses.loss\n\n  def on_train_epoch_end(self):\n    train_metrics = {}\n    for k, v in self.metrics.train_nlls.items():\n      if getattr(v, 'weight', 0) &gt; 0:\n        train_metrics[k] = v.compute()\n    if train_metrics:\n      self.log_dict(train_metrics, on_step=False, on_epoch=True, sync_dist=True)\n    if hasattr(self.metrics, 'train_aux') and self.metrics.train_aux.weight &gt; 0:\n      self.log(name='train/aux', value=self.metrics.train_aux.compute(), on_step=False, on_epoch=True, sync_dist=True)\n\n  def on_validation_epoch_start(self):\n    self.metrics.reset()\n    self._eval_mode()\n    assert self.metrics.valid_nlls.nll.mean_value == 0\n    assert self.metrics.valid_nlls.nll.weight == 0\n\n  def validation_step(self, batch, batch_idx):\n    losses = self._loss(batch['input_ids'], batch['attention_mask'])\n    self.metrics.update_valid(losses.nlls, losses.num_tokens)\n    return losses.loss\n\n  def on_validation_epoch_end(self):\n    valid_metrics = {}\n    for k, v in self.metrics.valid_nlls.items():\n      if getattr(v, 'weight', 0) &gt; 0:\n        valid_metrics[k] = v.compute()\n    if valid_metrics:\n      self.log_dict(valid_metrics, on_step=False, on_epoch=True, sync_dist=True)\n    if hasattr(self.metrics, 'valid_aux') and self.metrics.valid_aux.weight &gt; 0:\n      self.log(name='val/aux', value=self.metrics.valid_aux.compute(), on_step=False, on_epoch=True, sync_dist=True)\n    if ((self.config.eval.compute_perplexity_on_sanity\n         or not self.trainer.sanity_checking)\n         and self.config.eval.generate_samples):\n      try:\n        samples, text_samples = None, None\n        for _ in range(\n          self.config.sampling.num_sample_batches):\n          samples = self.generate_samples(num_samples=self.config.loader.eval_batch_size)\n\n          self.metrics.record_entropy(samples)\n          # For logging and optional saving only\n          text_samples = self.tokenizer.batch_decode(samples)\n        if text_samples is not None:\n          if self.trainer.global_rank == 0 and hasattr(\n            self.trainer.logger, 'log_table'):\n            # Log the last generated samples\n            text_samples = text_samples[\n              : self.config.sampling.num_sample_log]\n            self.trainer.logger.log_table(\n              key=f'samples@global_step{self.global_step}',\n              columns=['Generated Samples'],\n              data=[[s] for s in text_samples])\n          # Always log sample entropy (cheap and useful)\n          self.log('val/sample_entropy', self.metrics.sample_entropy.compute(), on_epoch=True, on_step=False, sync_dist=True)\n\n          # Optionally save validation samples for later gen-PPL evaluation\n          if getattr(self.config.eval, 'save_validation_samples', False):\n            save_dir = Path(os.getcwd()) / 'validation_samples'\n            save_dir.mkdir(parents=True, exist_ok=True)\n            save_path = save_dir / f'step_{self.global_step}.pt'\n            torch.save(samples.detach().cpu(), save_path.as_posix())\n      except Exception as e:\n        print(f\"Sampling failed at step {self.global_step}: {e}\")\n    self._train_mode()\n\n  def configure_optimizers(self):\n    optimizer = torch.optim.AdamW(\n      self._get_parameters(),\n      lr=self.config.optim.lr,\n      betas=(self.config.optim.beta1,\n             self.config.optim.beta2),\n      eps=self.config.optim.eps,\n      weight_decay=self.config.optim.weight_decay)\n\n    scheduler = hydra.utils.instantiate(self.config.lr_scheduler, optimizer=optimizer)\n    scheduler_dict = {'scheduler': scheduler,\n                      'interval': 'step',\n                      'monitor': 'val/loss',\n                      'name': 'trainer/lr'}\n    return [optimizer], [scheduler_dict]\n\n  def _create_sampler(self):\n    \"\"\"Instantiate (and cache) the configured sampler.\"\"\"\n    if self._sampler is not None:\n      return self._sampler\n    sampler_cfg = self._sampler_cfg\n    if sampler_cfg is None:\n      return None\n    self._sampler = hydra.utils.instantiate(\n      sampler_cfg,\n      self.config,\n      forward_process=getattr(self, '_forward_process', None),\n      _recursive_=False,\n    )\n    return self._sampler\n\n  def _resolve_sampler_config(self):\n    \"\"\"Return the first sampler config specifying a Hydra target.\"\"\"\n    algo_sampler = getattr(self.config.algo, 'sampler', None)\n    if getattr(algo_sampler, '_target_', None):\n      return algo_sampler\n    sampling_sampler = getattr(self.config.sampling, 'sampler', None)\n    if getattr(sampling_sampler, '_target_', None):\n      return sampling_sampler\n    return None\n\n  @torch.no_grad()\n  def generate_samples(self, num_samples, num_steps=None, eps=None):\n    \"\"\"Generate samples from the model using the new sampler system.\n\n    Subclasses should not need to override this method if they have a \n    corresponding Sampler implementation registered in the sampling registry.\n    \"\"\"\n    if num_steps is None:\n      num_steps = self.config.sampling.steps\n    if eps is None:\n      eps = 1e-5\n    inject_bos = getattr(self.config.sampling, 'inject_bos', True)\n\n    sampler = self._create_sampler()\n    if sampler is None:\n      raise NotImplementedError(\n        f\"Algorithm {self.config.algo.name} does not have a configured sampler. \"\n        \"Set 'sampling.sampler._target_' or 'algo.sampler._target_' in the config \"\n        \"to select a Sampler, or override generate_samples().\")\n\n    return sampler.generate(model=self, num_samples=num_samples, num_steps=num_steps, eps=eps, inject_bos=inject_bos)\n\n  def _process_model_input(self, x0, valid_tokens):\n    raise NotImplementedError\n\n  def nll(self, input_tokens,\n          current_accumulation_step=None, train_mode=False):\n    \"\"\"Compute negative log likelihood for the given input tokens.\n\n    Args:\n        input_tokens: Input token indices.\n        current_accumulation_step: Current gradient accumulation step index.\n        train_mode: Whether the model is in training mode.\n\n    Returns:\n        Tensor: NLL loss.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.TrainerBase.generate_samples","title":"<code>generate_samples(num_samples, num_steps=None, eps=None)</code>","text":"<p>Generate samples from the model using the new sampler system.</p> <p>Subclasses should not need to override this method if they have a  corresponding Sampler implementation registered in the sampling registry.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>@torch.no_grad()\ndef generate_samples(self, num_samples, num_steps=None, eps=None):\n  \"\"\"Generate samples from the model using the new sampler system.\n\n  Subclasses should not need to override this method if they have a \n  corresponding Sampler implementation registered in the sampling registry.\n  \"\"\"\n  if num_steps is None:\n    num_steps = self.config.sampling.steps\n  if eps is None:\n    eps = 1e-5\n  inject_bos = getattr(self.config.sampling, 'inject_bos', True)\n\n  sampler = self._create_sampler()\n  if sampler is None:\n    raise NotImplementedError(\n      f\"Algorithm {self.config.algo.name} does not have a configured sampler. \"\n      \"Set 'sampling.sampler._target_' or 'algo.sampler._target_' in the config \"\n      \"to select a Sampler, or override generate_samples().\")\n\n  return sampler.generate(model=self, num_samples=num_samples, num_steps=num_steps, eps=eps, inject_bos=inject_bos)\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.TrainerBase.nll","title":"<code>nll(input_tokens, current_accumulation_step=None, train_mode=False)</code>","text":"<p>Compute negative log likelihood for the given input tokens.</p> <p>Parameters:</p> Name Type Description Default <code>input_tokens</code> <p>Input token indices.</p> required <code>current_accumulation_step</code> <p>Current gradient accumulation step index.</p> <code>None</code> <code>train_mode</code> <p>Whether the model is in training mode.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Tensor</code> <p>NLL loss.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>def nll(self, input_tokens,\n        current_accumulation_step=None, train_mode=False):\n  \"\"\"Compute negative log likelihood for the given input tokens.\n\n  Args:\n      input_tokens: Input token indices.\n      current_accumulation_step: Current gradient accumulation step index.\n      train_mode: Whether the model is in training mode.\n\n  Returns:\n      Tensor: NLL loss.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/algorithms/base/#discrete_diffusion.algorithms.base.ensure_mask_token","title":"<code>ensure_mask_token(tokenizer)</code>","text":"<p>Return mask token id and vocab size, ensuring the tokenizer exposes the mask.</p> Source code in <code>src/discrete_diffusion/algorithms/base.py</code> <pre><code>def ensure_mask_token(tokenizer):\n  \"\"\"Return mask token id and vocab size, ensuring the tokenizer exposes the mask.\"\"\"\n  vocab_size = _effective_vocab_size(tokenizer)\n  if getattr(tokenizer, 'mask_token', None) is None:\n    mask_id = vocab_size\n    vocab_size += 1\n  else:\n    mask_id = tokenizer.mask_token_id\n  if getattr(tokenizer, 'mask_token_id', None) is None:\n    setattr(tokenizer, 'mask_token_id', int(mask_id))\n  return int(mask_id), vocab_size\n</code></pre>"},{"location":"reference/algorithms/bd3lm/","title":"BD3LM","text":""},{"location":"reference/algorithms/bd3lm/#discrete_diffusion.algorithms.bd3lm","title":"<code>discrete_diffusion.algorithms.bd3lm</code>","text":"<p>Block Diffusion algorithm adapted from the BD3-LMs reference implementation.</p>"},{"location":"reference/algorithms/bd3lm/#discrete_diffusion.algorithms.bd3lm.BD3LM","title":"<code>BD3LM</code>","text":"<p>               Bases: <code>AbsorbingState</code></p> <p>Block-diffusion trainer mirroring BD3-LMs behaviour.</p> Source code in <code>src/discrete_diffusion/algorithms/bd3lm.py</code> <pre><code>class BD3LM(AbsorbingState):\n  \"\"\"Block-diffusion trainer mirroring BD3-LMs behaviour.\"\"\"\n\n  def __init__(self, config, tokenizer):\n    # BD3LM always uses 'subs' parameterization\n    from omegaconf import OmegaConf\n    OmegaConf.set_struct(config.algo, False)\n    config.algo.parameterization = 'subs'\n    OmegaConf.set_struct(config.algo, True)\n    super().__init__(config, tokenizer)\n    self.cross_attn = getattr(self.config.algo, 'cross_attn', False)\n    self.mdlm_loss_scale = getattr(self.config.algo, 'mdlm_loss_scale', False)\n    self.block_size = getattr(config, 'block_size', self.config.model.length)\n    self.var_min = getattr(self.config.algo, 'var_min', False)\n\n    # Override metrics with BD3LM variant\n    self.metrics = BD3Metrics(config)\n\n    # Validate noise schedule type (self.noise is set by TrainerBase)\n    from ..noise_schedules import LogLinear\n    if not isinstance(self.noise, LogLinear):\n      raise ValueError(\n        f'BD3LM requires LogLinear noise schedule, got {type(self.noise).__name__}'\n      )\n\n    # Compute sigma bounds once (for _sigma_from_p method)\n    self.sigma_max = -torch.log(self.noise.alpha_t(torch.tensor(1.0)))\n    self.sigma_min = torch.tensor(self.noise.eps, dtype=torch.float32)\n\n    if self.var_min:\n      self.register_buffer('sampling_eps_min', torch.tensor(\n        self.config.training.sampling_eps_min, dtype=torch.float32))\n      self.register_buffer('sampling_eps_max', torch.tensor(\n        self.config.training.sampling_eps_max, dtype=torch.float32))\n\n    self.time_conditioning = getattr(self.config.algo, 'time_conditioning', False)\n    self.fast_forward_epochs = None\n    self.fast_forward_batches = None\n\n  # -------------------------------------------------------------------------\n  # Noise schedule helper methods\n  # -------------------------------------------------------------------------\n  def _total_noise(self, t):\n    \"\"\"Compute sigma(t) = -log(alpha(t))\"\"\"\n    return -torch.log(self.noise.alpha_t(t))\n\n  def _rate_noise(self, t):\n    \"\"\"Compute dsigma/dt = -alpha'(t) / alpha(t)\"\"\"\n    alpha = self.noise.alpha_t(t)\n    alpha_prime = self.noise.alpha_prime_t(t)\n    return -alpha_prime / alpha\n\n  def _compute_loss_scaling_and_move_chance(self, t):\n    \"\"\"BD3LM loss scaling: -1/t, and move probability: t\"\"\"\n    return -1 / t, t\n\n  # -------------------------------------------------------------------------\n  # Lightning hooks\n  # -------------------------------------------------------------------------\n  def to(self, *args, **kwargs):\n    self = super().to(*args, **kwargs)\n    if hasattr(self.backbone, 'block_diff_mask'):\n      self.backbone.block_diff_mask = self.backbone.block_diff_mask.to(self.device)\n    return self\n\n  def on_train_epoch_start(self):\n    super().on_train_epoch_start()\n    self._train_mode()\n\n  def training_step(self, batch, batch_idx):\n    del batch_idx\n    losses = self._loss(batch['input_ids'], batch['attention_mask'])\n    self.metrics.train_nlls.update(losses.nlls, losses.token_mask)\n    self.log(name='trainer/loss',\n             value=losses.loss.item(),\n             on_step=True,\n             on_epoch=False,\n             sync_dist=True,\n             prog_bar=True)\n    return losses.loss\n\n  def on_validation_epoch_start(self):\n    super().on_validation_epoch_start()\n    if self.var_min:\n      self.sampling_eps = self.config.training.sampling_eps\n\n  def validation_step(self, batch, batch_idx):\n    del batch_idx\n\n    if self.var_min:\n      valid_loss = None\n      for noise_clip_start in self.metrics.valid_vars.keys():\n        sampling_eps_min, sampling_eps_max = noise_clip_start\n        losses_clip = self._loss(\n          batch['input_ids'],\n          batch['attention_mask'],\n          sampling_eps_min=sampling_eps_min,\n          sampling_eps_max=sampling_eps_max)\n        if self._check_val_sampling_intvl(sampling_eps_min, sampling_eps_max):\n          valid_loss = losses_clip\n        if len(self.metrics.valid_vars[noise_clip_start]) &lt; 100:\n          nlls = losses_clip.nlls\n          per_block = nlls.reshape(nlls.shape[0], -1, self.block_size).mean(-1)\n          self.metrics.valid_vars[noise_clip_start].append(per_block)\n      if valid_loss is not None:\n        self.metrics.valid_nlls.update(valid_loss.nlls, valid_loss.token_mask)\n      return valid_loss.loss if valid_loss is not None else losses_clip.loss\n    else:\n      losses = self._loss(\n        batch['input_ids'],\n        batch['attention_mask'],\n        sampling_eps_min=1e-3 if self.block_size &gt; 1 else 1,\n        sampling_eps_max=1 if self.block_size &gt; 1 else 1)\n      self.metrics.valid_nlls.update(losses.nlls, losses.token_mask)\n      return losses.loss\n\n  def on_validation_epoch_end(self):\n    if self.var_min and not self.trainer.sanity_checking:\n      self._clipped_schedule_search()\n    for k, v in self.metrics.valid_nlls.items():\n      self.log(name=k, value=v.compute(), on_step=False,\n               on_epoch=True, sync_dist=True)\n    self._train_mode()\n\n  def configure_optimizers(self):\n    return super().configure_optimizers()\n\n  # -------------------------------------------------------------------------\n  # Forward helpers\n  # -------------------------------------------------------------------------\n  def _subs_parameterization(self, logits, xt):\n    logits[:, :, self.mask_id] = self.neg_infinity\n    unmasked_indices = (xt != self.mask_id)\n    logits[unmasked_indices] = self.neg_infinity\n    logits[unmasked_indices, xt[unmasked_indices]] = 0.0\n    return logits\n\n  def forward(self, x, sigma, sample_mode=False, store_kv=False):\n    sigma = self._process_sigma(sigma)\n    with torch.amp.autocast('cuda', dtype=torch.float32):\n      logits = self.backbone(x, sigma,\n                             sample_mode=sample_mode,\n                             store_kv=store_kv)\n    if self.cross_attn:\n      x = x[:, :self.config.model.length]\n    return self._subs_parameterization(logits, xt=x)\n\n  # -------------------------------------------------------------------------\n  # Noise helpers\n  # -------------------------------------------------------------------------\n  def _sigma_from_p(self, p):\n    return torch.min(- torch.log(1 - p), self.sigma_max)\n\n  def _sample_t(self, batch_dims, device, sampling_eps_min, sampling_eps_max, block_size=None):\n    if block_size is None:\n      block_size = self.block_size\n    n = batch_dims[-1]\n    num_blocks = n // block_size\n    _eps_b = torch.rand((batch_dims[0], num_blocks), device=device)\n    if self.antithetic_sampling:\n      offset_b = torch.arange(batch_dims[0] * num_blocks, device=device) / (batch_dims[0] * num_blocks)\n      offset_b = offset_b.view(batch_dims[0], num_blocks)\n      _eps_b = (_eps_b / (batch_dims[0] * num_blocks) + offset_b) % 1\n    t = _eps_b\n    if block_size != self.config.model.length:\n      t = t.repeat_interleave(block_size, dim=-1)\n    if sampling_eps_max &gt;= 1 and sampling_eps_min &gt;= 1:\n      return torch.ones_like(t)\n    t = t * (sampling_eps_max - sampling_eps_min) + sampling_eps_min\n    return t\n\n  # -------------------------------------------------------------------------\n  # Forward diffusion helpers\n  # -------------------------------------------------------------------------\n  def _resample_q_xt(self, x, xt, move_indices, p, block_size, sampling_eps_min, sampling_eps_max):\n    perc_masked = (xt == self.mask_id).float().sum(-1) / block_size\n    while (perc_masked &lt; sampling_eps_min).any() or (perc_masked &gt; sampling_eps_max).any():\n      if sampling_eps_min == 1e-3 and sampling_eps_max != 1:\n        regen_idx = (perc_masked &gt; sampling_eps_max)\n        if regen_idx.max() == 0:\n          break\n      elif sampling_eps_min != 1e-3 and sampling_eps_max == 1:\n        regen_idx = (perc_masked &lt; sampling_eps_min)\n        if regen_idx.max() == 0:\n          break\n      else:\n        regen_idx = (perc_masked &lt; sampling_eps_min) | (perc_masked &gt; sampling_eps_max)\n      regen_idx = regen_idx.repeat_interleave(block_size, dim=-1)\n      move_indices[regen_idx] = (torch.rand(*x.shape, device=x.device) &lt; p)[regen_idx]\n      xt = torch.where(move_indices, self.mask_id, x)\n      xt = xt.reshape(xt.shape[0], -1, block_size)\n      perc_masked = (xt == self.mask_id).float().sum(-1) / block_size\n    return xt\n\n  def q_xt(self, x, p, block_size=None, sampling_eps_min=None, sampling_eps_max=None):\n    if block_size is None:\n      block_size = self.block_size\n    move_indices = torch.rand(*x.shape, device=x.device) &lt;= p\n    xt = torch.where(move_indices, self.mask_id, x)\n    if block_size == 1 and sampling_eps_min == 1.0:\n      return torch.full_like(x, self.mask_id)\n    if self.config.training.resample and not (sampling_eps_min == 1e-3 and sampling_eps_max == 1.0):\n      xt = xt.reshape(xt.shape[0], -1, block_size)\n      xt = self._resample_q_xt(x, xt, move_indices, p, block_size, sampling_eps_min, sampling_eps_max)\n      xt = xt.reshape(xt.shape[0], -1)\n    return xt\n\n  def _maybe_sub_sample(self, x0, attention_mask):\n    seqlen = x0.shape[1]\n    if seqlen &gt; self.num_tokens:\n      start = np.random.choice(self.num_tokens)\n      end = start + self.num_tokens\n      input_tokens = x0[:, start: end]\n      new_attention_mask = attention_mask[:, start: end]\n      insert_special = getattr(self.config.data, 'insert_train_special', False)\n      insert_eos = getattr(self.config.data, 'insert_train_eos', False)\n      if insert_special or insert_eos:\n        input_tokens[:, 0] = self.tokenizer.bos_token_id\n    else:\n      input_tokens = x0\n      new_attention_mask = attention_mask\n    return input_tokens, new_attention_mask\n\n  def _forward_pass_diffusion(self, x0, t=None, sampling_eps_min=None, sampling_eps_max=None):\n    if sampling_eps_min is None:\n      sampling_eps_min = 1e-3\n      sampling_eps_max = 1.0\n    if t is None:\n      t = self._sample_t(x0.shape, x0.device, sampling_eps_min, sampling_eps_max)\n    loss_scale, p = self._compute_loss_scaling_and_move_chance(t)\n    sigma = self._sigma_from_p(p[:, 0].unsqueeze(-1))\n    dsigma = - loss_scale * torch.expm1(sigma)\n    if self.mdlm_loss_scale:\n      sigma, dsigma = self._total_noise(t), self._rate_noise(t)\n      p = 1 - torch.exp(-sigma)\n      loss_scale = - (dsigma / torch.expm1(sigma))\n    xt = self.q_xt(x0, p, sampling_eps_min=sampling_eps_min, sampling_eps_max=sampling_eps_max)\n    if sampling_eps_min is not None and sampling_eps_min &gt; 0.5:\n      loss_scale = - torch.ones_like(loss_scale)\n    if self.config.algo.ignore_bos:\n      xt[:, 0] = x0[:, 0]\n    x_input = xt\n    if self.cross_attn:\n      x_input = torch.cat((xt, x0), dim=-1)\n    model_output = self.forward(x_input, sigma=sigma)\n    ce_loss = F.cross_entropy(\n        model_output.flatten(0, 1),\n        x0.flatten(0, 1),\n        reduction='none'\n    ).view_as(x0)\n    loss = -loss_scale * ce_loss\n    return loss\n\n  # -------------------------------------------------------------------------\n  # Loss computation\n  # -------------------------------------------------------------------------\n  def _loss(self, x0, attention_mask, t=None, sampling_eps_min=None, sampling_eps_max=None):\n    if sampling_eps_min is None and self.var_min:\n      sampling_eps_min = self.sampling_eps_min\n      sampling_eps_max = self.sampling_eps_max\n    elif sampling_eps_min is None:\n      sampling_eps_min = 1e-3\n      sampling_eps_max = 1.0\n\n    (input_tokens, attention_mask) = self._maybe_sub_sample(x0, attention_mask)\n    loss = self._forward_pass_diffusion(\n      input_tokens,\n      t=t,\n      sampling_eps_min=sampling_eps_min,\n      sampling_eps_max=sampling_eps_max)\n\n    if self.ignore_bos and not self.training:\n      attention_mask[:, 0] = 0\n\n    nlls = loss * attention_mask\n    token_nll = nlls.sum() / attention_mask.sum()\n    return Loss(loss=token_nll,\n                nlls=nlls,\n                token_mask=attention_mask)\n\n  # -------------------------------------------------------------------------\n  # Validation helpers\n  # -------------------------------------------------------------------------\n  def _clipped_schedule_search(self):\n    best_var = float('inf')\n    for (eps_min, eps_max), var in self.metrics.valid_vars.items():\n      all_vars = torch.tensor(0., device=self.device)\n      for value in var:\n        agg_var = value.to(self.device)\n        agg_var = self.all_gather(agg_var)\n        all_vars += agg_var.var()\n      if all_vars &lt; best_var:\n        best_var = all_vars\n        sampling_eps_min_best = eps_min\n        sampling_eps_max_best = eps_max\n      self.log(f'valid_var_{round(eps_min, 2)} - {round(eps_max, 2)}',\n               all_vars / max(len(var), 1),\n               on_epoch=True,\n               on_step=False,\n               sync_dist=True)\n    if getattr(self.config.algo, 'fix_clipping', False) is False:\n      self.sampling_eps_min.fill_(sampling_eps_min_best)\n      self.sampling_eps_max.fill_(sampling_eps_max_best)\n\n  def _check_val_sampling_intvl(self, sampling_eps_min, sampling_eps_max):\n    if (sampling_eps_min == 1e-3 and sampling_eps_max == 1\n        and not (self.block_size == 1 and self.config.training.eval_nll)):\n      return True\n    elif (self.block_size == 1 and sampling_eps_min &gt;= 1):\n      return True\n    return False\n</code></pre>"},{"location":"reference/algorithms/candi/","title":"CANDI","text":""},{"location":"reference/algorithms/candi/#discrete_diffusion.algorithms.candi","title":"<code>discrete_diffusion.algorithms.candi</code>","text":"<p>CANDI implementation from https://arxiv.org/abs/2510.22510</p>"},{"location":"reference/algorithms/candi/#discrete_diffusion.algorithms.candi.CANDI","title":"<code>CANDI</code>","text":"<p>               Bases: <code>Diffusion</code></p> Source code in <code>src/discrete_diffusion/algorithms/candi.py</code> <pre><code>class CANDI(Diffusion):\n    def __init__(self, config, tokenizer):\n        vocab_size = len(tokenizer) + 1\n        super().__init__(config, tokenizer, vocab_size=vocab_size)\n        self.noise = hydra.utils.instantiate(self.config.noise, vocab_size=vocab_size)\n        fp_cfg = getattr(self.config.algo, \"forward_process\", None)\n        fp_config = omegaconf.OmegaConf.create(fp_cfg)\n        self._forward_process = hydra.utils.instantiate(\n            fp_config, tokenizer=self.tokenizer, schedule=self.noise, _recursive_=False\n        )\n        self.temp = config.algo.get(\"temp\", 1.0)\n\n    def _validate_configuration(self):\n        assert \"candi\" in self._forward_process.name.lower()\n        assert \"candi\" in self.config.model.name \n        return super()._validate_configuration()\n\n    def _process_model_output(self, xt, model_output, reveal_mask): \n        if xt.ndim == 2: \n            xt_tokens = xt\n        else: \n            xt_tokens = xt.argmax(dim=-1)\n\n        model_output = model_output / self.temp\n        model_output = model_output - torch.logsumexp(\n            model_output, dim=-1, keepdim=True\n        )\n        reveal_mask = reveal_mask.bool()\n        model_output[reveal_mask] = self.neg_infinity\n        model_output[reveal_mask, xt_tokens[reveal_mask]] = 0\n        return model_output\n\n    def nll_per_token(self, log_x_theta, alpha_t, dalpha_t, x0_tokens, **kwargs): \n        \"\"\"Computes the negative log-likelihood per token as in Equation 13 of CANDI paper.\"\"\"\n        log_p_theta = torch.gather(\n            input=log_x_theta, dim=-1, index=x0_tokens[:, :, None]\n        ).squeeze(-1)\n        nll = log_p_theta * dalpha_t / (1 - alpha_t)\n        return nll\n\n    def nll(self, x0, current_accumulation_step=None, train_mode=False):\n        t = self._sample_t(x0.shape[0], current_accumulation_step)\n        alpha_t = self.noise.alpha_t(t)\n        alpha_t = alpha_t.unsqueeze(-1)\n        assert alpha_t.ndim == 2\n        assert t.shape[0] == x0.shape[0]\n\n        noisy_input = self._forward_process.forward(x0, t)\n        log_x_theta = self.forward(**noisy_input)\n        nll = self.nll_per_token(\n                log_x_theta=log_x_theta, \n                x0_tokens=x0,\n                **noisy_input,\n           )\n        return nll \n\n    def forward(self, **kwargs): \n        with torch.cuda.amp.autocast(dtype=torch.float32):\n            model_output = self.backbone(**kwargs)\n        return self._process_model_output(model_output=model_output, xt=kwargs['xt'], reveal_mask=kwargs['reveal_mask'])\n\n    def prior_sample(self, *batch_dims): \n        sigma = self.noise.sigma_t(torch.tensor(.999).to(self.device))\n        noise = torch.randn(\n            *batch_dims, self.vocab_size-1, dtype=torch.float32, device=self.device\n        )  * sigma\n        return noise\n</code></pre>"},{"location":"reference/algorithms/candi/#discrete_diffusion.algorithms.candi.CANDI.nll_per_token","title":"<code>nll_per_token(log_x_theta, alpha_t, dalpha_t, x0_tokens, **kwargs)</code>","text":"<p>Computes the negative log-likelihood per token as in Equation 13 of CANDI paper.</p> Source code in <code>src/discrete_diffusion/algorithms/candi.py</code> <pre><code>def nll_per_token(self, log_x_theta, alpha_t, dalpha_t, x0_tokens, **kwargs): \n    \"\"\"Computes the negative log-likelihood per token as in Equation 13 of CANDI paper.\"\"\"\n    log_p_theta = torch.gather(\n        input=log_x_theta, dim=-1, index=x0_tokens[:, :, None]\n    ).squeeze(-1)\n    nll = log_p_theta * dalpha_t / (1 - alpha_t)\n    return nll\n</code></pre>"},{"location":"reference/algorithms/flexmdm/","title":"FlexMDM","text":""},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder","title":"<code>discrete_diffusion.algorithms.flexmdm_anyorder</code>","text":"<p>FlexMDM Any-Order Algorithm Implementation.</p> <p>This module implements the FlexMDM any-order mask insertion flow algorithm, which jointly models insertion (length) and masking (content) processes.</p>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder","title":"<code>FlexMDMAnyOrder</code>","text":"<p>               Bases: <code>TrainerBase</code></p> <p>FlexMDM Any-Order Mask Insertion Flow algorithm.</p> <p>This algorithm uses a joint interpolant for variable-length discrete diffusion with both insertion (length) and masking (content) processes.</p> Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>class FlexMDMAnyOrder(TrainerBase):\n  \"\"\"FlexMDM Any-Order Mask Insertion Flow algorithm.\n\n  This algorithm uses a joint interpolant for variable-length discrete\n  diffusion with both insertion (length) and masking (content) processes.\n  \"\"\"\n\n  def __init__(self, config, tokenizer: transformers.PreTrainedTokenizer):\n    \"\"\"Initialize FlexMDM any-order algorithm.\n\n    Args:\n      config: Hydra config object\n      tokenizer: Tokenizer for the dataset\n    \"\"\"\n    # Ensure tokenizer has mask token\n    self.mask_id, vocab_size = ensure_mask_token(tokenizer)\n\n    # Set special tokens in config BEFORE calling super().__init__()\n    # so the model gets instantiated with correct token IDs\n    config.model.mask_token = self.mask_id\n    config.model.pad_token = tokenizer.pad_token_id\n\n    super().__init__(config, tokenizer, vocab_size=vocab_size)\n    self.save_hyperparameters()\n\n    # Get algorithm-specific config\n    algo_cfg = self.config.algo\n\n    # Loss function types\n    self.unmask_loss_fn = getattr(algo_cfg, 'unmask_loss_fn', 'elbo')\n    self.insert_loss_fn = getattr(algo_cfg, 'insert_loss_fn', 'expectation')\n\n    # Create insertion and unmasking schedules (default to linear)\n    insert_cfg = getattr(algo_cfg, 'insert_schedule', None)\n    unmask_cfg = getattr(algo_cfg, 'unmask_schedule', None)\n    self.insertion_schedule = build_flex_schedule(insert_cfg)\n    self.unmask_schedule = build_flex_schedule(unmask_cfg)\n\n    # Create interpolant\n    self.interpolant = FlexMDMForwardProcess(\n      insertion_schedule=self.insertion_schedule,\n      unmask_schedule=self.unmask_schedule,\n      tokenizer=self.tokenizer,\n      max_length=self.num_tokens,\n      pad_token=self.tokenizer.pad_token_id,\n    )\n\n    # Only embed insert time (not both insert and unmask)\n    self.only_embed_insert = getattr(algo_cfg, 'only_embed_insert', True)\n\n    self._validate_configuration()\n\n  def _validate_configuration(self):\n    \"\"\"Validate algorithm configuration.\"\"\"\n    assert self.unmask_loss_fn == 'elbo', (\n      f\"Only 'elbo' unmask loss supported, got {self.unmask_loss_fn}\"\n    )\n    assert self.insert_loss_fn in {'expectation', 'distribution'}, (\n      f\"Insert loss must be 'expectation' or 'distribution', \"\n      f\"got {self.insert_loss_fn}\"\n    )\n\n  @staticmethod\n  def _jump_kernel_elbo(x: torch.Tensor, y: torch.Tensor, eps: float = 1e-6):\n    \"\"\"Compute KL divergence for Poisson process (jump kernel ELBO).\n\n    This is the insertion loss for the length prediction.\n\n    Args:\n      x: True gap lengths [...]\n      y: Predicted gap lengths [...]\n      eps: Small constant for numerical stability\n\n    Returns:\n      KL divergence per position [...]\n    \"\"\"\n    x = x.float()\n    y = y.float()\n\n    x_safe = torch.clamp(x, min=eps)\n    y_safe = torch.clamp(y, min=eps)\n    return y_safe - x_safe + x_safe * (torch.log(x_safe) - torch.log(y_safe))\n\n  def sample_time(self, batch_size: int, device: torch.device) -&gt; torch.Tensor:\n    \"\"\"Sample time values with low-discrepancy sampling.\n\n    Args:\n      batch_size: Number of samples\n      device: Device for tensors\n\n    Returns:\n      Time values in [0, 1] [B]\n    \"\"\"\n    eps = 1e-6\n    interval = 1.0 - eps\n    interval_size = interval / batch_size\n    u = torch.rand(batch_size, device=device)\n    return (torch.arange(batch_size, device=device, dtype=u.dtype) + u\n            ) * interval_size\n\n  def forward(self, x: torch.Tensor, t: torch.Tensor) -&gt; ModelPrediction:\n    \"\"\"Forward pass through the model.\n\n    Args:\n      x: Token indices [B, L]\n      t: Time values [B]\n\n    Returns:\n      ModelPrediction with token_logits and expected_gaps/length_posterior\n    \"\"\"\n    if self.only_embed_insert:\n      t_embed = self.insertion_schedule.at(t)\n      return self.backbone(x, t_embed)\n    else:\n      return self.backbone(x, t)\n\n  def training_loss(\n    self, x1: torch.Tensor, t: torch.Tensor\n  ) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Compute training loss.\n\n    Args:\n      x1: Clean token sequences [B, L]\n      t: Time values [B]\n\n    Returns:\n      Tuple of (unmask_loss, insertion_loss, total_loss)\n    \"\"\"\n    # Sample interpolant\n    interpolant_sample = self.interpolant.sample_interpolant(t, x1)\n    unmask_weight, insert_weight = self.interpolant.elbo_weight(t, x1)\n\n    # Forward pass\n    prediction: ModelPrediction = self.forward(interpolant_sample.xt, t)\n\n    scale_factor = x1.shape[0] * self.num_tokens\n\n    # Unmask loss (token prediction)\n    if self.unmask_loss_fn == \"elbo\":\n      mask_indices = interpolant_sample.mask_indices\n      unmask_loss = unmask_weight[mask_indices] * liger_cross_entropy(\n        prediction.token_logits[mask_indices],\n        interpolant_sample.unmasked[mask_indices],\n        reduction=\"none\",\n      )\n      unmask_loss = unmask_loss.sum() / scale_factor\n    else:\n      raise ValueError(f\"Invalid unmask loss type: {self.unmask_loss_fn}\")\n\n    # Insertion loss (length prediction)\n    gaps, gaps_mask = interpolant_sample.gaps_and_mask\n    if self.insert_loss_fn == \"expectation\":\n      insertion_loss = insert_weight[gaps_mask] * self._jump_kernel_elbo(\n        gaps[gaps_mask], prediction.expected_gaps[gaps_mask]\n      )\n      insertion_loss = insertion_loss.sum() / scale_factor\n    elif self.insert_loss_fn == \"distribution\":\n      insertion_loss = insert_weight[gaps_mask] * liger_cross_entropy(\n        prediction.length_posterior[gaps_mask],\n        gaps[gaps_mask],\n        reduction=\"none\",\n      )\n      insertion_loss = insertion_loss.sum() / scale_factor\n    else:\n      raise ValueError(f\"Invalid insert loss type: {self.insert_loss_fn}\")\n\n    total_loss = unmask_loss + insertion_loss\n    return unmask_loss, insertion_loss, total_loss\n\n  def training_step(self, batch, batch_idx):\n    \"\"\"Training step.\n\n    Args:\n      batch: Batch dictionary with 'input_ids' and 'attention_mask'\n      batch_idx: Batch index\n\n    Returns:\n      Total loss\n    \"\"\"\n    del batch_idx  # Unused\n\n    # Extract input data\n    if isinstance(batch, dict):\n      x1 = batch[\"input_ids\"]\n    else:\n      x1 = batch\n\n    # Sample time\n    t = self.sample_time(x1.shape[0], x1.device)\n\n    # Calculate losses\n    unmask_loss, len_loss, loss = self.training_loss(x1, t)\n\n    # Log component losses\n    self.log(\"train/unmask_loss\", unmask_loss, prog_bar=True, sync_dist=True)\n    self.log(\"train/len_loss\", len_loss, prog_bar=True, sync_dist=True)\n    self.log(\"trainer/loss\", loss, prog_bar=True, sync_dist=True)\n\n    return loss\n\n  def validation_step(self, batch, batch_idx):\n    \"\"\"Validation step.\n\n    Args:\n      batch: Batch dictionary with 'input_ids' and 'attention_mask'\n      batch_idx: Batch index\n\n    Returns:\n      Total loss\n    \"\"\"\n    del batch_idx  # Unused\n\n    if isinstance(batch, dict):\n      x1 = batch[\"input_ids\"]\n    else:\n      x1 = batch\n\n    # Sample time\n    t = self.sample_time(x1.shape[0], x1.device)\n    unmask_loss, len_loss, loss = self.training_loss(x1, t)\n\n    self.log(\"val/unmask_loss\", unmask_loss, prog_bar=True, sync_dist=True)\n    self.log(\"val/len_loss\", len_loss, prog_bar=True, sync_dist=True)\n    self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n\n    return loss\n\n  def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure=None):\n    \"\"\"Optimizer step with logging.\n\n    Args:\n      epoch: Current epoch\n      batch_idx: Current batch index\n      optimizer: Optimizer\n      optimizer_closure: Closure for optimizer step\n    \"\"\"\n    super().optimizer_step(\n      epoch, batch_idx, optimizer, optimizer_closure=optimizer_closure\n    )\n\n    # Log learning rate and gradient norm\n    lr = optimizer.param_groups[0][\"lr\"]\n    self.log(\"train/lr\", lr, on_step=True, prog_bar=True)\n    grad_norm = torch.sqrt(\n      sum(p.grad.norm(2) ** 2 for p in self.parameters() if p.grad is not None)\n    )\n    self.log(\"train/grad_norm\", grad_norm, on_step=True, prog_bar=False)\n</code></pre>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder.__init__","title":"<code>__init__(config, tokenizer)</code>","text":"<p>Initialize FlexMDM any-order algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>Hydra config object</p> required <code>tokenizer</code> <code>PreTrainedTokenizer</code> <p>Tokenizer for the dataset</p> required Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>def __init__(self, config, tokenizer: transformers.PreTrainedTokenizer):\n  \"\"\"Initialize FlexMDM any-order algorithm.\n\n  Args:\n    config: Hydra config object\n    tokenizer: Tokenizer for the dataset\n  \"\"\"\n  # Ensure tokenizer has mask token\n  self.mask_id, vocab_size = ensure_mask_token(tokenizer)\n\n  # Set special tokens in config BEFORE calling super().__init__()\n  # so the model gets instantiated with correct token IDs\n  config.model.mask_token = self.mask_id\n  config.model.pad_token = tokenizer.pad_token_id\n\n  super().__init__(config, tokenizer, vocab_size=vocab_size)\n  self.save_hyperparameters()\n\n  # Get algorithm-specific config\n  algo_cfg = self.config.algo\n\n  # Loss function types\n  self.unmask_loss_fn = getattr(algo_cfg, 'unmask_loss_fn', 'elbo')\n  self.insert_loss_fn = getattr(algo_cfg, 'insert_loss_fn', 'expectation')\n\n  # Create insertion and unmasking schedules (default to linear)\n  insert_cfg = getattr(algo_cfg, 'insert_schedule', None)\n  unmask_cfg = getattr(algo_cfg, 'unmask_schedule', None)\n  self.insertion_schedule = build_flex_schedule(insert_cfg)\n  self.unmask_schedule = build_flex_schedule(unmask_cfg)\n\n  # Create interpolant\n  self.interpolant = FlexMDMForwardProcess(\n    insertion_schedule=self.insertion_schedule,\n    unmask_schedule=self.unmask_schedule,\n    tokenizer=self.tokenizer,\n    max_length=self.num_tokens,\n    pad_token=self.tokenizer.pad_token_id,\n  )\n\n  # Only embed insert time (not both insert and unmask)\n  self.only_embed_insert = getattr(algo_cfg, 'only_embed_insert', True)\n\n  self._validate_configuration()\n</code></pre>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder.forward","title":"<code>forward(x, t)</code>","text":"<p>Forward pass through the model.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Token indices [B, L]</p> required <code>t</code> <code>Tensor</code> <p>Time values [B]</p> required <p>Returns:</p> Type Description <code>ModelPrediction</code> <p>ModelPrediction with token_logits and expected_gaps/length_posterior</p> Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>def forward(self, x: torch.Tensor, t: torch.Tensor) -&gt; ModelPrediction:\n  \"\"\"Forward pass through the model.\n\n  Args:\n    x: Token indices [B, L]\n    t: Time values [B]\n\n  Returns:\n    ModelPrediction with token_logits and expected_gaps/length_posterior\n  \"\"\"\n  if self.only_embed_insert:\n    t_embed = self.insertion_schedule.at(t)\n    return self.backbone(x, t_embed)\n  else:\n    return self.backbone(x, t)\n</code></pre>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder.optimizer_step","title":"<code>optimizer_step(epoch, batch_idx, optimizer, optimizer_closure=None)</code>","text":"<p>Optimizer step with logging.</p> <p>Parameters:</p> Name Type Description Default <code>epoch</code> <p>Current epoch</p> required <code>batch_idx</code> <p>Current batch index</p> required <code>optimizer</code> <p>Optimizer</p> required <code>optimizer_closure</code> <p>Closure for optimizer step</p> <code>None</code> Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_closure=None):\n  \"\"\"Optimizer step with logging.\n\n  Args:\n    epoch: Current epoch\n    batch_idx: Current batch index\n    optimizer: Optimizer\n    optimizer_closure: Closure for optimizer step\n  \"\"\"\n  super().optimizer_step(\n    epoch, batch_idx, optimizer, optimizer_closure=optimizer_closure\n  )\n\n  # Log learning rate and gradient norm\n  lr = optimizer.param_groups[0][\"lr\"]\n  self.log(\"train/lr\", lr, on_step=True, prog_bar=True)\n  grad_norm = torch.sqrt(\n    sum(p.grad.norm(2) ** 2 for p in self.parameters() if p.grad is not None)\n  )\n  self.log(\"train/grad_norm\", grad_norm, on_step=True, prog_bar=False)\n</code></pre>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder.sample_time","title":"<code>sample_time(batch_size, device)</code>","text":"<p>Sample time values with low-discrepancy sampling.</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>Number of samples</p> required <code>device</code> <code>device</code> <p>Device for tensors</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Time values in [0, 1][B]</p> Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>def sample_time(self, batch_size: int, device: torch.device) -&gt; torch.Tensor:\n  \"\"\"Sample time values with low-discrepancy sampling.\n\n  Args:\n    batch_size: Number of samples\n    device: Device for tensors\n\n  Returns:\n    Time values in [0, 1] [B]\n  \"\"\"\n  eps = 1e-6\n  interval = 1.0 - eps\n  interval_size = interval / batch_size\n  u = torch.rand(batch_size, device=device)\n  return (torch.arange(batch_size, device=device, dtype=u.dtype) + u\n          ) * interval_size\n</code></pre>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder.training_loss","title":"<code>training_loss(x1, t)</code>","text":"<p>Compute training loss.</p> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>Tensor</code> <p>Clean token sequences [B, L]</p> required <code>t</code> <code>Tensor</code> <p>Time values [B]</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor, Tensor]</code> <p>Tuple of (unmask_loss, insertion_loss, total_loss)</p> Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>def training_loss(\n  self, x1: torch.Tensor, t: torch.Tensor\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n  \"\"\"Compute training loss.\n\n  Args:\n    x1: Clean token sequences [B, L]\n    t: Time values [B]\n\n  Returns:\n    Tuple of (unmask_loss, insertion_loss, total_loss)\n  \"\"\"\n  # Sample interpolant\n  interpolant_sample = self.interpolant.sample_interpolant(t, x1)\n  unmask_weight, insert_weight = self.interpolant.elbo_weight(t, x1)\n\n  # Forward pass\n  prediction: ModelPrediction = self.forward(interpolant_sample.xt, t)\n\n  scale_factor = x1.shape[0] * self.num_tokens\n\n  # Unmask loss (token prediction)\n  if self.unmask_loss_fn == \"elbo\":\n    mask_indices = interpolant_sample.mask_indices\n    unmask_loss = unmask_weight[mask_indices] * liger_cross_entropy(\n      prediction.token_logits[mask_indices],\n      interpolant_sample.unmasked[mask_indices],\n      reduction=\"none\",\n    )\n    unmask_loss = unmask_loss.sum() / scale_factor\n  else:\n    raise ValueError(f\"Invalid unmask loss type: {self.unmask_loss_fn}\")\n\n  # Insertion loss (length prediction)\n  gaps, gaps_mask = interpolant_sample.gaps_and_mask\n  if self.insert_loss_fn == \"expectation\":\n    insertion_loss = insert_weight[gaps_mask] * self._jump_kernel_elbo(\n      gaps[gaps_mask], prediction.expected_gaps[gaps_mask]\n    )\n    insertion_loss = insertion_loss.sum() / scale_factor\n  elif self.insert_loss_fn == \"distribution\":\n    insertion_loss = insert_weight[gaps_mask] * liger_cross_entropy(\n      prediction.length_posterior[gaps_mask],\n      gaps[gaps_mask],\n      reduction=\"none\",\n    )\n    insertion_loss = insertion_loss.sum() / scale_factor\n  else:\n    raise ValueError(f\"Invalid insert loss type: {self.insert_loss_fn}\")\n\n  total_loss = unmask_loss + insertion_loss\n  return unmask_loss, insertion_loss, total_loss\n</code></pre>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <p>Batch dictionary with 'input_ids' and 'attention_mask'</p> required <code>batch_idx</code> <p>Batch index</p> required <p>Returns:</p> Type Description <p>Total loss</p> Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>def training_step(self, batch, batch_idx):\n  \"\"\"Training step.\n\n  Args:\n    batch: Batch dictionary with 'input_ids' and 'attention_mask'\n    batch_idx: Batch index\n\n  Returns:\n    Total loss\n  \"\"\"\n  del batch_idx  # Unused\n\n  # Extract input data\n  if isinstance(batch, dict):\n    x1 = batch[\"input_ids\"]\n  else:\n    x1 = batch\n\n  # Sample time\n  t = self.sample_time(x1.shape[0], x1.device)\n\n  # Calculate losses\n  unmask_loss, len_loss, loss = self.training_loss(x1, t)\n\n  # Log component losses\n  self.log(\"train/unmask_loss\", unmask_loss, prog_bar=True, sync_dist=True)\n  self.log(\"train/len_loss\", len_loss, prog_bar=True, sync_dist=True)\n  self.log(\"trainer/loss\", loss, prog_bar=True, sync_dist=True)\n\n  return loss\n</code></pre>"},{"location":"reference/algorithms/flexmdm/#discrete_diffusion.algorithms.flexmdm_anyorder.FlexMDMAnyOrder.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <p>Batch dictionary with 'input_ids' and 'attention_mask'</p> required <code>batch_idx</code> <p>Batch index</p> required <p>Returns:</p> Type Description <p>Total loss</p> Source code in <code>src/discrete_diffusion/algorithms/flexmdm_anyorder.py</code> <pre><code>def validation_step(self, batch, batch_idx):\n  \"\"\"Validation step.\n\n  Args:\n    batch: Batch dictionary with 'input_ids' and 'attention_mask'\n    batch_idx: Batch index\n\n  Returns:\n    Total loss\n  \"\"\"\n  del batch_idx  # Unused\n\n  if isinstance(batch, dict):\n    x1 = batch[\"input_ids\"]\n  else:\n    x1 = batch\n\n  # Sample time\n  t = self.sample_time(x1.shape[0], x1.device)\n  unmask_loss, len_loss, loss = self.training_loss(x1, t)\n\n  self.log(\"val/unmask_loss\", unmask_loss, prog_bar=True, sync_dist=True)\n  self.log(\"val/len_loss\", len_loss, prog_bar=True, sync_dist=True)\n  self.log(\"val_loss\", loss, prog_bar=True, sync_dist=True)\n\n  return loss\n</code></pre>"},{"location":"reference/algorithms/gidd/","title":"GIDD","text":""},{"location":"reference/algorithms/gidd/#discrete_diffusion.algorithms.gidd","title":"<code>discrete_diffusion.algorithms.gidd</code>","text":"<p>GIDD algorithm implementation.</p>"},{"location":"reference/algorithms/mdlm/","title":"MDLM","text":""},{"location":"reference/algorithms/mdlm/#discrete_diffusion.algorithms.mdlm","title":"<code>discrete_diffusion.algorithms.mdlm</code>","text":"<p>MDLM algorithm implementation extracted from :mod:<code>algorithms.algo</code>.</p>"},{"location":"reference/algorithms/mdlm/#discrete_diffusion.algorithms.mdlm.MDLM","title":"<code>MDLM</code>","text":"<p>               Bases: <code>AbsorbingState</code></p> <p>Masked Diffusion Language Model (MDLM) algorithm.</p> <p>Implements the MDLM objective where tokens are masked and reconstructed.</p> Source code in <code>src/discrete_diffusion/algorithms/mdlm.py</code> <pre><code>class MDLM(trainer_base.AbsorbingState):\n  \"\"\"Masked Diffusion Language Model (MDLM) algorithm.\n\n  Implements the MDLM objective where tokens are masked and reconstructed.\n  \"\"\"\n  def __init__(self, config, tokenizer):\n    super().__init__(config, tokenizer)\n    self.shift_loss_targets = getattr(config.algo, 'shift_loss_targets', False)\n    super()._validate_configuration()\n\n  def _process_model_output(self, model_output, xt, sigma):\n    index = torch.full((xt.shape[0], xt.shape[1], 1), self.mask_id, device=xt.device)\n    model_output = torch.scatter(model_output, -1, index, self.neg_infinity)\n    model_output = torch.where((xt != self.mask_id)[..., None], self.neg_infinity, model_output)\n    model_output = torch.scatter(model_output, -1, xt[..., None], 0.0)\n    return model_output\n\n  def nll_per_token(self, log_x_theta, xt, x0, alpha_t, dalpha_t, low_var=False):\n    ce_loss = liger_cross_entropy(\n        log_x_theta.flatten(0, 1),\n        x0.flatten(0, 1),\n        reduction='none'\n    ).view_as(x0)\n    loss_coefficient = -1 if low_var else dalpha_t / (1 - alpha_t)\n    return -loss_coefficient * ce_loss\n\n  def _get_score(self, x, sigma, group_idxs=None):\n    model_output = self.forward(x, sigma, group_idxs)\n    # score(x, t) = p_t(y) / p_t(x) =&gt; log score(x, t) = log p_t(y) - log p_t(x)\n\n    log_k = -torch.log(torch.expm1(sigma)).squeeze(-1)\n    assert log_k.ndim == 1\n\n    # Compute scores for masked positions\n    masked_score = model_output + log_k[:, None, None]\n    masked_score[:, :, self.mask_id] = 0\n\n    unmasked_score = self.neg_infinity * torch.ones_like(model_output)\n    unmasked_score = torch.scatter(\n      unmasked_score,\n      -1,\n      x[..., None],\n      torch.zeros_like(unmasked_score[..., :1]))\n\n    unmasked_score[:, :, self.mask_id] = -(log_k[:, None] * torch.ones_like(x))\n\n    masked_indices = (x == self.mask_id).to(model_output.dtype)[:, :, None]\n    model_output = (masked_score * masked_indices + unmasked_score * (1 - masked_indices))\n    return model_output.exp()\n</code></pre>"},{"location":"reference/algorithms/partition_mdlm/","title":"Partition MDLM","text":""},{"location":"reference/algorithms/partition_mdlm/#discrete_diffusion.algorithms.partition_mdlm","title":"<code>discrete_diffusion.algorithms.partition_mdlm</code>","text":"<p>PartitionMDLM algorithm definition extracted from :mod:<code>algorithms.algo</code>.</p>"},{"location":"reference/algorithms/sedd/","title":"SEDD","text":""},{"location":"reference/algorithms/sedd/#discrete_diffusion.algorithms.sedd","title":"<code>discrete_diffusion.algorithms.sedd</code>","text":"<p>SEDD algorithm implementation extracted from :mod:<code>algorithms.algo</code>.</p>"},{"location":"reference/algorithms/sedd/#discrete_diffusion.algorithms.sedd.SEDD","title":"<code>SEDD</code>","text":"<p>               Bases: <code>AbsorbingState</code></p> Source code in <code>src/discrete_diffusion/algorithms/sedd.py</code> <pre><code>class SEDD(trainer_base.AbsorbingState):\n  def __init__(self, config, tokenizer):\n    super().__init__(config, tokenizer)\n    self._validate_configuration()\n\n  def _validate_configuration(self):\n    super()._validate_configuration()\n    if self.parameterization != 'sedd':\n      raise ValueError(self.parameterization)\n    if not self.time_conditioning:\n      raise ValueError('SEDD requires time conditioning.')\n\n  def _process_model_output(self, model_output, xt, sigma):\n    if sigma.ndim == 1:\n      sigma = sigma[:, None]\n    sigma = sigma.to(model_output.dtype)\n    # Match bd3lms implementation: compute esigm1_log in one step to avoid intermediate tensor\n    esigm1_log = torch.where(\n      sigma &lt; 0.5,\n      torch.expm1(sigma),\n      sigma.exp() - 1).log().to(model_output.dtype)\n    # model_output shape: (batch_size, diffusion_model_input_length, vocab_size)\n    model_output = model_output - esigm1_log.unsqueeze(-1) - torch.tensor(\n      np.log(model_output.shape[-1] - 1),\n      dtype=model_output.dtype,\n      device=model_output.device\n    )\n    # The below scatter operation sets the log score for the input word to 0.\n    model_output = torch.scatter(model_output, -1, xt[..., None], torch.zeros_like(model_output[..., :1]))\n    return model_output\n\n  def _score_entropy(self, log_score, sigma, xt, x0):\n    \"\"\"Compute the SEDD score-entropy term per token.\n\n    Robust to the forward process choice:\n    - Absorbing/mask-based: changed covers xt==mask_id since mask!=x0.\n    - SEDD/uniform-replace: changed = (xt != x0).\n    \"\"\"\n    if sigma.ndim == 1:\n      sigma = sigma[:, None]\n    sigma = sigma.to(log_score.dtype)\n\n    # Positions that changed under the forward process\n    changed = (xt != x0)\n    if not torch.any(changed):\n      return torch.zeros_like(xt, dtype=log_score.dtype)\n\n    expsig_minus_1 = torch.expm1(sigma).expand(-1, xt.shape[1])\n    q_ratio = 1 / expsig_minus_1[changed]\n\n    # Negative term: q_ratio * log_score(x0)\n    target_tokens = x0[changed]\n    neg_term = q_ratio * torch.gather(\n      log_score[changed],\n      -1,\n      target_tokens[..., None]).squeeze(-1)\n\n    # Positive term: sum over all tokens except the current token at xt.\n    # log_score has the log-score for xt set to 0 (score_xt = 1).\n    score = log_score[changed].exp()\n    current_tokens = xt[changed]\n    score_xt = torch.gather(score, -1, current_tokens[..., None]).squeeze(-1)\n    pos_term = score.sum(dim=-1) - score_xt\n\n    const = q_ratio * (q_ratio.log() - 1)\n    raw_entropy = (pos_term - neg_term + const).to(log_score.dtype)\n    entropy = torch.zeros_like(log_score[..., 0])\n    entropy = torch.masked_scatter(entropy, changed, raw_entropy)\n    return entropy\n\n  def nll_per_token(self, log_x_theta, xt, x0, alpha_t,\n                    dalpha_t, low_var=False):\n    sigma = self._sigma_from_alphat(alpha_t)\n    entropy = self._score_entropy(log_x_theta, sigma, xt, x0)\n    dalpha = torch.as_tensor(\n      dalpha_t, device=alpha_t.device, dtype=alpha_t.dtype)\n    while dalpha.dim() &lt; alpha_t.dim():\n      dalpha = dalpha.unsqueeze(-1)\n    dalpha = dalpha.expand_as(alpha_t)\n    dsigma = - dalpha / alpha_t\n    return dsigma * entropy\n</code></pre>"},{"location":"reference/algorithms/udlm/","title":"UDLM","text":""},{"location":"reference/algorithms/udlm/#discrete_diffusion.algorithms.udlm","title":"<code>discrete_diffusion.algorithms.udlm</code>","text":""},{"location":"reference/algorithms/udlm/#discrete_diffusion.algorithms.udlm.UDLM","title":"<code>UDLM</code>","text":"<p>               Bases: <code>Diffusion</code></p> <p>Uniform Discrete Latent Model (UDLM).</p> <ul> <li>Forward process: with prob (1 - alpha_t), replace token with a uniform token   over the vocabulary; otherwise keep it unchanged.</li> <li>Parameterization: reuse 'subs' head; logits are turned into log-probabilities   with log_softmax and no special mask handling.</li> </ul> Source code in <code>src/discrete_diffusion/algorithms/udlm.py</code> <pre><code>class UDLM(trainer_base.Diffusion):\n  \"\"\"Uniform Discrete Latent Model (UDLM).\n\n  - Forward process: with prob (1 - alpha_t), replace token with a uniform token\n    over the vocabulary; otherwise keep it unchanged.\n  - Parameterization: reuse 'subs' head; logits are turned into log-probabilities\n    with log_softmax and no special mask handling.\n  \"\"\"\n\n  def __init__(self, config, tokenizer):\n    super().__init__(config, tokenizer)\n    # Limiting distribution \u03c0(y) = 1 / V for all tokens y\n    self.register_buffer(\n      'limiting_distribution',\n      torch.full((self.vocab_size,), 1.0 / float(self.vocab_size)))\n    # Config for whether to include reconstruction loss (default: False for UDLM)\n    self.zero_recon_loss = getattr(config.algo, 'zero_recon_loss', True)\n    self._validate_configuration()\n    # Build a forward process using Hydra instantiation. If the config doesn't specify\n    # one, default UDLM to the 'uniform' forward process to match semantics.\n    try:\n      fp = hydra.utils.instantiate(\n        self.config.algo.forward_process,\n        tokenizer=self.tokenizer,\n        schedule=self.noise\n      )\n    except Exception:\n      fp = None\n    self._forward_process = (\n      fp if isinstance(fp, UniformForwardProcess)\n      else UniformForwardProcess(tokenizer=self.tokenizer, schedule=self.noise, name='uniform')\n    )\n\n  def _validate_configuration(self):\n    super()._validate_configuration()\n    # UDLM uses no time-conditioning by default and subs parameterization\n    if self.time_conditioning:\n      raise ValueError('UDLM expects algo.time_conditioning=False')\n    # Only log-linear noise is supported for UDLM currently\n    # This constraint exists because UDLM's loss computation hardcodes the log-linear\n    # schedule form (see nll_per_token method). Other schedules may be supported in the future.\n    if not isinstance(self.noise, LogLinear):\n      raise ValueError(\n        'UDLM currently supports only LogLinear noise schedule. '\n        'Set config.algo.noise_schedule.name=log_linear')\n\n  def prior_sample(self, *batch_dims):\n    # Uniform prior over [0, vocab_size)\n    return torch.randint(\n      low=0,\n      high=self.vocab_size,\n      size=batch_dims,\n      device=self.device,\n      dtype=torch.int64,\n    )\n\n  def q_xt(self, x, t, sampling_eps_min=None, sampling_eps_max=None):\n    del sampling_eps_min, sampling_eps_max\n    # Route through the forward-process registry (uniform replacement).\n    out = self._forward_process(x, t)\n    xt = out[0] if isinstance(out, (tuple, list)) else out\n    if getattr(self, 'ignore_bos', False):\n      xt[:, 0] = x[:, 0]\n    return xt\n\n  def _process_model_output(self, model_output, xt, sigma):\n    # No mask handling; UDLM uses plain log-probabilities over vocab\n    return torch.log_softmax(model_output, dim=-1)\n\n  def nll_per_token(self, log_x_theta, xt, x0, alpha_t, dalpha_t, low_var=False):\n    del low_var, dalpha_t\n    # Shapes\n    #  log_x_theta: (B, L, V)\n    #  xt, x0: (B, L)\n    #  alpha_t: (B, 1) from our LogLinear schedule: alpha_t = 1 - (1 - eps) * t\n    B, L, V = log_x_theta.shape\n    vocab_size = V\n\n    # Hardcode loglinear continuous-time forms (match guidance repo):\n    #   alpha_t = 1 - t\n    #   alpha_t' = -1\n    # Recover t from our alpha_t definition: alpha_t = 1 - (1 - eps) * t\n    eps = getattr(self.noise, 'eps', 1e-3)\n    t = (1 - alpha_t.to(log_x_theta.dtype)) / (1 - eps)\n    alpha_t_prime = -1.\n    alpha_t = 1. - t[..., None]  # B, 1, 1\n    x_bar = vocab_size * alpha_t * F.one_hot(x0, self.vocab_size).float() + 1 - alpha_t\n    x_bar_theta = vocab_size * alpha_t * log_x_theta.exp() + 1 - alpha_t\n\n    # \u03b1_t' / (N*\u03b1_t) with \u03b1_t' = -1\n    coeff = alpha_t_prime / (vocab_size * alpha_t)\n\n    # Term 1: indices where z_t = 1\n    x_bar_zt = torch.gather(x_bar, -1, xt[..., None])  # (B, L, 1)\n    x_bar_theta_zt = torch.gather(x_bar_theta, -1, xt[..., None])  # (B, L, 1)\n    term1 = (vocab_size / x_bar_zt) - (vocab_size / x_bar_theta_zt)  # (B, L, 1)\n\n    # Term 2: indices where z_t = 0\n    term2 = (\n      (x_bar / x_bar_zt) * (\n        x_bar_theta_zt.log() - x_bar_theta.log() +\n        x_bar.log() - x_bar_zt.log()\n      )\n    ).sum(dim=-1, keepdim=True)  # (B, L, 1)\n\n    diffusion_loss = (coeff * (term1 - term2)).squeeze(-1)  # (B, L)\n\n    # Optionally include reconstruction term at t=0 based on config\n    if self.zero_recon_loss:\n      # For UDLM with log-linear schedule, we only return the diffusion loss.\n      # This is the correct formulation for continuous-time UDLM (equivalent to\n      # zero_recon_loss=True in the discrete-diffusion-guidance implementation).\n      return diffusion_loss\n    else:\n      # Include reconstruction loss (used for discrete-time or other variants)\n      reconstruction_loss = self._reconstruction_loss(x0)  # (B, L)\n      return diffusion_loss + reconstruction_loss\n</code></pre>"},{"location":"reference/callbacks/latency/","title":"Training Latency","text":""},{"location":"reference/callbacks/latency/#discrete_diffusion.callbacks.training_latency_callback","title":"<code>discrete_diffusion.callbacks.training_latency_callback</code>","text":"<p>Lightning callbacks used across discrete_diffusion.</p>"},{"location":"reference/callbacks/latency/#discrete_diffusion.callbacks.training_latency_callback.TrainingLatencyCallback","title":"<code>TrainingLatencyCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Measure forward/backward latency on synthetic data during training.</p> <p>The callback generates synthetic batches once the configured <code>start_step</code> is reached and records latency/throughput statistics without touching the real dataloader. Metrics are logged once and saved under <code>train_latency</code> in the current working directory.</p> Source code in <code>src/discrete_diffusion/callbacks/training_latency_callback.py</code> <pre><code>class TrainingLatencyCallback(L.Callback):\n  \"\"\"Measure forward/backward latency on synthetic data during training.\n\n  The callback generates synthetic batches once the configured ``start_step``\n  is reached and records latency/throughput statistics without touching the\n  real dataloader. Metrics are logged once and saved under ``train_latency``\n  in the current working directory.\n  \"\"\"\n\n  def __init__(\n      self,\n      enabled: bool = False,\n      start_step: int = 500,\n      num_batches: int = 500,\n      num_warmup: int = 10,\n      batch_size: int | None = None,\n      sequence_length: int | None = None,\n      save_name: str = \"callback_latency.json\",\n      pretty_print: bool = True) -&gt; None:\n    super().__init__()\n    self.enabled = enabled\n    self.start_step = start_step\n    self.num_batches = num_batches\n    self.num_warmup = num_warmup\n    self.batch_size = batch_size\n    self.sequence_length = sequence_length\n    self.save_name = save_name\n    self.pretty_print = pretty_print\n    self._has_run = False\n\n  def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):  # noqa: D401\n    if not self.enabled or self._has_run:\n      return\n\n    if trainer.global_step &lt; self.start_step:\n      return\n\n    strategy = trainer.strategy\n    if strategy is not None:\n      strategy.barrier()\n\n    results: Dict[str, Dict[str, float]] | None = None\n    if getattr(trainer, 'global_rank', 0) == 0:\n      results = self._run_measurement(trainer, pl_module)\n      self._log_results(trainer, results)\n\n    self._has_run = True\n\n    if strategy is not None:\n      strategy.barrier()\n\n  def _run_measurement(self, trainer, pl_module) -&gt; Dict[str, Dict[str, float]]:\n    device = pl_module.device\n    batch_size = self.batch_size or getattr(\n      pl_module.config.loader, 'batch_size', None)\n    if batch_size is None:\n      raise ValueError('`batch_size` must be provided for latency timing.')\n\n    sequence_length = self.sequence_length or getattr(\n      pl_module.config.model, 'length', None)\n    if sequence_length is None:\n      raise ValueError('`sequence_length` must be provided for latency timing.')\n\n    vocab_size = getattr(pl_module, 'vocab_size', None)\n    if vocab_size is None:\n      if hasattr(pl_module, 'tokenizer'):\n        vocab_size = len(pl_module.tokenizer)\n      else:\n        raise ValueError('Could not infer vocabulary size for latency timing.')\n\n    forward_stats = self._time_forward(\n      pl_module, vocab_size, batch_size, sequence_length, device)\n    fwd_bwd_stats = self._time_forward_backward(\n      pl_module, vocab_size, batch_size, sequence_length, device)\n\n    return {\n      'forward': forward_stats.__dict__,\n      'forward_backward': fwd_bwd_stats.__dict__,\n      'meta': {\n        'start_step': self.start_step,\n        'measured_step': trainer.global_step,\n        'batch_size': batch_size,\n        'sequence_length': sequence_length,\n        'num_warmup': self.num_warmup,\n        'num_batches': self.num_batches,\n      }\n    }\n\n  def _time_forward(self, pl_module, vocab_size, batch_size,\n                    sequence_length, device) -&gt; _TimingStats:\n    latencies, throughputs = self._measure(\n      pl_module, vocab_size, batch_size, sequence_length, device,\n      backward=False)\n    return self._aggregate(latencies, throughputs)\n\n  def _time_forward_backward(self, pl_module, vocab_size, batch_size,\n                             sequence_length, device) -&gt; _TimingStats:\n    latencies, throughputs = self._measure(\n      pl_module, vocab_size, batch_size, sequence_length, device,\n      backward=True)\n    return self._aggregate(latencies, throughputs)\n\n  def _measure(self, pl_module, vocab_size, batch_size,\n               sequence_length, device, backward):\n    total_iters = self.num_warmup + self.num_batches\n    latencies = []\n    throughputs = []\n\n    for _ in range(total_iters):\n      x0 = torch.randint(\n        0, vocab_size,\n        size=(batch_size, sequence_length),\n        device=device)\n      valid_tokens = torch.ones_like(x0, device=device)\n\n      if device.type == 'cuda' and torch.cuda.is_available():\n        torch.cuda.synchronize(device)\n      start_time = time.perf_counter()\n      losses = pl_module._loss(x0, valid_tokens, train_mode=True)\n      if backward:\n        losses.loss.backward()\n        pl_module.zero_grad(set_to_none=True)\n      if device.type == 'cuda' and torch.cuda.is_available():\n        torch.cuda.synchronize(device)\n      end_time = time.perf_counter()\n\n      latency = end_time - start_time\n      latencies.append(latency)\n      throughputs.append((batch_size * sequence_length) / latency)\n\n    latencies = latencies[self.num_warmup:]\n    throughputs = throughputs[self.num_warmup:]\n    return latencies, throughputs\n\n  def _aggregate(self, latencies, throughputs) -&gt; _TimingStats:\n    latency_arr = np.asarray(latencies, dtype=np.float64)\n    throughput_arr = np.asarray(throughputs, dtype=np.float64)\n    return _TimingStats(\n      latency_mean=float(latency_arr.mean()),\n      latency_std=float(latency_arr.std(ddof=0)),\n      throughput_mean=float(throughput_arr.mean()),\n      throughput_std=float(throughput_arr.std(ddof=0)))\n\n  @rank_zero_only\n  def _log_results(self, trainer, results):\n    if trainer.logger is not None:\n      metrics = {\n        'latency/forward_mean_s': results['forward']['latency_mean'],\n        'latency/forward_std_s': results['forward']['latency_std'],\n        'throughput/forward_mean_tokens_per_s':\n          results['forward']['throughput_mean'],\n        'throughput/forward_std_tokens_per_s':\n          results['forward']['throughput_std'],\n        'latency/forward_backward_mean_s':\n          results['forward_backward']['latency_mean'],\n        'latency/forward_backward_std_s':\n          results['forward_backward']['latency_std'],\n        'throughput/forward_backward_mean_tokens_per_s':\n          results['forward_backward']['throughput_mean'],\n        'throughput/forward_backward_std_tokens_per_s':\n          results['forward_backward']['throughput_std'],\n      }\n      trainer.logger.log_metrics(metrics, step=trainer.global_step)\n\n    save_dir = os.path.join(os.getcwd(), 'train_latency')\n    os.makedirs(save_dir, exist_ok=True)\n    save_path = os.path.join(save_dir, self.save_name)\n    with open(save_path, 'w') as fp:\n      json.dump(results, fp, indent=4)\n\n    if self.pretty_print:\n      table = Table(title='Training Latency (synthetic batches)')\n      table.add_column('Phase')\n      table.add_column('Latency (s)', justify='right')\n      table.add_column('Throughput (tokens/s)', justify='right')\n      table.add_row(\n        'Forward',\n        f\"{results['forward']['latency_mean']:.6f} \u00b1 \"\n        f\"{results['forward']['latency_std']:.6f}\",\n        f\"{results['forward']['throughput_mean']:.1f} \u00b1 \"\n        f\"{results['forward']['throughput_std']:.1f}\")\n      table.add_row(\n        'Forward+Backward',\n        f\"{results['forward_backward']['latency_mean']:.6f} \u00b1 \"\n        f\"{results['forward_backward']['latency_std']:.6f}\",\n        f\"{results['forward_backward']['throughput_mean']:.1f} \u00b1 \"\n        f\"{results['forward_backward']['throughput_std']:.1f}\")\n      Console().print(table)\n</code></pre>"},{"location":"reference/callbacks/sample_saver/","title":"Sample Saver","text":""},{"location":"reference/callbacks/sample_saver/#discrete_diffusion.callbacks.sample_saver","title":"<code>discrete_diffusion.callbacks.sample_saver</code>","text":"<p>Periodic sample saving hook for discrete diffusion models.</p>"},{"location":"reference/callbacks/sample_saver/#discrete_diffusion.callbacks.sample_saver.SampleSaver","title":"<code>SampleSaver</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Save generated tokens every <code>every_n_steps</code> during training.</p> Source code in <code>src/discrete_diffusion/callbacks/sample_saver.py</code> <pre><code>class SampleSaver(L.Callback):\n  \"\"\"Save generated tokens every ``every_n_steps`` during training.\"\"\"\n\n  def __init__(\n      self,\n      enabled: bool = False,\n      every_n_steps: int = 1000,\n      num_samples: Optional[int] = None,\n      num_steps: Optional[int] = None,\n      save_dir: str = './samples/',\n      filename_template: str = 'step_{global_step}.json') -&gt; None:\n    super().__init__()\n    if every_n_steps &lt;= 0:\n      raise ValueError('every_n_steps must be positive')\n\n    self.enabled = enabled\n    self.every_n_steps = every_n_steps\n    self.num_samples = num_samples\n    self.num_steps = num_steps\n    self.save_dir = Path(save_dir)\n    self.filename_template = filename_template\n\n  def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n    del outputs, batch, batch_idx\n    if not self.enabled or not trainer.is_global_zero:\n      return\n\n    global_step = max(1, trainer.global_step)\n    if global_step % self.every_n_steps != 0:\n      return\n\n    samples = pl_module.generate_samples(\n      num_samples=self._resolve_num_samples(pl_module),\n      num_steps=self._resolve_num_steps(pl_module))\n    samples = samples.detach().cpu()\n    save_path = self._build_save_path(global_step)\n    save_path.parent.mkdir(parents=True, exist_ok=True)\n\n    text_samples = pl_module.tokenizer.batch_decode(samples.tolist())\n    entropy = self._mean_entropy(samples)\n    metadata = dict(\n      text=text_samples,\n      entropy=entropy,\n      config=OmegaConf.to_container(pl_module.config, resolve=True),\n    )\n    with open(save_path, 'w', encoding='utf-8') as fp:\n      json.dump(metadata, fp, indent=2)\n\n  def _mean_entropy(self, samples: torch.Tensor) -&gt; float:\n    if samples.numel() == 0:\n      return 0.0\n    entropies = []\n    for sample in samples.unbind(0):\n      _, counts = torch.unique(sample, return_counts=True, sorted=False)\n      probs = counts.float() / counts.sum()\n      entropies.append(float(torch.special.entr(probs).sum()))\n    return float(sum(entropies) / len(entropies))\n\n  def _build_save_path(self, global_step: int) -&gt; Path:\n    filename = self.filename_template.format(global_step=global_step)\n    return self.save_dir / filename\n\n  def _resolve_num_samples(self, pl_module) -&gt; int:\n    if self.num_samples is not None:\n      return self.num_samples\n    batch_size = getattr(pl_module.config.loader, 'eval_batch_size', None)\n    if batch_size is None:\n      raise ValueError('Could not infer num_samples for SampleSaver')\n    return batch_size\n\n  def _resolve_num_steps(self, pl_module) -&gt; int:\n    if self.num_steps is not None:\n      return self.num_steps\n    steps = getattr(pl_module.config.sampling, 'steps', None)\n    if steps is None:\n      raise ValueError('Could not infer sampling steps for SampleSaver')\n    return steps\n</code></pre>"},{"location":"reference/data/datamodule/","title":"DataModule","text":""},{"location":"reference/data/datamodule/#discrete_diffusion.data.datamodule","title":"<code>discrete_diffusion.data.datamodule</code>","text":"<p>Lightning DataModule for discrete diffusion datasets.</p>"},{"location":"reference/data/datamodule/#discrete_diffusion.data.datamodule.DiscreteDiffusionDataModule","title":"<code>DiscreteDiffusionDataModule</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p>Lightning DataModule for discrete diffusion datasets.</p> <p>Wraps dataset loading logic to provide train and validation dataloaders to the Lightning Trainer.</p> Source code in <code>src/discrete_diffusion/data/datamodule.py</code> <pre><code>class DiscreteDiffusionDataModule(L.LightningDataModule):\n  \"\"\"Lightning DataModule for discrete diffusion datasets.\n\n  Wraps dataset loading logic to provide train and validation dataloaders\n  to the Lightning Trainer.\n  \"\"\"\n\n  def __init__(self,\n               config,\n               tokenizer,\n               *,\n               skip_train: bool = False,\n               skip_valid: bool = False,\n               valid_seed: Optional[int] = None):\n    \"\"\"Initialize the DataModule.\n\n    Args:\n        config: Hydra configuration object.\n        tokenizer: Tokenizer instance.\n        skip_train: Whether to skip creating the training loader.\n        skip_valid: Whether to skip creating the validation loader.\n        valid_seed: Optional seed for validation set shuffling.\n    \"\"\"\n    super().__init__()\n    self.config = config\n    self.tokenizer = tokenizer\n    self.skip_train = skip_train\n    self.skip_valid = skip_valid\n    self.valid_seed = valid_seed\n    self._train_loader = None\n    self._valid_loader = None\n\n  def _build_loaders(self) -&gt; Tuple[Optional[object], Optional[object]]:\n    return get_dataloaders(\n      self.config,\n      self.tokenizer,\n      skip_train=self.skip_train,\n      skip_valid=self.skip_valid,\n      valid_seed=self.valid_seed)\n\n  def setup(self, stage: Optional[str] = None):\n    \"\"\"Set up datasets for the given stage.\n\n    Handles distributed data loading synchronization to ensure valid/test sets\n    are consistent across ranks.\n    \"\"\"\n    if stage not in (None, \"fit\", \"validate\"):\n      return\n    if self._train_loader is not None or self._valid_loader is not None:\n      return\n\n    trainer = getattr(self, \"trainer\", None)\n    strategy = getattr(trainer, \"strategy\", None) if trainer else None\n    barrier = getattr(strategy, \"barrier\", None) if strategy else None\n    is_rank_zero = bool(getattr(trainer, \"is_global_zero\", True))\n\n    if barrier is not None:\n      if is_rank_zero:\n        self._train_loader, self._valid_loader = self._build_loaders()\n      barrier()\n      if not is_rank_zero:\n        self._train_loader, self._valid_loader = self._build_loaders()\n      barrier()\n    else:\n      self._train_loader, self._valid_loader = self._build_loaders()\n\n  def train_dataloader(self):\n    if self._train_loader is None:\n      raise RuntimeError(\"DataModule setup() must run before requesting train loader.\")\n    return self._train_loader\n\n  def val_dataloader(self):\n    if self._valid_loader is None:\n      raise RuntimeError(\"DataModule setup() must run before requesting valid loader.\")\n    return self._valid_loader\n</code></pre>"},{"location":"reference/data/datamodule/#discrete_diffusion.data.datamodule.DiscreteDiffusionDataModule.__init__","title":"<code>__init__(config, tokenizer, *, skip_train=False, skip_valid=False, valid_seed=None)</code>","text":"<p>Initialize the DataModule.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>Hydra configuration object.</p> required <code>tokenizer</code> <p>Tokenizer instance.</p> required <code>skip_train</code> <code>bool</code> <p>Whether to skip creating the training loader.</p> <code>False</code> <code>skip_valid</code> <code>bool</code> <p>Whether to skip creating the validation loader.</p> <code>False</code> <code>valid_seed</code> <code>Optional[int]</code> <p>Optional seed for validation set shuffling.</p> <code>None</code> Source code in <code>src/discrete_diffusion/data/datamodule.py</code> <pre><code>def __init__(self,\n             config,\n             tokenizer,\n             *,\n             skip_train: bool = False,\n             skip_valid: bool = False,\n             valid_seed: Optional[int] = None):\n  \"\"\"Initialize the DataModule.\n\n  Args:\n      config: Hydra configuration object.\n      tokenizer: Tokenizer instance.\n      skip_train: Whether to skip creating the training loader.\n      skip_valid: Whether to skip creating the validation loader.\n      valid_seed: Optional seed for validation set shuffling.\n  \"\"\"\n  super().__init__()\n  self.config = config\n  self.tokenizer = tokenizer\n  self.skip_train = skip_train\n  self.skip_valid = skip_valid\n  self.valid_seed = valid_seed\n  self._train_loader = None\n  self._valid_loader = None\n</code></pre>"},{"location":"reference/data/datamodule/#discrete_diffusion.data.datamodule.DiscreteDiffusionDataModule.setup","title":"<code>setup(stage=None)</code>","text":"<p>Set up datasets for the given stage.</p> <p>Handles distributed data loading synchronization to ensure valid/test sets are consistent across ranks.</p> Source code in <code>src/discrete_diffusion/data/datamodule.py</code> <pre><code>def setup(self, stage: Optional[str] = None):\n  \"\"\"Set up datasets for the given stage.\n\n  Handles distributed data loading synchronization to ensure valid/test sets\n  are consistent across ranks.\n  \"\"\"\n  if stage not in (None, \"fit\", \"validate\"):\n    return\n  if self._train_loader is not None or self._valid_loader is not None:\n    return\n\n  trainer = getattr(self, \"trainer\", None)\n  strategy = getattr(trainer, \"strategy\", None) if trainer else None\n  barrier = getattr(strategy, \"barrier\", None) if strategy else None\n  is_rank_zero = bool(getattr(trainer, \"is_global_zero\", True))\n\n  if barrier is not None:\n    if is_rank_zero:\n      self._train_loader, self._valid_loader = self._build_loaders()\n    barrier()\n    if not is_rank_zero:\n      self._train_loader, self._valid_loader = self._build_loaders()\n    barrier()\n  else:\n    self._train_loader, self._valid_loader = self._build_loaders()\n</code></pre>"},{"location":"reference/data/datasets/","title":"Datasets","text":""},{"location":"reference/data/datasets/#discrete_diffusion.data.datasets","title":"<code>discrete_diffusion.data.datasets</code>","text":"<p>Specialized dataset builders re-used in the discrete diffusion loader.</p>"},{"location":"reference/data/datasets/#discrete_diffusion.data.datasets.get_text8_dataset","title":"<code>get_text8_dataset(cache_dir, max_seq_length=256, drop_last=True, crop_train=False)</code>","text":"<p>Adapted from D3PM text datasets.</p> Source code in <code>src/discrete_diffusion/data/datasets.py</code> <pre><code>def get_text8_dataset(cache_dir, max_seq_length=256, drop_last=True,\n                      crop_train=False):\n  \"\"\"Adapted from D3PM text datasets.\"\"\"\n  url = 'http://mattmahoney.net/dc/text8.zip'\n  cache_dir = f'{cache_dir}/text8' if not crop_train else f'{cache_dir}/text8-crop-train'\n  split_names = ['train', 'validation', 'test']\n  if not all([\n    utils.fsspec_exists(os.path.join(cache_dir, split))\n    for split in split_names\n  ]):\n    raw_cache_dir = os.path.join(cache_dir, 'raw_data')\n    if not all([\n      utils.fsspec_exists(\n        os.path.join(raw_cache_dir, f'text8.{split}.txt'))\n      for split in split_names\n    ]):\n      if not utils.fsspec_exists(os.path.join(raw_cache_dir, 'text8.zip')):\n        utils.fsspec_mkdirs(raw_cache_dir, exist_ok=True)\n        LOGGER.info('Downloading text8 from URL %s.', url)\n        with (urllib.request.urlopen(url) as in_stream,\n              open(os.path.join(raw_cache_dir, 'text8.zip'),\n                   'wb') as out_file):\n          shutil.copyfileobj(in_stream, out_file)\n      with fsspec.open(\n        os.path.join(raw_cache_dir, 'text8.zip'),\n        'rb') as f:\n        rawdata = zipfile.ZipFile(f).read('text8').decode('utf-8')\n      splits = {\n        'train': rawdata[:90000000],\n        'validation': rawdata[90000000: 95000000],\n        'test': rawdata[95000000:],\n      }\n      for split, data in splits.items():\n        _path = os.path.join(raw_cache_dir,\n                             f'text8.{split}.txt')\n        with fsspec.open(_path, 'w') as f:\n          f.write(data)\n    else:\n      splits = {}\n      for split in split_names:\n        _path = os.path.join(raw_cache_dir,\n                             f'text8.{split}.txt')\n        with fsspec.open(_path, 'r') as f:\n          splits[split] = f.read()\n    def chunks(lst, n):\n      for i in range(0, len(lst), n):\n        yield lst[i:i + n]\n    dataset_dict = {}\n    for k, v in splits.items():\n      chunk_size = 2 * max_seq_length if (k == 'train' and crop_train) else max_seq_length\n      text = list(chunks(v, chunk_size))\n      if drop_last and len(text[-1]) &lt; chunk_size:\n        text = text[:-1]\n      dataset_dict[k] = datasets.Dataset.from_dict({'text': text})\n    dataset = datasets.DatasetDict(dataset_dict)\n    dataset.save_to_disk(cache_dir)\n  else:\n    dataset = datasets.load_from_disk(cache_dir)\n  return dataset\n</code></pre>"},{"location":"reference/data/flex_chunking/","title":"Flex Chunking","text":""},{"location":"reference/data/flex_chunking/#discrete_diffusion.data.flex_chunking","title":"<code>discrete_diffusion.data.flex_chunking</code>","text":"<p>FlexMDM-style recursive chunking utilities.</p> <p>This module mirrors the delimiter-aware splitting logic that FlexMDM uses for OpenWebText preprocessing so that the src/ loader can reproduce the same document boundaries without re-implementing the entire dataset stack.</p>"},{"location":"reference/data/flex_chunking/#discrete_diffusion.data.flex_chunking.chunk_documents","title":"<code>chunk_documents(tokenizer, texts, max_length, delimiter_tokens, *, add_special_tokens=False)</code>","text":"<p>Tokenize <code>texts</code> and split them into padded <code>max_length</code> chunks.</p> <p>Returns a HuggingFace-ready dict with <code>input_ids</code>, <code>attention_mask</code>, <code>token_type_ids</code>, and the pre-padding <code>length</code> for each produced chunk.</p> Source code in <code>src/discrete_diffusion/data/flex_chunking.py</code> <pre><code>def chunk_documents(tokenizer: PreTrainedTokenizerBase,\n                    texts: Iterable[str],\n                    max_length: int,\n                    delimiter_tokens: Sequence[int],\n                    *,\n                    add_special_tokens: bool = False) -&gt; dict:\n  \"\"\"Tokenize ``texts`` and split them into padded ``max_length`` chunks.\n\n  Returns a HuggingFace-ready dict with ``input_ids``, ``attention_mask``,\n  ``token_type_ids``, and the pre-padding ``length`` for each produced chunk.\n  \"\"\"\n\n  pad_token = tokenizer.pad_token_id\n  if pad_token is None:\n    raise ValueError(\"Tokenizer must define a pad_token when using chunk_documents().\")\n\n  input_ids: List[List[int]] = []\n  attn_masks: List[List[int]] = []\n  token_type_ids: List[List[int]] = []\n  lengths: List[int] = []\n\n  for text in texts:\n    token_ids = tokenizer.encode(text, add_special_tokens=add_special_tokens)\n    chunks = recursive_split(token_ids, max_length, delimiter_tokens)\n    for chunk in chunks:\n      if len(chunk) &gt; max_length:\n        raise ValueError(\"Chunk size exceeded max_length; recursive_split should prevent this.\")\n      pad_len = max_length - len(chunk)\n      padded_chunk = list(chunk) + [pad_token] * pad_len\n      mask = [1] * len(chunk) + [0] * pad_len\n      input_ids.append(padded_chunk)\n      attn_masks.append(mask)\n      token_type_ids.append([0] * max_length)\n      lengths.append(len(chunk))\n\n  return {\n      \"input_ids\": input_ids,\n      \"attention_mask\": attn_masks,\n      \"token_type_ids\": token_type_ids,\n      \"length\": lengths,\n  }\n</code></pre>"},{"location":"reference/data/flex_chunking/#discrete_diffusion.data.flex_chunking.find_delimiter_positions","title":"<code>find_delimiter_positions(tokens, delimiter_tokens)</code>","text":"<p>Return all start indices where the delimiter occurs inside <code>tokens</code>.</p> Source code in <code>src/discrete_diffusion/data/flex_chunking.py</code> <pre><code>def find_delimiter_positions(tokens: Sequence[int], delimiter_tokens: Sequence[int]) -&gt; List[int]:\n  \"\"\"Return all start indices where the delimiter occurs inside ``tokens``.\"\"\"\n  if not delimiter_tokens:\n    return []\n  matches: List[int] = []\n  window = len(delimiter_tokens)\n  needle = list(delimiter_tokens)\n  for idx in range(len(tokens) - window + 1):\n    if tokens[idx : idx + window] == needle:\n      matches.append(idx)\n  return matches\n</code></pre>"},{"location":"reference/data/flex_chunking/#discrete_diffusion.data.flex_chunking.recursive_split","title":"<code>recursive_split(tokens, max_length, delimiter_tokens)</code>","text":"<p>Recursively split <code>tokens</code> into <code>max_length</code> chunks along delimiters.</p> Source code in <code>src/discrete_diffusion/data/flex_chunking.py</code> <pre><code>def recursive_split(tokens: Sequence[int], max_length: int, delimiter_tokens: Sequence[int]) -&gt; List[List[int]]:\n  \"\"\"Recursively split ``tokens`` into ``max_length`` chunks along delimiters.\"\"\"\n  if len(tokens) &lt;= max_length:\n    return [list(tokens)]\n\n  candidates = find_delimiter_positions(tokens, delimiter_tokens)\n  if not candidates:\n    return [list(tokens[i : i + max_length]) for i in range(0, len(tokens), max_length)]\n\n  midpoint = len(tokens) // 2\n  split_point = min(candidates, key=lambda pos: abs(pos - midpoint))\n  delimiter_len = len(delimiter_tokens)\n\n  left = recursive_split(tokens[:split_point], max_length, delimiter_tokens)\n  right = recursive_split(tokens[split_point + delimiter_len :], max_length, delimiter_tokens)\n  return left + right\n</code></pre>"},{"location":"reference/data/loaders/","title":"Loaders","text":""},{"location":"reference/data/loaders/#discrete_diffusion.data.loaders","title":"<code>discrete_diffusion.data.loaders</code>","text":"<p>Top-level loader API for discrete diffusion training.</p>"},{"location":"reference/data/processing/","title":"Processing","text":""},{"location":"reference/data/processing/#discrete_diffusion.data.processing","title":"<code>discrete_diffusion.data.processing</code>","text":"<p>Text processing helpers used when grouping tokenized data.</p>"},{"location":"reference/data/tokenizers/","title":"Tokenizers","text":""},{"location":"reference/data/tokenizers/#discrete_diffusion.data.tokenizers","title":"<code>discrete_diffusion.data.tokenizers</code>","text":"<p>Custom tokenizer implementations used by discrete diffusion datasets.</p>"},{"location":"reference/data/tokenizers/#discrete_diffusion.data.tokenizers.SyntheticTokenizer","title":"<code>SyntheticTokenizer</code>","text":"<p>               Bases: <code>PreTrainedTokenizer</code></p> <p>Simple synthetic tokenizer for deterministic experiments.</p> Source code in <code>src/discrete_diffusion/data/tokenizers.py</code> <pre><code>class SyntheticTokenizer(transformers.PreTrainedTokenizer):\n  \"\"\"Simple synthetic tokenizer for deterministic experiments.\"\"\"\n\n  def __init__(\n    self,\n    vocab_size,\n    bos_token=\"[BOS]\",\n    eos_token=\"[EOS]\",\n    sep_token=None,\n    cls_token=None,\n    pad_token=None,\n    mask_token=None,\n    unk_token=None,\n    **kwargs):\n\n    self.tokens = []\n    for i in range(vocab_size - 2):\n      self.tokens.append(str(i) + \" \")\n    self._vocab_str_to_int = {\n      '[BOS]': vocab_size - 2,\n      '[EOS]': vocab_size - 1,\n      **{ch: i for i, ch in enumerate(self.tokens)}}\n    self._vocab_int_to_str = {\n      v: k for k, v in self._vocab_str_to_int.items()}\n    super().__init__(\n      bos_token=bos_token,\n      eos_token=eos_token,\n      sep_token=sep_token,\n      cls_token=cls_token,\n      pad_token=pad_token,\n      mask_token=mask_token,\n      unk_token=unk_token,\n      **kwargs)\n\n  @property\n  def vocab_size(self) -&gt; int:\n    return len(self._vocab_str_to_int)\n\n  def _tokenize(self, text: str, **kwargs) -&gt; List[str]:\n    return list(text.lower())\n\n  def _convert_token_to_id(self, token: str) -&gt; int:\n    return self._vocab_str_to_int.get(\n      token, self._vocab_str_to_int['[UNK]'])\n\n  def _convert_id_to_token(self, index: int) -&gt; str:\n    return self._vocab_int_to_str[index]\n\n  def convert_tokens_to_string(self, tokens):\n    return ''.join(tokens)\n\n  def get_vocab(self) -&gt; Dict[str, int]:\n    return self._vocab_str_to_int\n</code></pre>"},{"location":"reference/evaluations/generative_ppl/","title":"Generative Perplexity","text":""},{"location":"reference/evaluations/generative_ppl/#discrete_diffusion.evaluations.generative_ppl","title":"<code>discrete_diffusion.evaluations.generative_ppl</code>","text":"<p>Standalone Generative Perplexity evaluation.</p> <p>Loads generated samples and evaluates NLL/PPL with a chosen eval LM.</p> <p>Supported sample formats: - .pt: torch.Tensor of token ids (shape [N, T] or [N, 1, T]) - .npz: numpy array under key 'samples' (shape [N, T]) - .json: contains base64-encoded numpy array under key 'np_tokens_b64'</p> <p>This script decodes using <code>model_tokenizer</code> and (optionally) retokenizes with the eval model's tokenizer before computing loss.</p>"},{"location":"reference/evaluations/harness/","title":"Evaluation Harness","text":""},{"location":"reference/evaluations/harness/#discrete_diffusion.evaluations.mgm_eval_harness","title":"<code>discrete_diffusion.evaluations.mgm_eval_harness</code>","text":""},{"location":"reference/evaluations/metrics/","title":"Metrics","text":""},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics","title":"<code>discrete_diffusion.evaluations.metrics</code>","text":""},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.BD3Metrics","title":"<code>BD3Metrics</code>","text":"<p>               Bases: <code>Metrics</code></p> <p>Extension of Metrics with BD3-specific variance tracking.</p> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>class BD3Metrics(Metrics):\n  \"\"\"Extension of Metrics with BD3-specific variance tracking.\"\"\"\n\n  def __init__(self, config) -&gt; None:\n    super().__init__()\n    self.config = config\n    self.block_size = getattr(config, 'block_size', config.model.length)\n    self.nfes = NFEs()\n    self.gen_entropy = NLL()\n    self.gen_nfes: List[float] = []\n    self.gen_entropies: List[float] = []\n    self.gen_lengths: List[int] = []\n\n    self.sampling_eps = config.training.sampling_eps\n    self.clip_search_delta = getattr(config.algo, 'clip_search_delta', None)\n    self.valid_vars: Dict[Tuple[float, float], List[torch.Tensor]] = {\n      (self.sampling_eps, 1.0): []\n    }\n    if getattr(config.algo, 'var_min', None):\n      self.init_valid_vars()\n\n  def init_valid_vars(self):\n    eps = self.sampling_eps\n    if self.block_size &gt; 1:\n      self.valid_vars = {(eps, 1): []}\n      for width in self.config.algo.clip_search_widths:\n        for i in torch.arange(0, 1 - width + self.clip_search_delta,\n                              self.clip_search_delta):\n          eps_min = torch.clamp(i, min=self.sampling_eps).item()\n          eps_max = torch.clamp(i + width, min=self.sampling_eps).item()\n          self.valid_vars[(eps_min, eps_max)] = []\n    else:\n      self.valid_vars = {\n        (eps, 1): [],\n        (1, 1): []\n      }\n\n  def update_train(self,\n                   nll_sum: torch.Tensor,\n                   num_tokens: torch.Tensor):\n    self.train_nlls.update(nll_sum, num_tokens)\n\n  def update_valid(self,\n                   nll_sum: torch.Tensor,\n                   num_tokens: torch.Tensor):\n    self.valid_nlls.update(nll_sum, num_tokens)\n\n  def to(self, *args, **kwargs):\n    super().to(*args, **kwargs)\n    self.nfes = self.nfes.to(*args, **kwargs)\n    self.gen_entropy = self.gen_entropy.to(*args, **kwargs)\n\n  def reset(self):\n    super().reset()\n    self.gen_nfes, self.gen_entropies, self.gen_lengths = [], [], []\n    self.nfes.reset()\n    self.gen_entropy.reset()\n    if getattr(self.config.algo, 'var_min', None):\n      self.init_valid_vars()\n\n  @torch.no_grad()\n  def record_entropy(self, tokens):\n    for sample in tokens:\n      entropy = _token_entropy(sample)\n      self._record_entropy_value(entropy)\n\n  def _record_entropy_value(self, entropy: float) -&gt; None:\n    self.sample_entropy.update(entropy)\n    self.gen_entropies.append(entropy)\n    self.gen_entropy.update(entropy, 1)\n</code></pre>"},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.BPD","title":"<code>BPD</code>","text":"<p>               Bases: <code>NLL</code></p> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>class BPD(NLL):\n  def compute(self) -&gt; torch.Tensor:\n    \"\"\"Computes the bits per dimension.\n\n    Returns:\n      bpd\n    \"\"\"\n    return self.mean_value / self.weight / LOG2\n</code></pre>"},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.BPD.compute","title":"<code>compute()</code>","text":"<p>Computes the bits per dimension.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>bpd</p> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>def compute(self) -&gt; torch.Tensor:\n  \"\"\"Computes the bits per dimension.\n\n  Returns:\n    bpd\n  \"\"\"\n  return self.mean_value / self.weight / LOG2\n</code></pre>"},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.NFEs","title":"<code>NFEs</code>","text":"<p>               Bases: <code>MeanMetric</code></p> <p>Average number of function evaluations per sample.</p> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>class NFEs(torchmetrics.aggregation.MeanMetric):\n  \"\"\"Average number of function evaluations per sample.\"\"\"\n</code></pre>"},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.NLL","title":"<code>NLL</code>","text":"<p>               Bases: <code>MeanMetric</code></p> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>class NLL(torchmetrics.aggregation.MeanMetric):\n  def update(self,\n             value: Value,\n             weight: Value = 1.0) -&gt; None:\n    \"\"\"Update state with data.\n\n    Args:\n      value: Either a float or tensor containing data.\n        Additional tensor dimensions will be flattened\n      weight: Either a float or tensor containing weights\n        for calculating the average. Shape of weight should\n        be able to broadcast with the shape of `value`.\n        Default to `1.0` corresponding to simple harmonic\n        average.\n    \"\"\"\n    # broadcast weight to value shape\n    if not isinstance(value, torch.Tensor):\n      value = torch.as_tensor(value,\n                              dtype=self.dtype,\n                              device=self.device)\n    else:\n      value = value.to(dtype=self.dtype, device=self.device)\n\n    if (weight is not None and\n        not isinstance(weight, torch.Tensor)):\n      weight = torch.as_tensor(weight,\n                               dtype=self.dtype,\n                               device=self.device)\n    else:\n      weight = weight.to(dtype=self.dtype, device=self.device)\n\n    # Handle edge case where torch.compile infers scalar value but sees tensor inputs\n    if value.ndim == 0 and weight.ndim &gt; 0:\n      weight = weight.squeeze()\n    if value.ndim &gt; 0:\n      weight = torch.broadcast_to(weight, value.shape)\n\n    if value.numel() == 0:\n      return\n    self.mean_value += value.sum()\n    self.weight += weight.sum()\n</code></pre>"},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.NLL.update","title":"<code>update(value, weight=1.0)</code>","text":"<p>Update state with data.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Value</code> <p>Either a float or tensor containing data. Additional tensor dimensions will be flattened</p> required <code>weight</code> <code>Value</code> <p>Either a float or tensor containing weights for calculating the average. Shape of weight should be able to broadcast with the shape of <code>value</code>. Default to <code>1.0</code> corresponding to simple harmonic average.</p> <code>1.0</code> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>def update(self,\n           value: Value,\n           weight: Value = 1.0) -&gt; None:\n  \"\"\"Update state with data.\n\n  Args:\n    value: Either a float or tensor containing data.\n      Additional tensor dimensions will be flattened\n    weight: Either a float or tensor containing weights\n      for calculating the average. Shape of weight should\n      be able to broadcast with the shape of `value`.\n      Default to `1.0` corresponding to simple harmonic\n      average.\n  \"\"\"\n  # broadcast weight to value shape\n  if not isinstance(value, torch.Tensor):\n    value = torch.as_tensor(value,\n                            dtype=self.dtype,\n                            device=self.device)\n  else:\n    value = value.to(dtype=self.dtype, device=self.device)\n\n  if (weight is not None and\n      not isinstance(weight, torch.Tensor)):\n    weight = torch.as_tensor(weight,\n                             dtype=self.dtype,\n                             device=self.device)\n  else:\n    weight = weight.to(dtype=self.dtype, device=self.device)\n\n  # Handle edge case where torch.compile infers scalar value but sees tensor inputs\n  if value.ndim == 0 and weight.ndim &gt; 0:\n    weight = weight.squeeze()\n  if value.ndim &gt; 0:\n    weight = torch.broadcast_to(weight, value.shape)\n\n  if value.numel() == 0:\n    return\n  self.mean_value += value.sum()\n  self.weight += weight.sum()\n</code></pre>"},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.Perplexity","title":"<code>Perplexity</code>","text":"<p>               Bases: <code>NLL</code></p> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>class Perplexity(NLL):\n  def compute(self) -&gt; torch.Tensor:\n    \"\"\"Computes the Perplexity.\n\n    Returns:\n     Perplexity\n    \"\"\"\n    return torch.exp(self.mean_value / self.weight)\n</code></pre>"},{"location":"reference/evaluations/metrics/#discrete_diffusion.evaluations.metrics.Perplexity.compute","title":"<code>compute()</code>","text":"<p>Computes the Perplexity.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Perplexity</p> Source code in <code>src/discrete_diffusion/evaluations/metrics.py</code> <pre><code>def compute(self) -&gt; torch.Tensor:\n  \"\"\"Computes the Perplexity.\n\n  Returns:\n   Perplexity\n  \"\"\"\n  return torch.exp(self.mean_value / self.weight)\n</code></pre>"},{"location":"reference/forward_process/absorbing/","title":"Absorbing Process","text":""},{"location":"reference/forward_process/absorbing/#discrete_diffusion.forward_process.absorbing","title":"<code>discrete_diffusion.forward_process.absorbing</code>","text":"<p>Absorbing-state forward processes.</p>"},{"location":"reference/forward_process/absorbing/#discrete_diffusion.forward_process.absorbing.AbsorbingForwardProcess","title":"<code>AbsorbingForwardProcess</code>","text":"<p>               Bases: <code>ForwardProcess</code></p> <p>Absorbing-state forward process.</p> <p>Replaces tokens with the mask token with probability <code>(1 - alpha_t)</code>. Returns the noised ids and the per-position mask probability <code>p_mask</code>.</p> Source code in <code>src/discrete_diffusion/forward_process/absorbing.py</code> <pre><code>class AbsorbingForwardProcess(ForwardProcess):\n  \"\"\"Absorbing-state forward process.\n\n  Replaces tokens with the mask token with probability `(1 - alpha_t)`.\n  Returns the noised ids and the per-position mask probability `p_mask`.\n  \"\"\"\n\n  def __init__(self, tokenizer, schedule: NoiseSchedule, name: str | None = None) -&gt; None:\n    super().__init__(tokenizer=tokenizer, schedule=schedule, name=name)\n    self.mask_id = _mask_token_id(tokenizer)\n\n  @torch.no_grad()\n  def forward(self, input_ids: torch.Tensor, t: torch.Tensor):\n    alpha_t = self.schedule.alpha_t(t).view(-1, 1)\n    p_mask = (1.0 - alpha_t).to(dtype=torch.float32)\n    move_mask = (torch.rand_like(input_ids, dtype=torch.float32) &lt; p_mask).to(torch.bool)\n    xt = torch.where(move_mask, torch.tensor(self.mask_id, device=input_ids.device, dtype=input_ids.dtype), input_ids)\n    return xt, p_mask\n</code></pre>"},{"location":"reference/forward_process/base/","title":"Base Process","text":""},{"location":"reference/forward_process/base/#discrete_diffusion.forward_process.base","title":"<code>discrete_diffusion.forward_process.base</code>","text":"<p>Base interface for discrete forward processes.</p> <p>Forward processes encapsulate tokenizer-specific details and apply a chosen noise schedule to produce noised latent variables <code>z_t</code> (or <code>x_t</code>).</p> <p>This module only defines the abstract interface; concrete implementations will be introduced separately.</p>"},{"location":"reference/forward_process/base/#discrete_diffusion.forward_process.base.ForwardProcess","title":"<code>ForwardProcess</code>","text":"<p>               Bases: <code>Module</code></p> <p>Abstract base class for discrete forward noising dynamics.</p> <p>Implementations should use <code>self.tokenizer</code> and <code>self.schedule</code> to compute noised states for given inputs and timesteps.</p> Source code in <code>src/discrete_diffusion/forward_process/base.py</code> <pre><code>class ForwardProcess(torch.nn.Module):\n  \"\"\"Abstract base class for discrete forward noising dynamics.\n\n  Implementations should use `self.tokenizer` and `self.schedule` to compute\n  noised states for given inputs and timesteps.\n  \"\"\"\n\n  def __init__(self, tokenizer, schedule: NoiseSchedule, name=None) -&gt; None:\n    super().__init__()\n    self.tokenizer = tokenizer\n    self.schedule = schedule\n    self.name = name\n\n  def forward(self, input_ids: torch.Tensor, t: torch.Tensor):  # pragma: no cover - abstract method\n    \"\"\"Return the noised tokens at time `t`.\n\n    Concrete classes may return additional tensors as needed (e.g.,\n    per-position `t` for blockwise sampling).\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/forward_process/base/#discrete_diffusion.forward_process.base.ForwardProcess.forward","title":"<code>forward(input_ids, t)</code>","text":"<p>Return the noised tokens at time <code>t</code>.</p> <p>Concrete classes may return additional tensors as needed (e.g., per-position <code>t</code> for blockwise sampling).</p> Source code in <code>src/discrete_diffusion/forward_process/base.py</code> <pre><code>def forward(self, input_ids: torch.Tensor, t: torch.Tensor):  # pragma: no cover - abstract method\n  \"\"\"Return the noised tokens at time `t`.\n\n  Concrete classes may return additional tensors as needed (e.g.,\n  per-position `t` for blockwise sampling).\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/forward_process/block_absorbing/","title":"Block Absorbing Process","text":""},{"location":"reference/forward_process/block_absorbing/#discrete_diffusion.forward_process.block_absorbing","title":"<code>discrete_diffusion.forward_process.block_absorbing</code>","text":"<p>Block-absorbing forward process.</p> <p>Minimal implementation: applies the absorbing process with a single shared time <code>t</code> across the entire sequence (i.e., one block == whole sequence). Returns <code>(masked_ids, p_mask, t_out)</code> where <code>t_out</code> is broadcast per-position.</p>"},{"location":"reference/forward_process/candi_hybrid/","title":"CANDI Hybrid Process","text":""},{"location":"reference/forward_process/candi_hybrid/#discrete_diffusion.forward_process.candi_hybrid","title":"<code>discrete_diffusion.forward_process.candi_hybrid</code>","text":"<p>Hybrid Noising process for CANDI.</p>"},{"location":"reference/forward_process/candi_hybrid/#discrete_diffusion.forward_process.candi_hybrid.HybridForwardCANDI","title":"<code>HybridForwardCANDI</code>","text":"<p>               Bases: <code>ForwardProcess</code></p> <p>Hybrid noising kernel for CANDI. https://arxiv.org/pdf/2510.22510 </p> <p>Selects positions with probability <code>(1 - alpha_t)</code> to add Gaussian noise, with variance sigma_t. Leaves others the same.</p> Source code in <code>src/discrete_diffusion/forward_process/candi_hybrid.py</code> <pre><code>class HybridForwardCANDI(ForwardProcess):\n    \"\"\"Hybrid noising kernel for CANDI.\n    https://arxiv.org/pdf/2510.22510 \n\n    Selects positions with probability `(1 - alpha_t)` to add Gaussian noise, with variance sigma_t.\n    Leaves others the same.\n\n    \"\"\"\n\n    def __init__(\n        self, tokenizer, schedule: NoiseSchedule, name: str | None = None\n    ) -&gt; None:\n        assert hasattr(schedule, \"r_t\") and hasattr(schedule, \"sigma_t\"), (\n            \"CANDI schedule must implement r_t and sigma_t methods.\"\n        )\n\n        super().__init__(tokenizer=tokenizer, schedule=schedule, name=name)\n        self.mask_id = _mask_token_id(tokenizer)\n        self.vocab_size = len(tokenizer)\n        self._corruption_vocab_size = len(tokenizer) + 1\n\n    def _discrete_noising(self, x, alpha_t):\n        \"\"\"Computes the noisy discrete sample.\"\"\"\n        p_mask = (1.0 - alpha_t).to(dtype=torch.float32)\n        move_indices = torch.rand(*x.shape, device=x.device) &lt; p_mask\n        uniform_tensor = torch.randint(0, self._corruption_vocab_size, x.shape, device=x.device)\n        xt = torch.where(move_indices, uniform_tensor, x)\n        return xt\n\n    @torch.no_grad()\n    def forward(self, input_ids: torch.Tensor, t: torch.Tensor):\n        \"\"\"Applies hybrid noising process to input_ids at time t. Implements Equation 11 of CANDI paper.\"\"\"\n        alpha_t = self.schedule.alpha_t(t).view(-1, 1)\n        dalpha_t = self.schedule.alpha_prime_t(t).view(-1, 1)\n        sigma_t = self.schedule.sigma_t(t).view(-1, 1, 1)\n\n        disc_xt = self._discrete_noising(input_ids, alpha_t)\n        reveal_mask = (disc_xt == input_ids).float()\n\n        X_0 = F.one_hot(input_ids, num_classes=self.vocab_size).to(input_ids.device)\n        X_t_prime = X_0 + torch.randn_like(X_0, dtype=torch.float32) * sigma_t\n        X_t = X_0 * reveal_mask.unsqueeze(-1) + X_t_prime * (1 - reveal_mask).unsqueeze(-1)\n\n        return {\n            \"xt\": X_t, \n            \"reveal_mask\": reveal_mask, \n            \"continuous_noise\": sigma_t.squeeze(), \n            \"discrete_noise\": (1 - alpha_t).squeeze(),\n            \"alpha_t\": alpha_t, \n            \"dalpha_t\": dalpha_t\n        }  \n</code></pre>"},{"location":"reference/forward_process/candi_hybrid/#discrete_diffusion.forward_process.candi_hybrid.HybridForwardCANDI.forward","title":"<code>forward(input_ids, t)</code>","text":"<p>Applies hybrid noising process to input_ids at time t. Implements Equation 11 of CANDI paper.</p> Source code in <code>src/discrete_diffusion/forward_process/candi_hybrid.py</code> <pre><code>@torch.no_grad()\ndef forward(self, input_ids: torch.Tensor, t: torch.Tensor):\n    \"\"\"Applies hybrid noising process to input_ids at time t. Implements Equation 11 of CANDI paper.\"\"\"\n    alpha_t = self.schedule.alpha_t(t).view(-1, 1)\n    dalpha_t = self.schedule.alpha_prime_t(t).view(-1, 1)\n    sigma_t = self.schedule.sigma_t(t).view(-1, 1, 1)\n\n    disc_xt = self._discrete_noising(input_ids, alpha_t)\n    reveal_mask = (disc_xt == input_ids).float()\n\n    X_0 = F.one_hot(input_ids, num_classes=self.vocab_size).to(input_ids.device)\n    X_t_prime = X_0 + torch.randn_like(X_0, dtype=torch.float32) * sigma_t\n    X_t = X_0 * reveal_mask.unsqueeze(-1) + X_t_prime * (1 - reveal_mask).unsqueeze(-1)\n\n    return {\n        \"xt\": X_t, \n        \"reveal_mask\": reveal_mask, \n        \"continuous_noise\": sigma_t.squeeze(), \n        \"discrete_noise\": (1 - alpha_t).squeeze(),\n        \"alpha_t\": alpha_t, \n        \"dalpha_t\": dalpha_t\n    }  \n</code></pre>"},{"location":"reference/forward_process/flexmdm/","title":"FlexMDM Interpolant","text":""},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm","title":"<code>discrete_diffusion.forward_process.flexmdm</code>","text":"<p>FlexMDM Joint Interpolant for Any-Order Mask Insertion Flow.</p> <p>This module implements the forward process for FlexMDM's any-order algorithm, which jointly models insertion (length) and masking (content) processes.</p>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.FlexMDMForwardProcess","title":"<code>FlexMDMForwardProcess</code>","text":"<p>               Bases: <code>ForwardProcess</code></p> <p>Interpolant for any-order mask insertion flow.</p> <p>This implements a joint process where tokens are both inserted (affecting length) and masked (affecting content). The insertion and unmasking processes are governed by separate noise schedules.</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>class FlexMDMForwardProcess(ForwardProcess):\n  \"\"\"Interpolant for any-order mask insertion flow.\n\n  This implements a joint process where tokens are both inserted (affecting\n  length) and masked (affecting content). The insertion and unmasking\n  processes are governed by separate noise schedules.\n  \"\"\"\n\n  def __init__(\n    self,\n    tokenizer,\n    insertion_schedule: ScheduleProtocol,\n    unmask_schedule: ScheduleProtocol,\n    max_length: int,\n    pad_token: int,\n    name: str | None = None,\n  ):\n    \"\"\"Initialize any-order interpolant.\n\n    Args:\n      tokenizer: Tokenizer instance\n      insertion_schedule: Schedule for insertion process\n      unmask_schedule: Schedule for unmasking process\n      max_length: Maximum sequence length\n      pad_token: ID of padding token\n      name: Optional name for the process\n    \"\"\"\n    super().__init__(tokenizer=tokenizer, schedule=None, name=name)\n    self.insertion_schedule = insertion_schedule\n    self.unmask_schedule = unmask_schedule\n    self.max_length = max_length\n    self.pad_token = pad_token\n    self.mask_token = _mask_token_id(tokenizer)\n    self.vocab_size = _effective_vocab_size(tokenizer)\n\n  def hitting_time(self, t: Tensor, x1: Tensor) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Sample hitting times for insertion and unmasking.\n\n    Insertion time is sampled uniformly, then unmasking time is sampled\n    uniformly in [insertion_time, 1].\n\n    Args:\n      t: Current time [B]\n      x1: Clean sequences [B, L]\n\n    Returns:\n      Tuple of (insertion_time [B, L], unmasking_time [B, L])\n    \"\"\"\n    B, L = x1.shape\n    eps = 1e-6\n\n    insert_time = self.insertion_schedule.sample((B, L), device=x1.device)\n    insert_time = eps + (1 - eps) * insert_time  # Ensure not exactly 0\n    unmask_time = self.unmask_schedule.sample_truncated(\n      insert_time, (B, L), device=x1.device\n    )\n\n    return insert_time, unmask_time\n\n  def elbo_weight(self, t: Tensor, x1: Tensor):\n    \"\"\"Compute ELBO loss weights using rate scale factors.\n\n    Args:\n      t: Time values [B]\n      x1: Clean sequences [B, L]\n\n    Returns:\n      Tuple of (unmask_weight [B, L], insert_weight [B, L+1])\n    \"\"\"\n    insert_weight = self.insertion_schedule.rate_scale_factor(t)\n    insert_weight = insert_weight[:, None].expand(-1, x1.shape[1] + 1)\n\n    unmask_weight = self.unmask_schedule.rate_scale_factor(t)\n    unmask_weight = unmask_weight.unsqueeze(1).expand(-1, x1.shape[1])\n\n    return unmask_weight, insert_weight\n\n  def to_actual_rate(\n    self, xt: Tensor, prediction: ModelPrediction, t: Tensor\n  ) -&gt; Rate:\n    \"\"\"Convert model prediction to actual sampling rates.\n\n    Args:\n      xt: Current noised sequence [B, L]\n      prediction: Model output\n      t: Time values [B]\n\n    Returns:\n      Rate object with unmask and length rates\n    \"\"\"\n    token_posterior = F.softmax(prediction.token_logits, dim=-1)  # [B, L, V]\n    unmask_rate = token_posterior * self.unmask_schedule.rate_scale_factor(\n      t\n    ).view(-1, 1, 1)\n\n    length_rate = (\n      prediction.expected_gaps\n      * self.insertion_schedule.rate_scale_factor(t).view(-1, 1)\n    )\n\n    return Rate(\n      unmask_rate=unmask_rate,  # [B, L, V]\n      length_rate=length_rate,  # [B, L+1]\n    )\n\n  def sample_interpolant(\n    self, t: Tensor, x1: Tensor\n  ) -&gt; JointInterpolantResult:\n    \"\"\"Sample interpolant by applying deletion and masking.\n\n    Tokens are deleted if t &lt; insertion_time, masked if\n    insertion_time &lt;= t &lt; unmasking_time, and clean otherwise.\n\n    Args:\n      t: Time values [B]\n      x1: Clean sequences [B, L]\n\n    Returns:\n      JointInterpolantResult with noised sequence and metadata\n    \"\"\"\n    # Sample hitting times for each token\n    insertion_time, unmasking_time = self.hitting_time(t, x1)\n\n    # Determine token states\n    clean_tokens = x1.ne(self.pad_token)\n    deleted_tokens = clean_tokens &amp; (t[:, None] &lt; insertion_time)\n    masked_tokens = (\n      clean_tokens\n      &amp; (t[:, None] &gt;= insertion_time)\n      &amp; (t[:, None] &lt; unmasking_time)\n    )\n\n    # Apply transformations\n    xt = torch.where(\n      deleted_tokens,\n      self.pad_token,  # Deletion -&gt; pad token\n      torch.where(\n        masked_tokens,\n        self.mask_token,  # Masking -&gt; mask token\n        x1,  # Otherwise clean\n      ),\n    )\n\n    # Sort to move padding to the end, track indices\n    st = xt.ne(self.pad_token).argsort(dim=1, descending=True, stable=True)\n    xt = torch.gather(xt, 1, st)\n    st[xt == self.pad_token] = 0\n\n    return JointInterpolantResult(\n      xt=xt,\n      st=st,\n      _x1=x1,\n      _pad_token=self.pad_token,\n      _mask_token=self.mask_token,\n    )\n\n  @torch.no_grad()\n  def forward(self, input_ids: torch.Tensor, t: torch.Tensor):\n    \"\"\"Return the noised tokens at time `t`.\n\n    Returns:\n      xt: Noised sequence [B, L]\n      result: JointInterpolantResult containing metadata\n    \"\"\"\n    result = self.sample_interpolant(t, input_ids)\n    return result.xt, result\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.FlexMDMForwardProcess.__init__","title":"<code>__init__(tokenizer, insertion_schedule, unmask_schedule, max_length, pad_token, name=None)</code>","text":"<p>Initialize any-order interpolant.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <p>Tokenizer instance</p> required <code>insertion_schedule</code> <code>ScheduleProtocol</code> <p>Schedule for insertion process</p> required <code>unmask_schedule</code> <code>ScheduleProtocol</code> <p>Schedule for unmasking process</p> required <code>max_length</code> <code>int</code> <p>Maximum sequence length</p> required <code>pad_token</code> <code>int</code> <p>ID of padding token</p> required <code>name</code> <code>str | None</code> <p>Optional name for the process</p> <code>None</code> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>def __init__(\n  self,\n  tokenizer,\n  insertion_schedule: ScheduleProtocol,\n  unmask_schedule: ScheduleProtocol,\n  max_length: int,\n  pad_token: int,\n  name: str | None = None,\n):\n  \"\"\"Initialize any-order interpolant.\n\n  Args:\n    tokenizer: Tokenizer instance\n    insertion_schedule: Schedule for insertion process\n    unmask_schedule: Schedule for unmasking process\n    max_length: Maximum sequence length\n    pad_token: ID of padding token\n    name: Optional name for the process\n  \"\"\"\n  super().__init__(tokenizer=tokenizer, schedule=None, name=name)\n  self.insertion_schedule = insertion_schedule\n  self.unmask_schedule = unmask_schedule\n  self.max_length = max_length\n  self.pad_token = pad_token\n  self.mask_token = _mask_token_id(tokenizer)\n  self.vocab_size = _effective_vocab_size(tokenizer)\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.FlexMDMForwardProcess.elbo_weight","title":"<code>elbo_weight(t, x1)</code>","text":"<p>Compute ELBO loss weights using rate scale factors.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time values [B]</p> required <code>x1</code> <code>Tensor</code> <p>Clean sequences [B, L]</p> required <p>Returns:</p> Type Description <p>Tuple of (unmask_weight [B, L], insert_weight [B, L+1])</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>def elbo_weight(self, t: Tensor, x1: Tensor):\n  \"\"\"Compute ELBO loss weights using rate scale factors.\n\n  Args:\n    t: Time values [B]\n    x1: Clean sequences [B, L]\n\n  Returns:\n    Tuple of (unmask_weight [B, L], insert_weight [B, L+1])\n  \"\"\"\n  insert_weight = self.insertion_schedule.rate_scale_factor(t)\n  insert_weight = insert_weight[:, None].expand(-1, x1.shape[1] + 1)\n\n  unmask_weight = self.unmask_schedule.rate_scale_factor(t)\n  unmask_weight = unmask_weight.unsqueeze(1).expand(-1, x1.shape[1])\n\n  return unmask_weight, insert_weight\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.FlexMDMForwardProcess.forward","title":"<code>forward(input_ids, t)</code>","text":"<p>Return the noised tokens at time <code>t</code>.</p> <p>Returns:</p> Name Type Description <code>xt</code> <p>Noised sequence [B, L]</p> <code>result</code> <p>JointInterpolantResult containing metadata</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>@torch.no_grad()\ndef forward(self, input_ids: torch.Tensor, t: torch.Tensor):\n  \"\"\"Return the noised tokens at time `t`.\n\n  Returns:\n    xt: Noised sequence [B, L]\n    result: JointInterpolantResult containing metadata\n  \"\"\"\n  result = self.sample_interpolant(t, input_ids)\n  return result.xt, result\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.FlexMDMForwardProcess.hitting_time","title":"<code>hitting_time(t, x1)</code>","text":"<p>Sample hitting times for insertion and unmasking.</p> <p>Insertion time is sampled uniformly, then unmasking time is sampled uniformly in [insertion_time, 1].</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Current time [B]</p> required <code>x1</code> <code>Tensor</code> <p>Clean sequences [B, L]</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>Tuple of (insertion_time [B, L], unmasking_time [B, L])</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>def hitting_time(self, t: Tensor, x1: Tensor) -&gt; tuple[Tensor, Tensor]:\n  \"\"\"Sample hitting times for insertion and unmasking.\n\n  Insertion time is sampled uniformly, then unmasking time is sampled\n  uniformly in [insertion_time, 1].\n\n  Args:\n    t: Current time [B]\n    x1: Clean sequences [B, L]\n\n  Returns:\n    Tuple of (insertion_time [B, L], unmasking_time [B, L])\n  \"\"\"\n  B, L = x1.shape\n  eps = 1e-6\n\n  insert_time = self.insertion_schedule.sample((B, L), device=x1.device)\n  insert_time = eps + (1 - eps) * insert_time  # Ensure not exactly 0\n  unmask_time = self.unmask_schedule.sample_truncated(\n    insert_time, (B, L), device=x1.device\n  )\n\n  return insert_time, unmask_time\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.FlexMDMForwardProcess.sample_interpolant","title":"<code>sample_interpolant(t, x1)</code>","text":"<p>Sample interpolant by applying deletion and masking.</p> <p>Tokens are deleted if t &lt; insertion_time, masked if insertion_time &lt;= t &lt; unmasking_time, and clean otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time values [B]</p> required <code>x1</code> <code>Tensor</code> <p>Clean sequences [B, L]</p> required <p>Returns:</p> Type Description <code>JointInterpolantResult</code> <p>JointInterpolantResult with noised sequence and metadata</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>def sample_interpolant(\n  self, t: Tensor, x1: Tensor\n) -&gt; JointInterpolantResult:\n  \"\"\"Sample interpolant by applying deletion and masking.\n\n  Tokens are deleted if t &lt; insertion_time, masked if\n  insertion_time &lt;= t &lt; unmasking_time, and clean otherwise.\n\n  Args:\n    t: Time values [B]\n    x1: Clean sequences [B, L]\n\n  Returns:\n    JointInterpolantResult with noised sequence and metadata\n  \"\"\"\n  # Sample hitting times for each token\n  insertion_time, unmasking_time = self.hitting_time(t, x1)\n\n  # Determine token states\n  clean_tokens = x1.ne(self.pad_token)\n  deleted_tokens = clean_tokens &amp; (t[:, None] &lt; insertion_time)\n  masked_tokens = (\n    clean_tokens\n    &amp; (t[:, None] &gt;= insertion_time)\n    &amp; (t[:, None] &lt; unmasking_time)\n  )\n\n  # Apply transformations\n  xt = torch.where(\n    deleted_tokens,\n    self.pad_token,  # Deletion -&gt; pad token\n    torch.where(\n      masked_tokens,\n      self.mask_token,  # Masking -&gt; mask token\n      x1,  # Otherwise clean\n    ),\n  )\n\n  # Sort to move padding to the end, track indices\n  st = xt.ne(self.pad_token).argsort(dim=1, descending=True, stable=True)\n  xt = torch.gather(xt, 1, st)\n  st[xt == self.pad_token] = 0\n\n  return JointInterpolantResult(\n    xt=xt,\n    st=st,\n    _x1=x1,\n    _pad_token=self.pad_token,\n    _mask_token=self.mask_token,\n  )\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.FlexMDMForwardProcess.to_actual_rate","title":"<code>to_actual_rate(xt, prediction, t)</code>","text":"<p>Convert model prediction to actual sampling rates.</p> <p>Parameters:</p> Name Type Description Default <code>xt</code> <code>Tensor</code> <p>Current noised sequence [B, L]</p> required <code>prediction</code> <code>ModelPrediction</code> <p>Model output</p> required <code>t</code> <code>Tensor</code> <p>Time values [B]</p> required <p>Returns:</p> Type Description <code>Rate</code> <p>Rate object with unmask and length rates</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>def to_actual_rate(\n  self, xt: Tensor, prediction: ModelPrediction, t: Tensor\n) -&gt; Rate:\n  \"\"\"Convert model prediction to actual sampling rates.\n\n  Args:\n    xt: Current noised sequence [B, L]\n    prediction: Model output\n    t: Time values [B]\n\n  Returns:\n    Rate object with unmask and length rates\n  \"\"\"\n  token_posterior = F.softmax(prediction.token_logits, dim=-1)  # [B, L, V]\n  unmask_rate = token_posterior * self.unmask_schedule.rate_scale_factor(\n    t\n  ).view(-1, 1, 1)\n\n  length_rate = (\n    prediction.expected_gaps\n    * self.insertion_schedule.rate_scale_factor(t).view(-1, 1)\n  )\n\n  return Rate(\n    unmask_rate=unmask_rate,  # [B, L, V]\n    length_rate=length_rate,  # [B, L+1]\n  )\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.JointInterpolantResult","title":"<code>JointInterpolantResult</code>  <code>dataclass</code>","text":"<p>Result from sampling the joint interpolant.</p> <p>Attributes:</p> Name Type Description <code>xt</code> <code>Tensor</code> <p>Noised sequence at time t [B, L]</p> <code>st</code> <code>Tensor</code> <p>Sorting indices mapping xt back to x1 positions [B, L]</p> <code>_x1</code> <code>Tensor</code> <p>Original clean sequence (stored for property computation)</p> <code>_pad_token</code> <code>int</code> <p>Padding token ID</p> <code>_mask_token</code> <code>int</code> <p>Mask token ID</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>@dataclass\nclass JointInterpolantResult:\n  \"\"\"Result from sampling the joint interpolant.\n\n  Attributes:\n    xt: Noised sequence at time t [B, L]\n    st: Sorting indices mapping xt back to x1 positions [B, L]\n    _x1: Original clean sequence (stored for property computation)\n    _pad_token: Padding token ID\n    _mask_token: Mask token ID\n  \"\"\"\n  xt: Tensor  # Shape [Batch, Length]\n  st: Tensor  # Shape [Batch, Length]\n  _x1: Tensor\n  _pad_token: int\n  _mask_token: int\n\n  @property\n  def mask_indices(self) -&gt; Tensor:\n    \"\"\"Boolean mask indicating which positions are masked.\"\"\"\n    return self.xt == self._mask_token\n\n  @property\n  def unmasked(self) -&gt; Tensor:\n    \"\"\"Ground truth tokens at positions corresponding to xt.\"\"\"\n    return torch.gather(self._x1, 1, self.st)\n\n  @property\n  def xt_length(self) -&gt; Tensor:\n    \"\"\"Length of xt (excluding padding) [B].\"\"\"\n    return (self.xt != self._pad_token).sum(dim=1)\n\n  @property\n  def x1_length(self) -&gt; Tensor:\n    \"\"\"Length of x1 (excluding padding) [B].\"\"\"\n    return (self._x1 != self._pad_token).sum(dim=1)\n\n  @property\n  def gaps_and_mask(self) -&gt; tuple[Tensor, Tensor]:\n    \"\"\"Compute gap counts between xt positions.\n\n    Returns:\n      gaps: Number of deleted tokens between each position [B, L+1]\n      mask: Valid positions mask [B, L+1]\n    \"\"\"\n    x1_len = self.x1_length\n    gaps = self.st.clone()\n\n    # Add padding to compute differences\n    pad_front = gaps.new_zeros((gaps.shape[0], 1)) - 1\n    pad_back = gaps.new_zeros((gaps.shape[0], 1))\n    gaps = torch.cat([pad_front, gaps, pad_back], dim=1)\n\n    # Set the last gap to point to x1_len\n    gaps.scatter_(\n      1, self.xt_length.unsqueeze(1) + 1, x1_len.unsqueeze(1)\n    )\n\n    # Compute gaps as differences minus 1\n    gaps = gaps[:, 1:] - gaps[:, :-1] - 1\n    gaps = torch.clamp(gaps, min=0)\n\n    # Create mask for valid positions\n    idx = torch.arange(gaps.size(1), device=self.xt.device).unsqueeze(0)\n    mask = idx &lt;= self.xt_length.unsqueeze(1)\n    gaps[~mask] = 0\n\n    return gaps, mask\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.JointInterpolantResult.gaps_and_mask","title":"<code>gaps_and_mask</code>  <code>property</code>","text":"<p>Compute gap counts between xt positions.</p> <p>Returns:</p> Name Type Description <code>gaps</code> <code>Tensor</code> <p>Number of deleted tokens between each position [B, L+1]</p> <code>mask</code> <code>Tensor</code> <p>Valid positions mask [B, L+1]</p>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.JointInterpolantResult.mask_indices","title":"<code>mask_indices</code>  <code>property</code>","text":"<p>Boolean mask indicating which positions are masked.</p>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.JointInterpolantResult.unmasked","title":"<code>unmasked</code>  <code>property</code>","text":"<p>Ground truth tokens at positions corresponding to xt.</p>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.JointInterpolantResult.x1_length","title":"<code>x1_length</code>  <code>property</code>","text":"<p>Length of x1 (excluding padding) [B].</p>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.JointInterpolantResult.xt_length","title":"<code>xt_length</code>  <code>property</code>","text":"<p>Length of xt (excluding padding) [B].</p>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.ModelPrediction","title":"<code>ModelPrediction</code>  <code>dataclass</code>","text":"<p>Model output for FlexMDM any-order algorithm.</p> <p>Attributes:</p> Name Type Description <code>token_logits</code> <code>Tensor</code> <p>Logits for token predictions [B, L, V]</p> <code>length_posterior</code> <code>Optional[Tensor]</code> <p>Optional distribution over gap lengths [B, L, max_gap]</p> <code>expected_gaps</code> <code>Tensor</code> <p>Expected number of tokens to insert [B, L]</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>@dataclass\nclass ModelPrediction:\n  \"\"\"Model output for FlexMDM any-order algorithm.\n\n  Attributes:\n    token_logits: Logits for token predictions [B, L, V]\n    length_posterior: Optional distribution over gap lengths [B, L, max_gap]\n    expected_gaps: Expected number of tokens to insert [B, L]\n  \"\"\"\n  token_logits: Tensor\n  length_posterior: Optional[Tensor]\n  expected_gaps: Tensor\n\n  def __init__(\n    self,\n    token_logits: Tensor,\n    length_posterior: Optional[Tensor] = None,\n    expected_gaps: Optional[Tensor] = None,\n  ):\n    assert length_posterior is not None or expected_gaps is not None\n    self.token_logits = token_logits\n    self.length_posterior = length_posterior\n    self.expected_gaps = expected_gaps\n    if self.expected_gaps is None:\n      _, _, L = self.length_posterior.shape\n      index = torch.arange(0, L, device=token_logits.device).view(1, 1, -1)\n      self.expected_gaps = (\n        F.softmax(self.length_posterior, dim=-1) * index\n      ).sum(dim=-1)\n</code></pre>"},{"location":"reference/forward_process/flexmdm/#discrete_diffusion.forward_process.flexmdm.Rate","title":"<code>Rate</code>  <code>dataclass</code>","text":"<p>Rate information for sampling.</p> <p>Attributes:</p> Name Type Description <code>unmask_rate</code> <code>Tensor</code> <p>Rate of unmasking transitions [B, L, V]</p> <code>length_rate</code> <code>Tensor</code> <p>Rate of insertion transitions [B, L+1]</p> Source code in <code>src/discrete_diffusion/forward_process/flexmdm.py</code> <pre><code>@dataclass\nclass Rate:\n  \"\"\"Rate information for sampling.\n\n  Attributes:\n    unmask_rate: Rate of unmasking transitions [B, L, V]\n    length_rate: Rate of insertion transitions [B, L+1]\n  \"\"\"\n  unmask_rate: Tensor  # Shape [Batch, Length, Vocab]\n  length_rate: Tensor  # Shape [Batch, Length+1]\n</code></pre>"},{"location":"reference/forward_process/uniform/","title":"Uniform Process","text":""},{"location":"reference/forward_process/uniform/#discrete_diffusion.forward_process.uniform","title":"<code>discrete_diffusion.forward_process.uniform</code>","text":"<p>Uniform forward process: random token replacement.</p> <p>With probability <code>(1 - alpha_t)</code>, replaces each token by a uniformly drawn token from the vocabulary (optionally excluding the mask token if present).</p>"},{"location":"reference/forward_process/utils/","title":"Forward Process Utils","text":""},{"location":"reference/forward_process/utils/#discrete_diffusion.forward_process.utils","title":"<code>discrete_diffusion.forward_process.utils</code>","text":"<p>Utilities for forward-process implementations.</p> <p>Includes tokenizer helpers and a numerically stable categorical sampler.</p>"},{"location":"reference/forward_process/utils/#discrete_diffusion.forward_process.utils.sample_categorical","title":"<code>sample_categorical(categorical_probs)</code>","text":"<p>Sample categories via a Gumbel-max formulation for stability.</p> <p>Expects <code>categorical_probs</code> to be non-negative and to sum to one along the last dimension. This implementation mirrors the stable sampler used in the existing absorbing helpers for consistency.</p> Source code in <code>src/discrete_diffusion/forward_process/utils.py</code> <pre><code>def sample_categorical(categorical_probs: torch.Tensor) -&gt; torch.Tensor:\n  \"\"\"Sample categories via a Gumbel-max formulation for stability.\n\n  Expects `categorical_probs` to be non-negative and to sum to one along the\n  last dimension. This implementation mirrors the stable sampler used in the\n  existing absorbing helpers for consistency.\n  \"\"\"\n  gumbel_norm = 1e-10 - (torch.rand_like(categorical_probs) + 1e-10).log()\n  return (categorical_probs / gumbel_norm).argmax(dim=-1)\n</code></pre>"},{"location":"reference/models/block_dit/","title":"Block DiT","text":""},{"location":"reference/models/block_dit/#discrete_diffusion.models.block_dit","title":"<code>discrete_diffusion.models.block_dit</code>","text":"<p>Block-diffusion aware DiT backbone.</p>"},{"location":"reference/models/block_dit/#discrete_diffusion.models.block_dit.BlockDiT","title":"<code>BlockDiT</code>","text":"<p>               Bases: <code>Module</code>, <code>PyTorchModelHubMixin</code></p> <p>DiT backbone extended with block-diffusion attention masks.</p> Source code in <code>src/discrete_diffusion/models/block_dit.py</code> <pre><code>class BlockDiT(nn.Module, huggingface_hub.PyTorchModelHubMixin):\n  \"\"\"DiT backbone extended with block-diffusion attention masks.\"\"\"\n\n  def __init__(self, config, vocab_size: int):\n    super().__init__()\n    if isinstance(config, dict):\n      config = omegaconf.OmegaConf.create(config)\n    self.config = config\n    self.n = config.model.length\n    self.causal = getattr(config.model, 'causal_attention', config.algo.parameterization == 'ar')\n    self.adaLN = (not self.causal) or getattr(config.model, 'adaln', False)\n    self.vocab_size = vocab_size\n    self.block_size = getattr(config, 'block_size', config.model.length)\n    dim = config.model.hidden_size\n    cond_dim = config.model.cond_dim\n    self.n_heads = config.model.n_heads\n    self.vocab_embed = EmbeddingLayer(dim, vocab_size)\n    if self.adaLN or not self.causal:\n      self.sigma_map = TimestepEmbedder(cond_dim)\n    self.rotary_emb = Rotary(dim // config.model.n_heads)\n    self.attn_backend = getattr(config.model, 'attn_backend', 'flash_attn')\n    self.max_seqlen = 1024\n\n    blocks = []\n    for _ in range(config.model.n_blocks):\n      if self.causal:\n        block = DDiTBlockCausal(\n          n=config.model.length,\n          dim=dim,\n          n_heads=config.model.n_heads,\n          dropout=config.model.dropout,\n          max_batch_size=config.loader.eval_batch_size,\n          adaLN=self.adaLN,\n          cond_dim=cond_dim,\n          attn_backend=self.attn_backend)\n      else:\n        block = DDiTBlock(\n          n=config.model.length,\n          dim=dim,\n          n_heads=config.model.n_heads,\n          cond_dim=cond_dim,\n          adaLN=self.adaLN,\n          dropout=config.model.dropout,\n          block_size=self.block_size,\n          attn_backend=self.attn_backend,\n          max_seqlen=self.max_seqlen)\n      blocks.append(block)\n    self.blocks = nn.ModuleList(blocks)\n    self.output_layer = DDiTFinalLayer(\n      hidden_size=dim,\n      out_channels=vocab_size,\n      cond_dim=cond_dim,\n      adaLN=self.adaLN,\n      tie_word_embeddings=getattr(config.model, 'tie_word_embeddings', False))\n    # Tie output projection to input embeddings if requested\n    if getattr(config.model, 'tie_word_embeddings', False):\n      self.output_layer.linear.weight = self.vocab_embed.embedding\n    if getattr(config.algo, 'cross_attn', False):\n      self.gen_mask(config.model.length, self.block_size, self.attn_backend)\n\n  def _get_bias_dropout_scale(self):\n    if self.training:\n      return bias_dropout_add_scale_fused_train\n    return bias_dropout_add_scale_fused_inference\n\n  def gen_mask(self, seqlen, block_size, attn_backend='sdpa'):\n    if attn_backend == 'flex' and FLEX_ATTN_AVAILABLE:\n      assert create_block_mask is not None\n      self.block_diff_mask = create_block_mask(\n        partial(block_diff_mask, block_size=block_size, n=seqlen),\n        B=None, H=None, Q_LEN=seqlen * 2, KV_LEN=seqlen * 2)\n    elif attn_backend == 'sdpa':\n      self.block_diff_mask = block_diff_mask(\n        b=None, h=None, q_idx=torch.arange(seqlen * 2)[:, None],\n        kv_idx=torch.arange(seqlen * 2)[None, :],\n        block_size=block_size, n=seqlen)\n    else:\n      raise ValueError('Unknown attention backend')\n\n  def reset_kv_cache(self):\n    for block in self.blocks:\n      block.kv_cache = torch.zeros(\n        self.config.loader.eval_batch_size,\n        self.max_seqlen,\n        self.config.model.hidden_size * 3,\n        device='cuda',\n        dtype=torch.bfloat16)\n      block.cache_idx = 0\n\n  def forward(self, indices, sigma, sample_mode=False, store_kv=False):\n    x = self.vocab_embed(indices)\n    if sigma is None:\n      t_cond = None\n    else:\n      t_cond = F.silu(self.sigma_map(sigma))\n\n    cross_attn = hasattr(self, 'block_diff_mask')\n    if cross_attn:\n      mask = self.block_diff_mask\n      if sample_mode:\n        if getattr(self.config.sampling, 'kv_cache', False):\n          mask = None\n          accum_length = self.blocks[0].cache_idx + self.block_size\n          x_full = torch.zeros((\n            x.shape[0], accum_length, x.shape[2]), device=x.device)\n          rotary_cos_sin = self.rotary_emb(x_full)\n        else:\n          mask = mask[\n            self.n:self.n + x.shape[1], self.n:self.n + x.shape[1]]\n          rotary_cos_sin = self.rotary_emb(x)\n      else:\n        rotary_cos_sin = self.rotary_emb(x[:, :self.n])\n    else:\n      rotary_cos_sin = self.rotary_emb(x)\n      mask = None\n\n    with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n      for block in self.blocks:\n        x = block(\n          x,\n          rotary_cos_sin,\n          c=t_cond,\n          causal=self.causal,\n          sample_mode=sample_mode,\n          mask=mask,\n          store_kv=store_kv)\n      x = self.output_layer(x, t_cond)\n    if cross_attn and not sample_mode:\n      x = x[:, :self.n]\n    return x\n</code></pre>"},{"location":"reference/models/block_dit/#discrete_diffusion.models.block_dit.block_diff_mask","title":"<code>block_diff_mask(b, h, q_idx, kv_idx, block_size=None, n=None)</code>","text":"<p>Construct the block diffusion attention mask.</p> <p>Line-by-line match to upstream BD3-LM implementation.</p> Source code in <code>src/discrete_diffusion/models/block_dit.py</code> <pre><code>def block_diff_mask(b, h, q_idx, kv_idx, block_size=None, n=None):  # noqa: D401, ignored args\n  \"\"\"Construct the block diffusion attention mask.\n\n  Line-by-line match to upstream BD3-LM implementation.\n  \"\"\"\n\n  x0_flag_q = (q_idx &gt;= n)\n  x0_flag_kv = (kv_idx &gt;= n)\n\n  block_q = torch.where(\n    x0_flag_q == 1,\n    (q_idx - n) // block_size,\n    q_idx // block_size)\n  block_kv = torch.where(\n    x0_flag_kv == 1,\n    (kv_idx - n) // block_size,\n    kv_idx // block_size)\n\n  block_diagonal = (block_q == block_kv) &amp; (x0_flag_q == x0_flag_kv)\n  offset_block_causal = (\n    (block_q &gt; block_kv)\n    &amp; (x0_flag_kv == 1)\n    &amp; (x0_flag_q == 0))\n  block_causal = (\n    (block_q &gt;= block_kv)\n    &amp; (x0_flag_kv == 1)\n    &amp; (x0_flag_q == 1))\n  return block_diagonal | offset_block_causal | block_causal\n</code></pre>"},{"location":"reference/models/common/","title":"Common Model Layers","text":""},{"location":"reference/models/common/#discrete_diffusion.models.common","title":"<code>discrete_diffusion.models.common</code>","text":"<p>Shared model primitives for UNI-D\u00b2 backbones.</p> <p>This module centralizes lightweight, backend-agnostic helpers used across multiple backbones (DiT, BlockDiT, Encoder-Decoder). Attention backend selection (flash-attn vs SDPA vs flex) remains in each backbone.</p>"},{"location":"reference/models/common/#discrete_diffusion.models.common.DDiTBlockCausal","title":"<code>DDiTBlockCausal</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>class DDiTBlockCausal(nn.Module):\n  def __init__(self, dim, n_heads, mlp_ratio=4, dropout=0.1, attn_backend='auto'):\n    super().__init__()\n    self.n_heads = n_heads\n    self.attn_backend = attn_backend\n\n    self.norm1 = LayerNorm(dim)\n    self.attn_qkv = nn.Linear(dim, 3 * dim, bias=False)\n    self.attn_out = nn.Linear(dim, dim, bias=False)\n    self.dropout1 = nn.Dropout(dropout)\n\n    self.norm2 = LayerNorm(dim)\n    self.mlp = nn.Sequential(\n      nn.Linear(dim, mlp_ratio * dim, bias=True),\n      nn.GELU(approximate='tanh'),\n      nn.Linear(mlp_ratio * dim, dim, bias=True))\n    self.dropout2 = nn.Dropout(dropout)\n    self.dropout = dropout\n\n  def _get_bias_dropout_scale(self):\n    if self.training:\n      return bias_dropout_add_scale_fused_train\n    else:\n      return bias_dropout_add_scale_fused_inference\n\n  def _apply_causal_attention(self, qkv, rotary_cos_sin):\n    \"\"\"Apply causal attention with fallback logic.\"\"\"\n    cos, sin = rotary_cos_sin\n    cos = cos.to(qkv.dtype)\n    sin = sin.to(qkv.dtype)\n\n    # Try flash-attn first\n    if self.attn_backend == 'flash_attn' or (self.attn_backend == 'auto' and supports_flash_attention()):\n      with torch.amp.autocast('cuda', enabled=False):\n        qkv_rotary = apply_rotary_pos_emb(qkv, cos, sin)\n      return flash_varlen_attention_qkvpacked(qkv_rotary, causal=True)\n    else:\n      # Fallback to SDPA\n      qkv_rotary = apply_rotary_pos_emb_torchscript(qkv, cos, sin)\n      q, k, v = qkv_rotary.chunk(3, dim=2)\n      return sdpa_attention(q, k, v, causal=True, dropout_p=0.0)\n\n  def forward(self, x, rotary_cos_sin, **kwargs):\n    del kwargs\n    bias_dropout_scale_fn = self._get_bias_dropout_scale()\n    x_skip = x\n    x = self.norm1(x)\n\n    qkv = self.attn_qkv(x)\n    qkv = rearrange(\n      qkv,\n      'b s (three h d) -&gt; b s three h d',\n      three=3,\n      h=self.n_heads)\n    x = self._apply_causal_attention(qkv, rotary_cos_sin)\n\n    scale = torch.ones(1, device=x.device, dtype=x.dtype)\n    x = bias_dropout_scale_fn(\n      self.attn_out(x), None, scale, x_skip, self.dropout)\n\n    x = bias_dropout_scale_fn(\n      self.mlp(self.norm2(x)), None, scale, x, self.dropout)\n    return x\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.LabelEmbedder","title":"<code>LabelEmbedder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embeds class labels into vector representations.</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>class LabelEmbedder(nn.Module):\n  \"\"\"Embeds class labels into vector representations.\"\"\"\n\n  def __init__(self, num_classes, cond_size):\n    super().__init__()\n    self.embedding_table = nn.Embedding(num_classes + 1, cond_size)\n    self.num_classes = num_classes\n\n  def forward(self, labels):\n    return self.embedding_table(labels)\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.TimestepEmbedder","title":"<code>TimestepEmbedder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embeds scalar timesteps into vector representations.</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>class TimestepEmbedder(nn.Module):\n  \"\"\"Embeds scalar timesteps into vector representations.\"\"\"\n\n  def __init__(self, hidden_size: int, frequency_embedding_size: int = 256):\n    super().__init__()\n    self.mlp = nn.Sequential(\n      nn.Linear(frequency_embedding_size, hidden_size, bias=True),\n      nn.SiLU(),\n      nn.Linear(hidden_size, hidden_size, bias=True))\n    self.frequency_embedding_size = frequency_embedding_size\n\n  @staticmethod\n  def timestep_embedding(t: torch.Tensor, dim: int, max_period: int = 10000):\n    # https://github.com/openai/glide-text2im/blob/main/glide_text2im/nn.py\n    half = dim // 2\n    freqs = torch.exp(\n      - math.log(max_period)\n      * torch.arange(start=0, end=half, dtype=torch.float32, device=t.device)\n      / half)\n    args = t[:, None].float() * freqs[None]\n    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n    if dim % 2:\n      embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n    return embedding\n\n  def forward(self, t: torch.Tensor) -&gt; torch.Tensor:\n    t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n    t_emb = self.mlp(t_freq)\n    return t_emb\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.apply_rotary_pos_emb","title":"<code>apply_rotary_pos_emb(qkv, cos, sin)</code>","text":"<p>In-place rotary application for qkv-packed tensors using flash-attn helper.</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def apply_rotary_pos_emb(qkv: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor):\n  \"\"\"In-place rotary application for qkv-packed tensors using flash-attn helper.\"\"\"\n  if flash_attn is None:\n    raise RuntimeError(\"flash_attn is required for rotary qkv application\")\n  cos = cos[0, :, 0, 0, :cos.shape[-1] // 2]\n  sin = sin[0, :, 0, 0, :sin.shape[-1] // 2]\n  return flash_attn.layers.rotary.apply_rotary_emb_qkv_(qkv, cos, sin)\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.apply_rotary_pos_emb_single","title":"<code>apply_rotary_pos_emb_single(vec, cos, sin)</code>","text":"<p>Apply rotary to a single tensor (q or k) with shape (B, S, H, D).</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def apply_rotary_pos_emb_single(vec: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor):\n  \"\"\"Apply rotary to a single tensor (q or k) with shape (B, S, H, D).\"\"\"\n  if flash_attn is None:\n    raise RuntimeError(\"flash_attn is required for rotary single-vector application\")\n  with torch.amp.autocast('cuda', enabled=False):\n    cos = cos.to(vec.dtype)\n    sin = sin.to(vec.dtype)\n    if vec.shape[1] &lt; cos.shape[1]:\n      cos = cos[:, :vec.shape[1]]\n      sin = sin[:, :vec.shape[1]]\n    if cos.shape[0] == 1:\n      cos_in = cos[0, :, 0, 0, :cos.shape[-1] // 2]\n      sin_in = sin[0, :, 0, 0, :sin.shape[-1] // 2]\n    else:\n      cos_in = cos[:, :, 0, 0, :cos.shape[-1] // 2]\n      sin_in = sin[:, :, 0, 0, :sin.shape[-1] // 2]\n    vec = flash_attn.layers.rotary.apply_rotary_emb_torch(vec, cos_in, sin_in)\n  return vec\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.apply_rotary_pos_emb_torchscript","title":"<code>apply_rotary_pos_emb_torchscript(qkv, cos, sin)</code>","text":"<p>TorchScript-friendly rotary application for SDPA/backends without flash-attn.</p> <p>Expects qkv shaped (B, S, 3, H, D). Returns transformed qkv.</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def apply_rotary_pos_emb_torchscript(qkv: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor):\n  \"\"\"TorchScript-friendly rotary application for SDPA/backends without flash-attn.\n\n  Expects qkv shaped (B, S, 3, H, D). Returns transformed qkv.\n  \"\"\"\n  return (qkv * cos) + (rotate_half(qkv) * sin)\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.flash_varlen_attention_qkvpacked","title":"<code>flash_varlen_attention_qkvpacked(qkv, causal=False, dropout_p=0.0)</code>","text":"<p>FlashAttention varlen over packed qkv.</p> <p>Parameters:</p> Name Type Description Default <code>qkv</code> <code>Tensor</code> <p>Tensor shaped (B, S, 3, H, D)</p> required <code>causal</code> <code>bool</code> <p>Whether to apply causal masking.</p> <code>False</code> <code>dropout_p</code> <code>float</code> <p>Dropout probability (kept for parity; 0.0 for inference/eval).</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor shaped (B, S, H*D)</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def flash_varlen_attention_qkvpacked(\n    qkv: torch.Tensor,\n    causal: bool = False,\n    dropout_p: float = 0.0,\n) -&gt; torch.Tensor:\n  \"\"\"FlashAttention varlen over packed qkv.\n\n  Args:\n    qkv: Tensor shaped (B, S, 3, H, D)\n    causal: Whether to apply causal masking.\n    dropout_p: Dropout probability (kept for parity; 0.0 for inference/eval).\n\n  Returns:\n    Tensor shaped (B, S, H*D)\n  \"\"\"\n  if flash_attn is None:\n    raise RuntimeError(\"flash_attn is not available for flash_varlen_attention_qkvpacked\")\n  bsz, seqlen = qkv.shape[0], qkv.shape[1]\n  qkv_flat = rearrange(qkv, 'b s ... -&gt; (b s) ...')\n  cu_seqlens = torch.arange(\n    0, (bsz + 1) * seqlen, step=seqlen, dtype=torch.int32, device=qkv.device)\n  x = flash_attn.flash_attn_interface.flash_attn_varlen_qkvpacked_func(\n    qkv_flat, cu_seqlens, seqlen, dropout_p, causal=causal)\n  x = rearrange(x, '(b s) h d -&gt; b s (h d)', b=bsz)\n  return x\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.residual_linear","title":"<code>residual_linear(x, W, x_skip, residual_scale)</code>","text":"<p>Compute x_skip + residual_scale * (W @ x) efficiently via addmm.</p> Shapes <ul> <li>x: (..., dim_in)</li> <li>W: (dim_out, dim_in)</li> <li>returns: (..., dim_out)</li> </ul> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def residual_linear(x: torch.Tensor, W: torch.Tensor, x_skip: torch.Tensor, residual_scale: float) -&gt; torch.Tensor:\n  \"\"\"Compute x_skip + residual_scale * (W @ x) efficiently via addmm.\n\n  Shapes:\n    - x: (..., dim_in)\n    - W: (dim_out, dim_in)\n    - returns: (..., dim_out)\n  \"\"\"\n  dim_out, dim_in = W.shape[0], W.shape[1]\n  return torch.addmm(\n    x_skip.view(-1, dim_out),\n    x.view(-1, dim_in),\n    W.T,\n    alpha=residual_scale).view(*x.shape[:-1], dim_out)\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.sdpa_attention","title":"<code>sdpa_attention(q, k, v, attn_mask=None, causal=False, dropout_p=0.0, scale=None)</code>","text":"<p>Scaled dot-product attention over packed heads using torch SDPA.</p> <p>Parameters:</p> Name Type Description Default <code>q, k, v</code> <p>Tensors shaped (B, S, H, D)</p> required <code>attn_mask</code> <code>Optional[Tensor]</code> <p>Optional mask shaped (B, S, S) or broadcastable.</p> <code>None</code> <code>causal</code> <code>bool</code> <p>Whether to use causal masking.</p> <code>False</code> <code>dropout_p</code> <code>float</code> <p>Dropout probability (training only; kept for API parity).</p> <code>0.0</code> <code>scale</code> <code>Optional[float]</code> <p>Optional scale override (1/sqrt(D)).</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor shaped (B, S, H*D) (flattened heads for downstream linear).</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def sdpa_attention(\n    q: torch.Tensor,\n    k: torch.Tensor,\n    v: torch.Tensor,\n    attn_mask: typing.Optional[torch.Tensor] = None,\n    causal: bool = False,\n    dropout_p: float = 0.0,\n    scale: typing.Optional[float] = None,\n) -&gt; torch.Tensor:\n  \"\"\"Scaled dot-product attention over packed heads using torch SDPA.\n\n  Args:\n    q, k, v: Tensors shaped (B, S, H, D)\n    attn_mask: Optional mask shaped (B, S, S) or broadcastable.\n    causal: Whether to use causal masking.\n    dropout_p: Dropout probability (training only; kept for API parity).\n    scale: Optional scale override (1/sqrt(D)).\n\n  Returns:\n    Tensor shaped (B, S, H*D) (flattened heads for downstream linear).\n  \"\"\"\n  # torch SDPA expects (B, H, S, D)\n  q = q.transpose(1, 2)\n  k = k.transpose(1, 2)\n  v = v.transpose(1, 2)\n  x = F.scaled_dot_product_attention(\n    q, k, v,\n    attn_mask=attn_mask[:, None] if attn_mask is not None else None,\n    dropout_p=dropout_p,\n    is_causal=causal,\n    scale=scale)\n  x = x.transpose(1, 2)  # (B, S, H, D)\n  return rearrange(x, 'b s h d -&gt; b s (h d)')\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.sdpa_attention_masked","title":"<code>sdpa_attention_masked(q, k, v, attn_mask, causal=False)</code>","text":"<p>Convenience wrapper for masked SDPA returning (B,S,H*D).</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def sdpa_attention_masked(\n    q: torch.Tensor,\n    k: torch.Tensor,\n    v: torch.Tensor,\n    attn_mask: torch.Tensor,\n    causal: bool = False) -&gt; torch.Tensor:\n  \"\"\"Convenience wrapper for masked SDPA returning (B,S,H*D).\"\"\"\n  return sdpa_attention(q, k, v, attn_mask=attn_mask, causal=causal, dropout_p=0.0)\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.sdpa_attention_unmasked","title":"<code>sdpa_attention_unmasked(q, k, v)</code>","text":"<p>Convenience wrapper for unmasked SDPA returning (B,S,H*D).</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def sdpa_attention_unmasked(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor) -&gt; torch.Tensor:\n  \"\"\"Convenience wrapper for unmasked SDPA returning (B,S,H*D).\"\"\"\n  return sdpa_attention(q, k, v, attn_mask=None, causal=False, dropout_p=0.0)\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.split_and_apply_rotary_pos_emb","title":"<code>split_and_apply_rotary_pos_emb(qkv, rotary_cos_sin)</code>","text":"<p>Apply rotary to q,k slices of packed qkv.</p> <p>Expects qkv shaped (B, S, 3, H, D). Returns (q, k, v) with shapes (B, S, H, D), (B, S, H, D), (B, S, H, D).</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def split_and_apply_rotary_pos_emb(qkv: torch.Tensor, rotary_cos_sin: typing.Tuple[torch.Tensor, torch.Tensor]):\n  \"\"\"Apply rotary to q,k slices of packed qkv.\n\n  Expects qkv shaped (B, S, 3, H, D). Returns (q, k, v) with shapes\n  (B, S, H, D), (B, S, H, D), (B, S, H, D).\n  \"\"\"\n  if flash_attn is None:\n    raise RuntimeError(\"flash_attn is required for rotary split helpers\")\n  with torch.amp.autocast('cuda', enabled=False):\n    cos, sin = rotary_cos_sin\n    cos = cos.to(qkv.dtype)\n    sin = sin.to(qkv.dtype)\n    # Align cached length/batch with qkv if needed\n    if qkv.shape[1] &lt; cos.shape[1]:\n      cos = cos[:, :qkv.shape[1]]\n      sin = sin[:, :qkv.shape[1]]\n    if cos.shape[0] == 1:\n      cos_in = cos[0, :, 0, 0, :cos.shape[-1] // 2]\n      sin_in = sin[0, :, 0, 0, :sin.shape[-1] // 2]\n    else:\n      cos_in = cos[:, :, 0, 0, :cos.shape[-1] // 2]\n      sin_in = sin[:, :, 0, 0, :sin.shape[-1] // 2]\n    q, k, v = qkv.chunk(3, dim=2)\n    q = flash_attn.layers.rotary.apply_rotary_emb_torch(q.squeeze(dim=2), cos_in, sin_in)\n    k = flash_attn.layers.rotary.apply_rotary_emb_torch(k.squeeze(dim=2), cos_in, sin_in)\n    v = v.squeeze(dim=2)\n  return q, k, v\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.supports_flash_attention","title":"<code>supports_flash_attention()</code>","text":"<p>Check if flash-attn is available and functional.</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def supports_flash_attention() -&gt; bool:\n  \"\"\"Check if flash-attn is available and functional.\"\"\"\n  return FLASH_ATTN_AVAILABLE\n</code></pre>"},{"location":"reference/models/common/#discrete_diffusion.models.common.supports_flex_attention","title":"<code>supports_flex_attention()</code>","text":"<p>Check if torch flex attention is available (PyTorch 2.4+).</p> Source code in <code>src/discrete_diffusion/models/common.py</code> <pre><code>def supports_flex_attention() -&gt; bool:\n  \"\"\"Check if torch flex attention is available (PyTorch 2.4+).\"\"\"\n  return hasattr(torch.nn.functional, 'flex_attention')\n</code></pre>"},{"location":"reference/models/dit/","title":"Diffusion Transformer (DiT)","text":""},{"location":"reference/models/dit/#discrete_diffusion.models.dit","title":"<code>discrete_diffusion.models.dit</code>","text":""},{"location":"reference/models/dit/#discrete_diffusion.models.dit.DIT","title":"<code>DIT</code>","text":"<p>               Bases: <code>Module</code>, <code>PyTorchModelHubMixin</code></p> <p>Diffusion Transformer (DiT) backbone model.</p> <p>A Transformer architecture optimized for diffusion, supporting both causal (GPT-style) and bidirectional (BERT-style) attention, with adaptive layer normalization for time conditioning.</p> Source code in <code>src/discrete_diffusion/models/dit.py</code> <pre><code>class DIT(nn.Module, huggingface_hub.PyTorchModelHubMixin):\n  \"\"\"Diffusion Transformer (DiT) backbone model.\n\n  A Transformer architecture optimized for diffusion, supporting both\n  causal (GPT-style) and bidirectional (BERT-style) attention, with\n  adaptive layer normalization for time conditioning.\n  \"\"\"\n  def __init__(self, config, vocab_size: int):\n    \"\"\"Initialize the DiT model.\n\n    Args:\n        config: Hydra configuration object containing model hyperparameters.\n        vocab_size: Size of the vocabulary.\n    \"\"\"\n    super().__init__()\n    if type(config) == dict:\n      config = omegaconf.OmegaConf.create(config)\n    self.causal = config.algo.causal_attention\n    self.adaLN = not self.causal\n    self.config = config\n    self.vocab_size = vocab_size\n    dim = config.model.hidden_size\n    cond_dim = config.model.cond_dim\n    self.vocab_embed = EmbeddingLayer(dim, vocab_size)\n    if not self.causal:\n      self.sigma_map = TimestepEmbedder(cond_dim)\n    self.rotary_emb = Rotary(dim // config.model.n_heads)\n\n    blocks = []\n    for _ in range(config.model.n_blocks):\n      if self.causal:\n        block = DDiTBlockCausal(\n          dim=dim,\n          n_heads=config.model.n_heads,\n          dropout=config.model.dropout)\n      else:\n        block = DDiTBlock(\n          dim=dim,\n          n_heads=config.model.n_heads,\n          cond_dim=cond_dim,\n          adaLN=self.adaLN,\n          dropout=config.model.dropout)\n      blocks.append(block)\n    self.blocks = nn.ModuleList(blocks)\n\n    self.output_layer = DDiTFinalLayer(\n      hidden_size=dim,\n      out_channels=vocab_size,\n      cond_dim=cond_dim,\n      adaLN=self.adaLN)\n    self.scale_by_sigma = config.model.scale_by_sigma\n    # Tie output projection to input embeddings if requested\n    if getattr(config.model, 'tie_word_embeddings', False):\n      self.output_layer.linear.weight = self.vocab_embed.embedding\n\n  def _get_bias_dropout_scale(self):\n    if self.training:\n      return bias_dropout_add_scale_fused_train\n    else:\n      return  bias_dropout_add_scale_fused_inference\n\n  def forward(self, x, sigma):\n    \"\"\"Forward pass of the DiT.\n\n    Args:\n        x: Input token indices [batch, seq_len].\n        sigma: Noise level/time embedding [batch] or [batch, seq_len].\n\n    Returns:\n        Tensor: Logits [batch, seq_len, vocab_size].\n    \"\"\"\n    x = self.vocab_embed(x)\n    if self.causal:\n      t_cond = None\n    else:\n      t_cond = F.silu(self.sigma_map(sigma))\n\n    rotary_cos_sin = self.rotary_emb(x)\n\n    with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n      for i in range(len(self.blocks)):\n        x = self.blocks[i](x, rotary_cos_sin, c=t_cond)\n      x = self.output_layer(x, c=t_cond)\n\n    return x\n</code></pre>"},{"location":"reference/models/dit/#discrete_diffusion.models.dit.DIT.__init__","title":"<code>__init__(config, vocab_size)</code>","text":"<p>Initialize the DiT model.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <p>Hydra configuration object containing model hyperparameters.</p> required <code>vocab_size</code> <code>int</code> <p>Size of the vocabulary.</p> required Source code in <code>src/discrete_diffusion/models/dit.py</code> <pre><code>def __init__(self, config, vocab_size: int):\n  \"\"\"Initialize the DiT model.\n\n  Args:\n      config: Hydra configuration object containing model hyperparameters.\n      vocab_size: Size of the vocabulary.\n  \"\"\"\n  super().__init__()\n  if type(config) == dict:\n    config = omegaconf.OmegaConf.create(config)\n  self.causal = config.algo.causal_attention\n  self.adaLN = not self.causal\n  self.config = config\n  self.vocab_size = vocab_size\n  dim = config.model.hidden_size\n  cond_dim = config.model.cond_dim\n  self.vocab_embed = EmbeddingLayer(dim, vocab_size)\n  if not self.causal:\n    self.sigma_map = TimestepEmbedder(cond_dim)\n  self.rotary_emb = Rotary(dim // config.model.n_heads)\n\n  blocks = []\n  for _ in range(config.model.n_blocks):\n    if self.causal:\n      block = DDiTBlockCausal(\n        dim=dim,\n        n_heads=config.model.n_heads,\n        dropout=config.model.dropout)\n    else:\n      block = DDiTBlock(\n        dim=dim,\n        n_heads=config.model.n_heads,\n        cond_dim=cond_dim,\n        adaLN=self.adaLN,\n        dropout=config.model.dropout)\n    blocks.append(block)\n  self.blocks = nn.ModuleList(blocks)\n\n  self.output_layer = DDiTFinalLayer(\n    hidden_size=dim,\n    out_channels=vocab_size,\n    cond_dim=cond_dim,\n    adaLN=self.adaLN)\n  self.scale_by_sigma = config.model.scale_by_sigma\n  # Tie output projection to input embeddings if requested\n  if getattr(config.model, 'tie_word_embeddings', False):\n    self.output_layer.linear.weight = self.vocab_embed.embedding\n</code></pre>"},{"location":"reference/models/dit/#discrete_diffusion.models.dit.DIT.forward","title":"<code>forward(x, sigma)</code>","text":"<p>Forward pass of the DiT.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>Input token indices [batch, seq_len].</p> required <code>sigma</code> <p>Noise level/time embedding [batch] or [batch, seq_len].</p> required <p>Returns:</p> Name Type Description <code>Tensor</code> <p>Logits [batch, seq_len, vocab_size].</p> Source code in <code>src/discrete_diffusion/models/dit.py</code> <pre><code>def forward(self, x, sigma):\n  \"\"\"Forward pass of the DiT.\n\n  Args:\n      x: Input token indices [batch, seq_len].\n      sigma: Noise level/time embedding [batch] or [batch, seq_len].\n\n  Returns:\n      Tensor: Logits [batch, seq_len, vocab_size].\n  \"\"\"\n  x = self.vocab_embed(x)\n  if self.causal:\n    t_cond = None\n  else:\n    t_cond = F.silu(self.sigma_map(sigma))\n\n  rotary_cos_sin = self.rotary_emb(x)\n\n  with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n    for i in range(len(self.blocks)):\n      x = self.blocks[i](x, rotary_cos_sin, c=t_cond)\n    x = self.output_layer(x, c=t_cond)\n\n  return x\n</code></pre>"},{"location":"reference/models/dit_candi/","title":"CANDI DiT","text":""},{"location":"reference/models/dit_candi/#discrete_diffusion.models.dit_candi","title":"<code>discrete_diffusion.models.dit_candi</code>","text":"<p>DiT model architecture adapted for continuous-discrete hybrid diffusion.</p>"},{"location":"reference/models/ema/","title":"EMA","text":""},{"location":"reference/models/ema/#discrete_diffusion.models.ema","title":"<code>discrete_diffusion.models.ema</code>","text":""},{"location":"reference/models/ema/#discrete_diffusion.models.ema.ExponentialMovingAverage","title":"<code>ExponentialMovingAverage</code>","text":"<p>Maintains (exponential) moving average of a set of parameters.</p> Source code in <code>src/discrete_diffusion/models/ema.py</code> <pre><code>class ExponentialMovingAverage:\n  \"\"\"\n  Maintains (exponential) moving average of a set of parameters.\n  \"\"\"\n\n  def __init__(self, parameters, decay, use_num_updates=True):\n    \"\"\"\n    Args:\n        parameters: Iterable of `torch.nn.Parameter`; usually the result of\n            `model.parameters()`.\n        decay: The exponential decay.\n        use_num_updates: Whether to use number of updates when computing\n            averages.\n    \"\"\"\n    if decay &lt; 0.0 or decay &gt; 1.0:\n      raise ValueError('Decay must be between 0 and 1')\n    self.decay = decay\n    self.num_updates = 0 if use_num_updates else None\n    self.shadow_params = [p.clone().detach()\n                          for p in parameters if p.requires_grad]\n    self.collected_params = []\n\n  def move_shadow_params_to_device(self, device):\n    self.shadow_params = [i.to(device) for i in self.shadow_params]\n\n  def update(self, parameters):\n    \"\"\"\n    Update currently maintained parameters.\n\n    Call this every time the parameters are updated, such as the result of\n    the `optimizer.step()` call.\n\n    Args:\n        parameters: Iterable of `torch.nn.Parameter`; usually the same set of\n            parameters used to initialize this object.\n    \"\"\"\n    decay = self.decay\n    if self.num_updates is not None:\n      self.num_updates += 1\n      decay = min(decay, (1 + self.num_updates) /\n                  (10 + self.num_updates))\n    one_minus_decay = 1.0 - decay\n    with torch.no_grad():\n      parameters = [p for p in parameters if p.requires_grad]\n      for s_param, param in zip(self.shadow_params, parameters):\n        s_param.sub_(one_minus_decay * (s_param - param))\n\n  def copy_to(self, parameters):\n    \"\"\"\n    Copy current parameters into given collection of parameters.\n\n    Args:\n        parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            updated with the stored moving averages.\n    \"\"\"\n    parameters = [p for p in parameters if p.requires_grad]\n    for s_param, param in zip(self.shadow_params, parameters):\n      if param.requires_grad:\n        param.data.copy_(s_param.data)\n\n  def store(self, parameters):\n    \"\"\"\n    Save the current parameters for restoring later.\n\n    Args:\n        parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            temporarily stored.\n    \"\"\"\n    self.collected_params = [param.clone() for param in parameters]\n\n  def restore(self, parameters):\n    \"\"\"\n    Restore the parameters stored with the `store` method.\n    Useful to validate the model with EMA parameters without affecting the\n    original optimization process. Store the parameters before the\n    `copy_to` method. After validation (or model saving), use this to\n    restore the former parameters.\n\n    Args:\n        parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            updated with the stored parameters.\n    \"\"\"\n    for c_param, param in zip(self.collected_params, parameters):\n      param.data.copy_(c_param.data)\n\n  def state_dict(self):\n    return dict(decay=self.decay,\n                num_updates=self.num_updates,\n                shadow_params=self.shadow_params)\n\n  def load_state_dict(self, state_dict):\n    self.decay = state_dict['decay']\n    self.num_updates = state_dict['num_updates']\n    self.shadow_params = state_dict['shadow_params']\n</code></pre>"},{"location":"reference/models/ema/#discrete_diffusion.models.ema.ExponentialMovingAverage.__init__","title":"<code>__init__(parameters, decay, use_num_updates=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>parameters</code> <p>Iterable of <code>torch.nn.Parameter</code>; usually the result of <code>model.parameters()</code>.</p> required <code>decay</code> <p>The exponential decay.</p> required <code>use_num_updates</code> <p>Whether to use number of updates when computing averages.</p> <code>True</code> Source code in <code>src/discrete_diffusion/models/ema.py</code> <pre><code>def __init__(self, parameters, decay, use_num_updates=True):\n  \"\"\"\n  Args:\n      parameters: Iterable of `torch.nn.Parameter`; usually the result of\n          `model.parameters()`.\n      decay: The exponential decay.\n      use_num_updates: Whether to use number of updates when computing\n          averages.\n  \"\"\"\n  if decay &lt; 0.0 or decay &gt; 1.0:\n    raise ValueError('Decay must be between 0 and 1')\n  self.decay = decay\n  self.num_updates = 0 if use_num_updates else None\n  self.shadow_params = [p.clone().detach()\n                        for p in parameters if p.requires_grad]\n  self.collected_params = []\n</code></pre>"},{"location":"reference/models/ema/#discrete_diffusion.models.ema.ExponentialMovingAverage.copy_to","title":"<code>copy_to(parameters)</code>","text":"<p>Copy current parameters into given collection of parameters.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <p>Iterable of <code>torch.nn.Parameter</code>; the parameters to be updated with the stored moving averages.</p> required Source code in <code>src/discrete_diffusion/models/ema.py</code> <pre><code>def copy_to(self, parameters):\n  \"\"\"\n  Copy current parameters into given collection of parameters.\n\n  Args:\n      parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n          updated with the stored moving averages.\n  \"\"\"\n  parameters = [p for p in parameters if p.requires_grad]\n  for s_param, param in zip(self.shadow_params, parameters):\n    if param.requires_grad:\n      param.data.copy_(s_param.data)\n</code></pre>"},{"location":"reference/models/ema/#discrete_diffusion.models.ema.ExponentialMovingAverage.restore","title":"<code>restore(parameters)</code>","text":"<p>Restore the parameters stored with the <code>store</code> method. Useful to validate the model with EMA parameters without affecting the original optimization process. Store the parameters before the <code>copy_to</code> method. After validation (or model saving), use this to restore the former parameters.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <p>Iterable of <code>torch.nn.Parameter</code>; the parameters to be updated with the stored parameters.</p> required Source code in <code>src/discrete_diffusion/models/ema.py</code> <pre><code>def restore(self, parameters):\n  \"\"\"\n  Restore the parameters stored with the `store` method.\n  Useful to validate the model with EMA parameters without affecting the\n  original optimization process. Store the parameters before the\n  `copy_to` method. After validation (or model saving), use this to\n  restore the former parameters.\n\n  Args:\n      parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n          updated with the stored parameters.\n  \"\"\"\n  for c_param, param in zip(self.collected_params, parameters):\n    param.data.copy_(c_param.data)\n</code></pre>"},{"location":"reference/models/ema/#discrete_diffusion.models.ema.ExponentialMovingAverage.store","title":"<code>store(parameters)</code>","text":"<p>Save the current parameters for restoring later.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <p>Iterable of <code>torch.nn.Parameter</code>; the parameters to be temporarily stored.</p> required Source code in <code>src/discrete_diffusion/models/ema.py</code> <pre><code>def store(self, parameters):\n  \"\"\"\n  Save the current parameters for restoring later.\n\n  Args:\n      parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n          temporarily stored.\n  \"\"\"\n  self.collected_params = [param.clone() for param in parameters]\n</code></pre>"},{"location":"reference/models/ema/#discrete_diffusion.models.ema.ExponentialMovingAverage.update","title":"<code>update(parameters)</code>","text":"<p>Update currently maintained parameters.</p> <p>Call this every time the parameters are updated, such as the result of the <code>optimizer.step()</code> call.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <p>Iterable of <code>torch.nn.Parameter</code>; usually the same set of parameters used to initialize this object.</p> required Source code in <code>src/discrete_diffusion/models/ema.py</code> <pre><code>def update(self, parameters):\n  \"\"\"\n  Update currently maintained parameters.\n\n  Call this every time the parameters are updated, such as the result of\n  the `optimizer.step()` call.\n\n  Args:\n      parameters: Iterable of `torch.nn.Parameter`; usually the same set of\n          parameters used to initialize this object.\n  \"\"\"\n  decay = self.decay\n  if self.num_updates is not None:\n    self.num_updates += 1\n    decay = min(decay, (1 + self.num_updates) /\n                (10 + self.num_updates))\n  one_minus_decay = 1.0 - decay\n  with torch.no_grad():\n    parameters = [p for p in parameters if p.requires_grad]\n    for s_param, param in zip(self.shadow_params, parameters):\n      s_param.sub_(one_minus_decay * (s_param - param))\n</code></pre>"},{"location":"reference/models/ema/#discrete_diffusion.models.ema.create_ema","title":"<code>create_ema(parameters, decay)</code>","text":"<p>Construct the EMA helper for the provided parameter iterable.</p> Source code in <code>src/discrete_diffusion/models/ema.py</code> <pre><code>def create_ema(parameters, decay: float):\n  \"\"\"Construct the EMA helper for the provided parameter iterable.\"\"\"\n  return ExponentialMovingAverage(parameters, decay=decay)\n</code></pre>"},{"location":"reference/models/encoder_decoder/","title":"Encoder-Decoder","text":""},{"location":"reference/models/encoder_decoder/#discrete_diffusion.models.encoder_decoder","title":"<code>discrete_diffusion.models.encoder_decoder</code>","text":""},{"location":"reference/models/encoder_decoder/#discrete_diffusion.models.encoder_decoder.Decoder","title":"<code>Decoder</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>src/discrete_diffusion/models/encoder_decoder.py</code> <pre><code>class Decoder(nn.Module):\n  def __init__(self, n_blocks, dim, n_heads, cond_dim, \n               mlp_ratio, dropout, adaLN, model_length, \n               swap_pre_query_mode, swap_query_process_mode, \n               swap_normalize_mode):\n    super().__init__()\n\n    self.hidden_dim = dim\n    self.n_heads = n_heads\n    self.cond_dim = cond_dim\n    self.mlp_ratio = mlp_ratio\n    self.adaLN = adaLN\n    self.model_length = model_length\n    self.dropout = dropout\n    self.n_blocks = n_blocks\n    self.swap_pre_query_mode = swap_pre_query_mode\n    self.group_swap = GroupSwapLayer(dim, n_heads, \n                swap_pre_query_mode, swap_query_process_mode, \n                model_length, swap_normalize_mode)\n\n    self.layers = nn.ModuleList([self._make_cross_attn_block() \n                                for _ in range(self.n_blocks)])\n\n  def _make_cross_attn_block(self):\n    return CrossAttnDDiTBlock(\n      self.hidden_dim, self.n_heads, self.adaLN, self.cond_dim, \n      self.mlp_ratio, self.dropout)\n\n  def forward(\n    self, \n    encoder_output,\n    t_cond, \n    rotary_cos_sin_queries, \n    rotary_cos_sin_keys, \n    self_attn_mask,\n    # Training\n    group_idxs, \n    # Inference\n    position_queries,\n    concrete_lengths_keys, \n    use_inference_mode,\n  ):\n    \"\"\"\n    1. Apply GroupSwap -&gt; prepare cross attention mask\n    2. Apply layers\n    \"\"\"\n    if not use_inference_mode:  # Training / Valid\n      cross_attn_mask = make_group_cross_attn_mask(group_idxs)\n      q_len = self.model_length\n    else:  # Sampling\n      # TODO: Make sure we don't attend to pad tokens\n      q_len = position_queries.shape[1]\n      kv_len = encoder_output.shape[1]\n      cross_attn_mask = make_inference_cross_attn_mask(\n        kv_len, q_len, concrete_lengths_keys)\n      # IMPORTANT NOTE: during inference, the self attention \n      #  mask is different than during training, since the\n      #  decoder input has a different shape than the encoder\n      #  input.\n      del self_attn_mask  # will not be used\n\n    x = self.group_swap(encoder_output, rotary_cos_sin_queries,\n      rotary_cos_sin_keys, group_idxs, position_queries, \n      concrete_lengths_keys, cross_attn_mask, use_inference_mode)\n\n    for layer in self.layers:\n      if isinstance(layer, DDiTBlock):  # self attention\n        x = layer(x, t_cond, rotary_cos_sin_queries, \n                  self_attn_mask)\n      else:  # cross attention\n        x = layer(\n          q_x=x,\n          kv_x=encoder_output,\n          t_cond=t_cond, \n          rotary_cos_sin_queries=rotary_cos_sin_queries,\n          rotary_cos_sin_keys=rotary_cos_sin_keys,\n          attn_mask=cross_attn_mask)\n    return x\n</code></pre>"},{"location":"reference/models/encoder_decoder/#discrete_diffusion.models.encoder_decoder.Decoder.forward","title":"<code>forward(encoder_output, t_cond, rotary_cos_sin_queries, rotary_cos_sin_keys, self_attn_mask, group_idxs, position_queries, concrete_lengths_keys, use_inference_mode)</code>","text":"<ol> <li>Apply GroupSwap -&gt; prepare cross attention mask</li> <li>Apply layers</li> </ol> Source code in <code>src/discrete_diffusion/models/encoder_decoder.py</code> <pre><code>def forward(\n  self, \n  encoder_output,\n  t_cond, \n  rotary_cos_sin_queries, \n  rotary_cos_sin_keys, \n  self_attn_mask,\n  # Training\n  group_idxs, \n  # Inference\n  position_queries,\n  concrete_lengths_keys, \n  use_inference_mode,\n):\n  \"\"\"\n  1. Apply GroupSwap -&gt; prepare cross attention mask\n  2. Apply layers\n  \"\"\"\n  if not use_inference_mode:  # Training / Valid\n    cross_attn_mask = make_group_cross_attn_mask(group_idxs)\n    q_len = self.model_length\n  else:  # Sampling\n    # TODO: Make sure we don't attend to pad tokens\n    q_len = position_queries.shape[1]\n    kv_len = encoder_output.shape[1]\n    cross_attn_mask = make_inference_cross_attn_mask(\n      kv_len, q_len, concrete_lengths_keys)\n    # IMPORTANT NOTE: during inference, the self attention \n    #  mask is different than during training, since the\n    #  decoder input has a different shape than the encoder\n    #  input.\n    del self_attn_mask  # will not be used\n\n  x = self.group_swap(encoder_output, rotary_cos_sin_queries,\n    rotary_cos_sin_keys, group_idxs, position_queries, \n    concrete_lengths_keys, cross_attn_mask, use_inference_mode)\n\n  for layer in self.layers:\n    if isinstance(layer, DDiTBlock):  # self attention\n      x = layer(x, t_cond, rotary_cos_sin_queries, \n                self_attn_mask)\n    else:  # cross attention\n      x = layer(\n        q_x=x,\n        kv_x=encoder_output,\n        t_cond=t_cond, \n        rotary_cos_sin_queries=rotary_cos_sin_queries,\n        rotary_cos_sin_keys=rotary_cos_sin_keys,\n        attn_mask=cross_attn_mask)\n  return x\n</code></pre>"},{"location":"reference/models/encoder_decoder/#discrete_diffusion.models.encoder_decoder.make_inference_cross_attn_mask","title":"<code>make_inference_cross_attn_mask(keys_tensor_length, queries_tensor_length, concrete_lengths_keys)</code>","text":"<p>Queries positions == noisy positions Key positions == denoised positions Concrete length: number of denoised tokens in each                        element of the batch.</p> Source code in <code>src/discrete_diffusion/models/encoder_decoder.py</code> <pre><code>def make_inference_cross_attn_mask(\n    keys_tensor_length, \n    queries_tensor_length,\n    concrete_lengths_keys,):\n  \"\"\"\n  Queries positions == noisy positions\n  Key positions == denoised positions\n  Concrete length: number of denoised tokens in each \n                        element of the batch.\n  \"\"\"\n  arrange = torch.arange(keys_tensor_length, device=concrete_lengths_keys.device)\n  mask = arrange[None] &lt; concrete_lengths_keys[:, None]  # BS x KV_LEN\n  mask = mask[:, None, :]  # BS x 1 x KV_LEN\n  mask = mask.repeat(1, queries_tensor_length, 1)  # BS x Q_LEN x KV_LEN\n  return mask\n</code></pre>"},{"location":"reference/models/flexmdm/","title":"FlexMDM Transformer","text":""},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer","title":"<code>discrete_diffusion.models.flexmdm_transformer</code>","text":"<p>FlexMDM Transformer Model for Any-Order Mask Insertion Flow.</p> <p>This module implements the transformer architecture for FlexMDM, including adaptive layer normalization, rotary embeddings, and dual prediction heads for both token logits and expected gap lengths.</p>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.AnyOrderMaskInsertionFlow","title":"<code>AnyOrderMaskInsertionFlow</code>","text":"<p>               Bases: <code>Module</code></p> <p>FlexMDM Any-Order Mask Insertion Flow model.</p> <p>This model predicts both token logits and expected gap lengths for the joint insertion-masking process.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class AnyOrderMaskInsertionFlow(nn.Module):\n  \"\"\"FlexMDM Any-Order Mask Insertion Flow model.\n\n  This model predicts both token logits and expected gap lengths for\n  the joint insertion-masking process.\n  \"\"\"\n\n  def __init__(self, config, vocab_size: int):\n    super().__init__()\n    if isinstance(config, dict):\n      config = omegaconf.OmegaConf.create(config)\n\n    self.config = config\n    self.vocab_size = vocab_size\n    self.hidden_size = config.model.hidden_size\n    self.n_heads = config.model.n_heads\n    self.cond_dim = config.model.cond_dim\n    self.n_blocks = config.model.n_blocks\n    self.dropout = config.model.dropout\n\n    max_length = getattr(config.model, 'max_length', None)\n    if max_length is None:\n      max_length = getattr(config.model, 'length', None)\n    if max_length is None:\n      raise ValueError(\n        \"AnyOrderMaskInsertionFlow requires 'max_length' or 'length' in the model config.\"\n      )\n    self.max_length = max_length\n\n    # Get special tokens from config\n    self.pad_token = getattr(config.model, 'pad_token', 0)\n    self.mask_token = getattr(config.model, 'mask_token', None)\n\n    # Get loss function type\n    self.len_predict_type = getattr(config.model, 'len_predict_type', 'expectation')\n\n    self.vocab_embed = EmbeddingLayer(self.hidden_size, self.vocab_size)\n    self.sigma_map = TimestepEmbedder(self.cond_dim)\n    self.rotary_emb = Rotary(self.hidden_size // self.n_heads)\n\n    self.blocks = nn.ModuleList(\n      [\n        DDiTBlock(\n          self.hidden_size,\n          self.n_heads,\n          self.cond_dim,\n          dropout=self.dropout,\n        )\n        for _ in range(self.n_blocks)\n      ]\n    )\n\n    self.output_layer = DDitFinalLayer(\n      self.hidden_size, self.vocab_size, self.cond_dim\n    )\n\n    if self.len_predict_type == \"distribution\":\n      self.len_pred = DDitFinalLayer(\n        self.hidden_size,\n        self.max_length + 1,\n        self.cond_dim,\n      )\n    elif self.len_predict_type == \"expectation\":\n      self.len_pred = ScalarLengthHead(\n        self.hidden_size, self.max_length, self.cond_dim\n      )\n    else:\n      raise ValueError(\n        f\"Invalid length prediction type: {self.len_predict_type}\"\n      )\n\n  def forward(\n    self, indices: torch.Tensor, t: torch.Tensor\n  ) -&gt; ModelPrediction:\n    \"\"\"Forward pass.\n\n    Args:\n      indices: Token indices [B, L]\n      t: Timestep [B]\n\n    Returns:\n      ModelPrediction with token_logits and expected_gaps or length_posterior\n    \"\"\"\n    B, L = indices.shape\n\n    # Append padding token for length prediction\n    indices = torch.cat(\n      [\n        indices,\n        self.pad_token\n        * torch.ones((B, 1), device=indices.device, dtype=torch.int64),\n      ],\n      dim=-1,\n    )\n\n    seq_lens = (indices != self.pad_token).sum(dim=-1)\n    block_mask = create_block_mask(\n      get_mask_mod(seq_lens),\n      B=B,\n      H=None,\n      Q_LEN=indices.shape[1],\n      KV_LEN=indices.shape[1],\n    )\n\n    x = self.vocab_embed(indices)\n    c = F.silu(self.sigma_map(t))\n\n    rotary_cos_sin = self.rotary_emb(x)\n\n    with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n      for i in range(len(self.blocks)):\n        x = self.blocks[i](x, rotary_cos_sin, c, block_mask)\n\n      # Token logits (excluding the appended padding position)\n      token_logits = self.output_layer(x[:, :-1], c)\n\n      # Length prediction\n      if self.len_predict_type == \"distribution\":\n        length_posterior = self.len_pred(x, c)\n        return ModelPrediction(\n          token_logits=token_logits,\n          length_posterior=length_posterior,\n        )\n      else:  # expectation\n        return ModelPrediction(\n          token_logits=token_logits,\n          expected_gaps=self.len_pred(x, c),\n        )\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.AnyOrderMaskInsertionFlow.forward","title":"<code>forward(indices, t)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>Tensor</code> <p>Token indices [B, L]</p> required <code>t</code> <code>Tensor</code> <p>Timestep [B]</p> required <p>Returns:</p> Type Description <code>ModelPrediction</code> <p>ModelPrediction with token_logits and expected_gaps or length_posterior</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>def forward(\n  self, indices: torch.Tensor, t: torch.Tensor\n) -&gt; ModelPrediction:\n  \"\"\"Forward pass.\n\n  Args:\n    indices: Token indices [B, L]\n    t: Timestep [B]\n\n  Returns:\n    ModelPrediction with token_logits and expected_gaps or length_posterior\n  \"\"\"\n  B, L = indices.shape\n\n  # Append padding token for length prediction\n  indices = torch.cat(\n    [\n      indices,\n      self.pad_token\n      * torch.ones((B, 1), device=indices.device, dtype=torch.int64),\n    ],\n    dim=-1,\n  )\n\n  seq_lens = (indices != self.pad_token).sum(dim=-1)\n  block_mask = create_block_mask(\n    get_mask_mod(seq_lens),\n    B=B,\n    H=None,\n    Q_LEN=indices.shape[1],\n    KV_LEN=indices.shape[1],\n  )\n\n  x = self.vocab_embed(indices)\n  c = F.silu(self.sigma_map(t))\n\n  rotary_cos_sin = self.rotary_emb(x)\n\n  with torch.amp.autocast(\"cuda\", dtype=torch.bfloat16):\n    for i in range(len(self.blocks)):\n      x = self.blocks[i](x, rotary_cos_sin, c, block_mask)\n\n    # Token logits (excluding the appended padding position)\n    token_logits = self.output_layer(x[:, :-1], c)\n\n    # Length prediction\n    if self.len_predict_type == \"distribution\":\n      length_posterior = self.len_pred(x, c)\n      return ModelPrediction(\n        token_logits=token_logits,\n        length_posterior=length_posterior,\n      )\n    else:  # expectation\n      return ModelPrediction(\n        token_logits=token_logits,\n        expected_gaps=self.len_pred(x, c),\n      )\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.DDiTBlock","title":"<code>DDiTBlock</code>","text":"<p>               Bases: <code>Module</code></p> <p>Diffusion Transformer block with adaptive layer norm.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class DDiTBlock(nn.Module):\n  \"\"\"Diffusion Transformer block with adaptive layer norm.\"\"\"\n\n  def __init__(self, dim, n_heads, cond_dim, mlp_ratio=4, dropout=0.1):\n    super().__init__()\n    self.n_heads = n_heads\n\n    self.norm1 = LayerNorm(dim)\n    self.attn_qkv = nn.Linear(dim, 3 * dim, bias=False)\n    self.attn_out = nn.Linear(dim, dim, bias=False)\n    self.dropout1 = nn.Dropout(dropout)\n\n    self.norm2 = LayerNorm(dim)\n    self.mlp = nn.Sequential(\n      nn.Linear(dim, mlp_ratio * dim, bias=True),\n      nn.GELU(approximate=\"tanh\"),\n      nn.Linear(mlp_ratio * dim, dim, bias=True),\n    )\n    self.dropout2 = nn.Dropout(dropout)\n\n    self.dropout = dropout\n\n    self.adaLN_modulation = nn.Linear(cond_dim, 6 * dim, bias=True)\n    self.adaLN_modulation.weight.data.zero_()\n    self.adaLN_modulation.bias.data.zero_()\n\n  def _get_bias_dropout_scale(self):\n    return (\n      bias_dropout_add_scale_fused_train\n      if self.training\n      else bias_dropout_add_scale_fused_inference\n    )\n\n  def forward(self, x, rotary_cos_sin, c, block_mask):\n    batch_size = x.shape[0]\n\n    bias_dropout_scale_fn = self._get_bias_dropout_scale()\n\n    shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (\n      self.adaLN_modulation(c)[:, None].chunk(6, dim=2)\n    )\n\n    # Attention operation\n    x_skip = x\n    x = modulate_fused(self.norm1(x), shift_msa, scale_msa)\n\n    qkv = self.attn_qkv(x)\n    qkv = rearrange(\n      qkv, \"b s (three h d) -&gt; b s three h d\", three=3, h=self.n_heads\n    )\n    with torch.amp.autocast(\"cuda\", enabled=False):\n      cos, sin = rotary_cos_sin\n      qkv = apply_rotary_pos_emb(qkv, cos.to(qkv.dtype), sin.to(qkv.dtype))\n\n    q, k, v = rearrange(qkv, \"b s three h d -&gt; three b h s d\", three=3)\n\n    x = flex_attention(q, k, v, block_mask=block_mask)\n\n    x = rearrange(x, \"b h s d -&gt; b s (h d)\", b=batch_size)\n\n    x = bias_dropout_scale_fn(\n      self.attn_out(x), None, gate_msa, x_skip, self.dropout\n    )\n\n    # MLP operation\n    x = bias_dropout_scale_fn(\n      self.mlp(modulate_fused(self.norm2(x), shift_mlp, scale_mlp)),\n      None,\n      gate_mlp,\n      x,\n      self.dropout,\n    )\n\n    return x\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.DDitFinalLayer","title":"<code>DDitFinalLayer</code>","text":"<p>               Bases: <code>Module</code></p> <p>Final output layer with adaptive layer norm.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class DDitFinalLayer(nn.Module):\n  \"\"\"Final output layer with adaptive layer norm.\"\"\"\n\n  def __init__(self, hidden_size, out_channels, cond_dim):\n    super().__init__()\n    self.norm_final = LayerNorm(hidden_size)\n    self.linear = nn.Linear(hidden_size, out_channels)\n    self.linear.weight.data.zero_()\n    self.linear.bias.data.zero_()\n\n    self.adaLN_modulation = nn.Linear(cond_dim, 2 * hidden_size, bias=True)\n    self.adaLN_modulation.weight.data.zero_()\n    self.adaLN_modulation.bias.data.zero_()\n\n  def forward(self, x, c):\n    shift, scale = self.adaLN_modulation(c)[:, None].chunk(2, dim=2)\n    x = modulate_fused(self.norm_final(x), shift, scale)\n    x = self.linear(x)\n    return x\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.EmbeddingLayer","title":"<code>EmbeddingLayer</code>","text":"<p>               Bases: <code>Module</code></p> <p>Token embedding layer.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class EmbeddingLayer(nn.Module):\n  \"\"\"Token embedding layer.\"\"\"\n\n  def __init__(self, dim, vocab_dim):\n    super().__init__()\n    self.embedding = nn.Parameter(torch.empty((vocab_dim, dim)))\n    torch.nn.init.kaiming_uniform_(self.embedding, a=math.sqrt(5))\n\n  def forward(self, x):\n    return self.embedding[x]\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.LayerNorm","title":"<code>LayerNorm</code>","text":"<p>               Bases: <code>Module</code></p> <p>Layer normalization with learnable scale.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class LayerNorm(nn.Module):\n  \"\"\"Layer normalization with learnable scale.\"\"\"\n\n  def __init__(self, dim):\n    super().__init__()\n    self.weight = nn.Parameter(torch.ones([dim]))\n    self.dim = dim\n\n  def forward(self, x):\n    with torch.amp.autocast(\"cuda\", enabled=False):\n      x = F.layer_norm(x.float(), [self.dim])\n    return x * self.weight[None, None, :]\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.Rotary","title":"<code>Rotary</code>","text":"<p>               Bases: <code>Module</code></p> <p>Rotary positional embeddings.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class Rotary(torch.nn.Module):\n  \"\"\"Rotary positional embeddings.\"\"\"\n\n  def __init__(self, dim, base=10_000):\n    super().__init__()\n    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))\n    self.register_buffer(\"inv_freq\", inv_freq)\n    self.seq_len_cached = None\n    self.cos_cached = None\n    self.sin_cached = None\n\n  def forward(self, x, seq_dim=1):\n    seq_len = x.shape[seq_dim]\n    if seq_len != self.seq_len_cached:\n      self.seq_len_cached = seq_len\n      t = torch.arange(x.shape[seq_dim], device=x.device).type_as(\n        self.inv_freq\n      )\n      freqs = torch.einsum(\"i,j-&gt;ij\", t, self.inv_freq.clone())\n      emb = torch.cat((freqs, freqs), dim=-1).to(x.device)\n      # Dims: batch, seq_len, qkv, head, dim\n      self.cos_cached = emb.cos()[None, :, None, None, :].repeat(1, 1, 3, 1, 1)\n      self.sin_cached = emb.sin()[None, :, None, None, :].repeat(1, 1, 3, 1, 1)\n      # Make transformation on v an identity\n      self.cos_cached[:, :, 2, :, :].fill_(1.0)\n      self.sin_cached[:, :, 2, :, :].fill_(0.0)\n\n    return self.cos_cached, self.sin_cached\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.ScalarLengthHead","title":"<code>ScalarLengthHead</code>","text":"<p>               Bases: <code>Module</code></p> <p>Predicts expected gap lengths as scalars.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class ScalarLengthHead(nn.Module):\n  \"\"\"Predicts expected gap lengths as scalars.\"\"\"\n\n  def __init__(\n    self, d_model: int, normalized_len: int, cond_dim: Optional[int] = None\n  ):\n    super().__init__()\n    self.has_cond = cond_dim is not None\n    if self.has_cond:\n      self.adaLN = nn.Linear(cond_dim, 2 * d_model, bias=True)\n      self.adaLN.weight.data.zero_()\n      self.adaLN.bias.data.zero_()\n\n    self.norm = LayerNorm(d_model)\n    self.proj1 = nn.Linear(d_model, d_model)\n    self.act = nn.GELU()\n    self.proj2 = nn.Linear(d_model, 1)\n    self.softplus = nn.Softplus()\n    self.normalized_len = normalized_len\n\n  def forward(\n    self, x: torch.Tensor, c: Optional[torch.Tensor] = None\n  ) -&gt; torch.Tensor:\n    x_fp32 = x.float()\n    c_fp32 = c.float() if (self.has_cond and c is not None) else None\n    if self.has_cond and c_fp32 is not None:\n      shift, scale = self.adaLN(c_fp32)[:, None].chunk(2, dim=2)\n      x_fp32 = modulate_fused(self.norm(x_fp32), shift, scale)\n    else:\n      x_fp32 = self.norm(x_fp32)\n    s = self.proj2(self.act(self.proj1(x_fp32)))\n    out = self.softplus(s).squeeze(-1) * self.normalized_len\n    return out.to(x.dtype)\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.TimestepEmbedder","title":"<code>TimestepEmbedder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Embeds scalar timesteps into vector representations.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>class TimestepEmbedder(nn.Module):\n  \"\"\"Embeds scalar timesteps into vector representations.\"\"\"\n\n  def __init__(self, hidden_size, frequency_embedding_size=256):\n    super().__init__()\n    self.mlp = nn.Sequential(\n      nn.Linear(frequency_embedding_size, hidden_size, bias=True),\n      nn.SiLU(),\n      nn.Linear(hidden_size, hidden_size, bias=True),\n    )\n    self.frequency_embedding_size = frequency_embedding_size\n\n  @staticmethod\n  def timestep_embedding(t, dim, max_period=10000):\n    \"\"\"Create sinusoidal timestep embeddings.\"\"\"\n    half = dim // 2\n    freqs = torch.exp(\n      -math.log(max_period)\n      * torch.arange(start=0, end=half, dtype=torch.float32)\n      / half\n    ).to(device=t.device)\n    args = t[:, None].float() * freqs[None]\n    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n    if dim % 2:\n      embedding = torch.cat(\n        [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n      )\n    return embedding\n\n  def forward(self, t):\n    t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n    t_emb = self.mlp(t_freq)\n    return t_emb\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.TimestepEmbedder.timestep_embedding","title":"<code>timestep_embedding(t, dim, max_period=10000)</code>  <code>staticmethod</code>","text":"<p>Create sinusoidal timestep embeddings.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>@staticmethod\ndef timestep_embedding(t, dim, max_period=10000):\n  \"\"\"Create sinusoidal timestep embeddings.\"\"\"\n  half = dim // 2\n  freqs = torch.exp(\n    -math.log(max_period)\n    * torch.arange(start=0, end=half, dtype=torch.float32)\n    / half\n  ).to(device=t.device)\n  args = t[:, None].float() * freqs[None]\n  embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n  if dim % 2:\n    embedding = torch.cat(\n      [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n    )\n  return embedding\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.apply_rotary_pos_emb","title":"<code>apply_rotary_pos_emb(qkv, cos, sin)</code>","text":"<p>Apply rotary positional embeddings (uses flash_attn if available).</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>def apply_rotary_pos_emb(qkv, cos, sin):\n  \"\"\"Apply rotary positional embeddings (uses flash_attn if available).\"\"\"\n  try:\n    import flash_attn.layers.rotary\n\n    cos = cos[0, :, 0, 0, : cos.shape[-1] // 2]\n    sin = sin[0, :, 0, 0, : sin.shape[-1] // 2]\n    return flash_attn.layers.rotary.apply_rotary_emb_qkv_(qkv, cos, sin)\n  except ImportError:\n    return _apply_rotary_pos_emb_torchscript(qkv, cos, sin)\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.bias_dropout_add_scale_fused_inference","title":"<code>bias_dropout_add_scale_fused_inference(x, bias, scale, residual, prob)</code>","text":"<p>Fused bias-dropout-add-scale for inference.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>@torch.jit.script\ndef bias_dropout_add_scale_fused_inference(\n  x: Tensor,\n  bias: Optional[Tensor],\n  scale: Tensor,\n  residual: Optional[Tensor],\n  prob: float,\n) -&gt; Tensor:\n  \"\"\"Fused bias-dropout-add-scale for inference.\"\"\"\n  if bias is not None:\n    out = scale * (x + bias)\n  else:\n    out = scale * x\n  if residual is not None:\n    out = residual + out\n  return out\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.bias_dropout_add_scale_fused_train","title":"<code>bias_dropout_add_scale_fused_train(x, bias, scale, residual, prob)</code>","text":"<p>Fused bias-dropout-add-scale for training.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>@torch.jit.script\ndef bias_dropout_add_scale_fused_train(\n  x: Tensor,\n  bias: Optional[Tensor],\n  scale: Tensor,\n  residual: Optional[Tensor],\n  prob: float,\n) -&gt; Tensor:\n  \"\"\"Fused bias-dropout-add-scale for training.\"\"\"\n  if bias is not None:\n    out = scale * F.dropout(x + bias, p=prob, training=True)\n  else:\n    out = scale * F.dropout(x, p=prob, training=True)\n  if residual is not None:\n    out = residual + out\n  return out\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.get_mask_mod","title":"<code>get_mask_mod(seq_len)</code>","text":"<p>Create mask function for variable-length sequences.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>def get_mask_mod(seq_len: torch.Tensor):\n  \"\"\"Create mask function for variable-length sequences.\"\"\"\n  def mask_mod(b, h, q_idx, kv_idx):\n    return (q_idx &lt;= seq_len[b]) &amp; (kv_idx &lt;= seq_len[b])\n  return mask_mod\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.modulate_fused","title":"<code>modulate_fused(x, shift, scale)</code>","text":"<p>Fused modulation: x * (1 + scale) + shift.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>@torch.jit.script\ndef modulate_fused(x: Tensor, shift: Tensor, scale: Tensor) -&gt; Tensor:\n  \"\"\"Fused modulation: x * (1 + scale) + shift.\"\"\"\n  return x * (1 + scale) + shift\n</code></pre>"},{"location":"reference/models/flexmdm/#discrete_diffusion.models.flexmdm_transformer.rotate_half","title":"<code>rotate_half(x)</code>","text":"<p>Rotate half the hidden dims of the input.</p> Source code in <code>src/discrete_diffusion/models/flexmdm_transformer.py</code> <pre><code>def rotate_half(x):\n  \"\"\"Rotate half the hidden dims of the input.\"\"\"\n  x1, x2 = x[..., : x.shape[-1] // 2], x[..., x.shape[-1] // 2 :]\n  return torch.cat((-x2, x1), dim=-1)\n</code></pre>"},{"location":"reference/models/hf_gpt2/","title":"HF GPT2 Wrapper","text":""},{"location":"reference/models/hf_gpt2/#discrete_diffusion.models.hf_gpt2_wrapper","title":"<code>discrete_diffusion.models.hf_gpt2_wrapper</code>","text":"<p>Hugging Face GPT-2 wrapper compatible with diffusion trainers.</p>"},{"location":"reference/models/hf_gpt2/#discrete_diffusion.models.hf_gpt2_wrapper.HFGPT2Wrapper","title":"<code>HFGPT2Wrapper</code>","text":"<p>               Bases: <code>Module</code></p> <p>Minimal GPT-2 wrapper exposing a unified <code>forward</code> signature.</p> <p>Parameters mirror the upstream helper located in the super-project while adding light glue so that diffusion trainers can pass extra keyword arguments (e.g. <code>sigma</code>).</p> Source code in <code>src/discrete_diffusion/models/hf_gpt2_wrapper.py</code> <pre><code>class HFGPT2Wrapper(torch.nn.Module):\n  \"\"\"Minimal GPT-2 wrapper exposing a unified `forward` signature.\n\n  Parameters mirror the upstream helper located in the super-project while\n  adding light glue so that diffusion trainers can pass extra keyword\n  arguments (e.g. ``sigma``).\n  \"\"\"\n\n  def __init__(\n      self,\n      pretrained_model_name_or_path: str = 'gpt2',\n      bidirectional: bool = False,\n      attn_type: Optional[str] = None,\n      vocab_size: Optional[int] = None,\n      max_seq_len: Optional[int] = None):\n    super().__init__()\n\n    from transformers import AutoConfig, AutoModelForCausalLM\n\n    del max_seq_len  # Hydra parity; unused by HF GPT-2\n\n    config = AutoConfig.from_pretrained(pretrained_model_name_or_path)\n    self.model = AutoModelForCausalLM.from_pretrained(\n        pretrained_model_name_or_path,\n        config=config,\n    )\n\n    if attn_type is None:\n      self.attn_type = 'bidirectional' if bidirectional else 'causal'\n    else:\n      self.attn_type = attn_type\n\n    # No custom attention masks / annealing support\n\n    if (self.attn_type in ('bidirectional', 'custom')\n        and getattr(config, 'model_type', None) == 'gpt2'):\n      # Remove GPT-2 causal mask by marking attention bias as fully visible.\n      for block in self.model.transformer.h:\n        if hasattr(block.attn, 'bias') and block.attn.bias is not None:\n          block.attn.bias.fill_(True)\n\n    if isinstance(vocab_size, int) and vocab_size &gt; 0:\n      embeddings = self.model.get_input_embeddings()\n      if embeddings.weight.size(0) != vocab_size:\n        self.model.resize_token_embeddings(vocab_size, pad_to_multiple_of=2)\n\n    # Removed attention mask provider support\n\n  def forward(\n      self,\n      input_ids: torch.Tensor,\n      *unused_args,\n      src_key_padding_mask: Optional[torch.Tensor] = None,\n      t: Optional[torch.Tensor] = None,\n      return_insertion_count: bool = False,\n      **unused_kwargs) -&gt; torch.Tensor:\n    del src_key_padding_mask, t, return_insertion_count\n\n    kwargs = {\n        'input_ids': input_ids,\n        'use_cache': False,\n        'return_dict': False,\n    }\n\n    # No custom 4D attention mask injection\n\n    outputs = self.model(**kwargs)\n    logits = outputs[0]\n    return logits\n</code></pre>"},{"location":"reference/noise_schedules/base/","title":"Base Schedule","text":""},{"location":"reference/noise_schedules/base/#discrete_diffusion.noise_schedules.base","title":"<code>discrete_diffusion.noise_schedules.base</code>","text":"<p>Base interfaces for noise schedules used in discrete diffusion.</p> <p>Defines a stable <code>NoiseSchedule</code> protocol with continuous-time semantics and an adapter <code>ScheduleAdapter</code> that preserves the legacy call signature <code>schedule(t) -&gt; (alpha_prime_t, alpha_t)</code> used throughout existing trainers.</p>"},{"location":"reference/noise_schedules/base/#discrete_diffusion.noise_schedules.base.NoiseSchedule","title":"<code>NoiseSchedule</code>","text":"<p>               Bases: <code>Module</code></p> <p>Abstract base class for continuous-time noise schedules.</p> <p>Implementations should return attenuation factors <code>alpha(t)</code> in (0, 1] and their derivative <code>alpha'(t)</code> with respect to <code>t</code>. Some schedules may also provide a cumulative/\"total\" noise measure (e.g., required by SEDD).</p> Source code in <code>src/discrete_diffusion/noise_schedules/base.py</code> <pre><code>class NoiseSchedule(torch.nn.Module):\n  \"\"\"Abstract base class for continuous-time noise schedules.\n\n  Implementations should return attenuation factors `alpha(t)` in (0, 1] and\n  their derivative `alpha'(t)` with respect to `t`. Some schedules may also\n  provide a cumulative/\"total\" noise measure (e.g., required by SEDD).\n  \"\"\"\n\n  def __init__(self) -&gt; None:\n    super().__init__()\n\n  def alpha_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Return attenuation `alpha(t)` for timesteps `t` in [0, 1].\n\n    Args:\n      t: Tensor of shape `(B,)` or broadcastable to `(B, 1)` with dtype float.\n\n    Returns:\n      Tensor matching the shape of `t` (broadcastable) with values in (0, 1].\n    \"\"\"\n    raise NotImplementedError\n\n  def alpha_prime_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Return derivative `d/dt alpha(t)` for timesteps `t`.\n\n    Args:\n      t: Tensor of shape `(B,)` or broadcastable to `(B, 1)` with dtype float.\n\n    Returns:\n      Tensor broadcastable to the shape of `t`.\n    \"\"\"\n    raise NotImplementedError\n\n  def total_noise(self, t: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Optional cumulative noise measure for schedules that define it.\n\n    Implementations that do not support a total noise measure may raise\n    `NotImplementedError`. This is used by SEDD-style forward processes.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/noise_schedules/base/#discrete_diffusion.noise_schedules.base.NoiseSchedule.alpha_prime_t","title":"<code>alpha_prime_t(t)</code>","text":"<p>Return derivative <code>d/dt alpha(t)</code> for timesteps <code>t</code>.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Tensor of shape <code>(B,)</code> or broadcastable to <code>(B, 1)</code> with dtype float.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor broadcastable to the shape of <code>t</code>.</p> Source code in <code>src/discrete_diffusion/noise_schedules/base.py</code> <pre><code>def alpha_prime_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n  \"\"\"Return derivative `d/dt alpha(t)` for timesteps `t`.\n\n  Args:\n    t: Tensor of shape `(B,)` or broadcastable to `(B, 1)` with dtype float.\n\n  Returns:\n    Tensor broadcastable to the shape of `t`.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/noise_schedules/base/#discrete_diffusion.noise_schedules.base.NoiseSchedule.alpha_t","title":"<code>alpha_t(t)</code>","text":"<p>Return attenuation <code>alpha(t)</code> for timesteps <code>t</code> in [0, 1].</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Tensor of shape <code>(B,)</code> or broadcastable to <code>(B, 1)</code> with dtype float.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor matching the shape of <code>t</code> (broadcastable) with values in (0, 1].</p> Source code in <code>src/discrete_diffusion/noise_schedules/base.py</code> <pre><code>def alpha_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n  \"\"\"Return attenuation `alpha(t)` for timesteps `t` in [0, 1].\n\n  Args:\n    t: Tensor of shape `(B,)` or broadcastable to `(B, 1)` with dtype float.\n\n  Returns:\n    Tensor matching the shape of `t` (broadcastable) with values in (0, 1].\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/noise_schedules/base/#discrete_diffusion.noise_schedules.base.NoiseSchedule.total_noise","title":"<code>total_noise(t)</code>","text":"<p>Optional cumulative noise measure for schedules that define it.</p> <p>Implementations that do not support a total noise measure may raise <code>NotImplementedError</code>. This is used by SEDD-style forward processes.</p> Source code in <code>src/discrete_diffusion/noise_schedules/base.py</code> <pre><code>def total_noise(self, t: torch.Tensor) -&gt; torch.Tensor:\n  \"\"\"Optional cumulative noise measure for schedules that define it.\n\n  Implementations that do not support a total noise measure may raise\n  `NotImplementedError`. This is used by SEDD-style forward processes.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/noise_schedules/cosine/","title":"Cosine Schedule","text":""},{"location":"reference/noise_schedules/cosine/#discrete_diffusion.noise_schedules.cosine","title":"<code>discrete_diffusion.noise_schedules.cosine</code>","text":"<p>Cosine noise schedule implementation.</p>"},{"location":"reference/noise_schedules/cosine/#discrete_diffusion.noise_schedules.cosine.CosineNoiseSchedule","title":"<code>CosineNoiseSchedule</code>","text":"<p>               Bases: <code>NoiseSchedule</code></p> <p>Cosine-shaped retention schedule with epsilon trimming.</p> <p>alpha_base(t) = 1 - cos(pi/2 * (1 - t)) alpha(t) = (1 - 2eps) * alpha_base(t) + eps alpha'(t) = (1 - 2eps) * d/dt[alpha_base(t)]           = (1 - 2*eps) * ( - (pi/2) * sin(pi/2 * (1 - t)) )</p> Source code in <code>src/discrete_diffusion/noise_schedules/cosine.py</code> <pre><code>class CosineNoiseSchedule(NoiseSchedule):\n  \"\"\"Cosine-shaped retention schedule with epsilon trimming.\n\n  alpha_base(t) = 1 - cos(pi/2 * (1 - t))\n  alpha(t) = (1 - 2*eps) * alpha_base(t) + eps\n  alpha'(t) = (1 - 2*eps) * d/dt[alpha_base(t)]\n            = (1 - 2*eps) * ( - (pi/2) * sin(pi/2 * (1 - t)) )\n  \"\"\"\n\n  def __init__(self, eps: float = 1e-4):\n    super().__init__()\n    self.eps = float(eps)\n\n  def alpha_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    base = 1 - torch.cos(torch.pi / 2 * (1 - t))\n    return (1 - 2 * self.eps) * base + self.eps\n\n  def alpha_prime_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    base_prime = -(torch.pi / 2) * torch.sin(torch.pi / 2 * (1 - t))\n    return (1 - 2 * self.eps) * base_prime\n</code></pre>"},{"location":"reference/noise_schedules/flex/","title":"Flex Schedule","text":""},{"location":"reference/noise_schedules/flex/#discrete_diffusion.noise_schedules.flex","title":"<code>discrete_diffusion.noise_schedules.flex</code>","text":"<p>FlexMDM schedule primitives and factory.</p>"},{"location":"reference/noise_schedules/flex/#discrete_diffusion.noise_schedules.flex.FlexSchedule","title":"<code>FlexSchedule</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Minimal interface matching FlexMDM's schedule objects.</p> Note <p>Flex noise schedules go from 0 to 1 (increasing noise/masking), while standard schedules go from 1 to 0 (decreasing signal). These should be unified in the future.</p> Source code in <code>src/discrete_diffusion/noise_schedules/flex.py</code> <pre><code>class FlexSchedule(abc.ABC):\n  \"\"\"Minimal interface matching FlexMDM's schedule objects.\n\n  Note:\n      Flex noise schedules go from 0 to 1 (increasing noise/masking), while\n      standard schedules go from 1 to 0 (decreasing signal). These should be\n      unified in the future.\n  \"\"\"\n\n  @abc.abstractmethod\n  def at(self, t: Tensor) -&gt; Tensor:\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def derivative_at(self, t: Tensor) -&gt; Tensor:\n    raise NotImplementedError\n\n  @abc.abstractmethod\n  def inv(self, alpha: Tensor) -&gt; Tensor:\n    raise NotImplementedError\n\n  def rate_scale_factor(self, t: Tensor) -&gt; Tensor:\n    denom = (1 - self.at(t)).clamp_min(1e-6)\n    return self.derivative_at(t) / denom\n\n  def sample(self, shape: tuple[int, ...], device: torch.device) -&gt; Tensor:\n    uniform = torch.rand(shape, device=device)\n    return self.inv(uniform)\n\n  def sample_truncated(\n    self, threshold: Tensor, shape: tuple[int, ...], device: torch.device\n  ) -&gt; Tensor:\n    uniform = torch.rand(shape, device=device)\n    threshold_alpha = self.at(threshold)\n    return self.inv(uniform * (1 - threshold_alpha) + threshold_alpha)\n</code></pre>"},{"location":"reference/noise_schedules/flex/#discrete_diffusion.noise_schedules.flex.build_flex_schedule","title":"<code>build_flex_schedule(config)</code>","text":"<p>Instantiate a Flex-style schedule from a Hydra config snippet.</p> Source code in <code>src/discrete_diffusion/noise_schedules/flex.py</code> <pre><code>def build_flex_schedule(config: Mapping[str, Any] | None) -&gt; FlexSchedule:\n  \"\"\"Instantiate a Flex-style schedule from a Hydra config snippet.\"\"\"\n  cfg = _to_dict(config)\n  schedule_type = cfg.get(\"type\", \"linear\").lower()\n\n  if schedule_type == \"linear\":\n    return LinearSchedule()\n  if schedule_type == \"cosine\":\n    return CosineSchedule()\n  if schedule_type == \"sin\":\n    return SinSchedule()\n  if schedule_type == \"polynomial\":\n    if \"exp\" not in cfg:\n      raise ValueError(\"Polynomial schedule requires 'exp'.\")\n    return PolynomialSchedule(exp=float(cfg[\"exp\"]))\n  if schedule_type == \"geometric\":\n    missing = [k for k in (\"min\", \"max\") if k not in cfg]\n    if missing:\n      raise ValueError(f\"Geometric schedule missing keys: {missing}\")\n    return GeometricSchedule(min_val=float(cfg[\"min\"]), max_val=float(cfg[\"max\"]))\n\n  raise ValueError(f\"Unsupported Flex schedule type: {schedule_type}\")\n</code></pre>"},{"location":"reference/noise_schedules/geometric/","title":"Geometric Schedule","text":""},{"location":"reference/noise_schedules/geometric/#discrete_diffusion.noise_schedules.geometric","title":"<code>discrete_diffusion.noise_schedules.geometric</code>","text":"<p>Geometric noise schedule implementation.</p> <p>Provides <code>total_noise(t)</code> and <code>rate_noise(t)</code> used by SEDD-style processes. Alpha-based methods are intentionally not implemented since SEDD relies on the cumulative noise parameterization.</p>"},{"location":"reference/noise_schedules/geometric/#discrete_diffusion.noise_schedules.geometric.GeometricNoise","title":"<code>GeometricNoise</code>","text":"<p>               Bases: <code>NoiseSchedule</code></p> <p>Geometric schedule parameterized by sigma bounds.</p> <p>total_noise(t) = sigma_min^(1-t) * sigma_max^t rate_noise(t)  = total_noise(t) * (log(sigma_max) - log(sigma_min))</p> Source code in <code>src/discrete_diffusion/noise_schedules/geometric.py</code> <pre><code>class GeometricNoise(NoiseSchedule):\n  \"\"\"Geometric schedule parameterized by sigma bounds.\n\n  total_noise(t) = sigma_min^(1-t) * sigma_max^t\n  rate_noise(t)  = total_noise(t) * (log(sigma_max) - log(sigma_min))\n  \"\"\"\n\n  def __init__(self, sigma_min: float = 1e-4, sigma_max: float = 20.0):\n    super().__init__()\n    self.register_buffer('sigma_min', torch.tensor(float(sigma_min)))\n    self.register_buffer('sigma_max', torch.tensor(float(sigma_max)))\n\n  def alpha_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    return (-self.total_noise(t)).exp()\n\n  def alpha_prime_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    a = self.alpha_t(t)\n    return -a * self.rate_noise(t)\n\n  def total_noise(self, t: torch.Tensor) -&gt; torch.Tensor:\n    # Geometric interpolation in the sigma domain\n    return (self.sigma_min ** (1 - t)) * (self.sigma_max ** t)\n\n  def rate_noise(self, t: torch.Tensor) -&gt; torch.Tensor:\n    sig = self.total_noise(t)\n    return sig * (self.sigma_max.log() - self.sigma_min.log())\n</code></pre>"},{"location":"reference/noise_schedules/hybrid/","title":"Hybrid Schedule","text":""},{"location":"reference/noise_schedules/hybrid/#discrete_diffusion.noise_schedules.hybrid","title":"<code>discrete_diffusion.noise_schedules.hybrid</code>","text":"<p>Hybrid noise schedule implementation.</p>"},{"location":"reference/noise_schedules/linear/","title":"Linear Schedule","text":""},{"location":"reference/noise_schedules/linear/#discrete_diffusion.noise_schedules.linear","title":"<code>discrete_diffusion.noise_schedules.linear</code>","text":"<p>Linear noise schedule implementation.</p> <p>Alpha(t) decreases linearly from near 1 to near 0 with epsilon trimming.</p>"},{"location":"reference/noise_schedules/linear/#discrete_diffusion.noise_schedules.linear.LinearNoiseSchedule","title":"<code>LinearNoiseSchedule</code>","text":"<p>               Bases: <code>NoiseSchedule</code></p> <p>Linear attenuation schedule matching MD4 defaults.</p> <p>alpha(t) = (1 - 2eps) * (1 - t) + eps alpha'(t) = - (1 - 2eps)</p> Source code in <code>src/discrete_diffusion/noise_schedules/linear.py</code> <pre><code>class LinearNoiseSchedule(NoiseSchedule):\n  \"\"\"Linear attenuation schedule matching MD4 defaults.\n\n  alpha(t) = (1 - 2*eps) * (1 - t) + eps\n  alpha'(t) = - (1 - 2*eps)\n  \"\"\"\n\n  def __init__(self, eps: float = 1e-4):\n    super().__init__()\n    self.eps = float(eps)\n\n  def alpha_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    base = 1 - t\n    return (1 - 2 * self.eps) * base + self.eps\n\n  def alpha_prime_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    return -(1 - 2 * self.eps) * torch.ones_like(t)\n\n  def rate_scale_factor(self, t: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Return alpha_prime_t(t) / (1 - alpha_t(t)) for FlexMDM compatibility.\n\n    This is used in computing rate-based losses and sampling probabilities.\n    \"\"\"\n    return self.alpha_prime_t(t) / (1 - self.alpha_t(t))\n\n  def inv(self, alpha: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Return t such that alpha_t(t) = alpha (inverse function).\n\n    For linear schedule: alpha = (1 - 2*eps) * (1 - t) + eps\n    Solving for t: t = 1 - (alpha - eps) / (1 - 2*eps)\n    \"\"\"\n    return 1 - (alpha - self.eps) / (1 - 2 * self.eps)\n\n  def sample(self, shape: tuple, device: torch.device) -&gt; torch.Tensor:\n    \"\"\"Sample times uniformly from [0, 1].\n\n    For linear schedule, uniform sampling in t space is appropriate.\n    \"\"\"\n    return torch.rand(shape, device=device)\n\n  def sample_truncated(self, threshold: torch.Tensor, shape: tuple, \n                       device: torch.device) -&gt; torch.Tensor:\n    \"\"\"Sample times uniformly from [threshold, 1].\n\n    Args:\n      threshold: Lower bound(s) for time sampling (can be batched)\n      shape: Shape of samples to generate\n      device: Device for tensor creation\n    \"\"\"\n    uniform = torch.rand(shape, device=device)\n    # Convert threshold to alpha space and back for proper truncation\n    threshold_alpha = self.alpha_t(threshold)\n    # Sample uniformly between threshold_alpha and 0 (alpha at t=1)\n    sampled_alpha = uniform * (0 - threshold_alpha) + threshold_alpha\n    # Convert back to time space\n    return self.inv(sampled_alpha.clamp(min=self.eps))\n</code></pre>"},{"location":"reference/noise_schedules/linear/#discrete_diffusion.noise_schedules.linear.LinearNoiseSchedule.inv","title":"<code>inv(alpha)</code>","text":"<p>Return t such that alpha_t(t) = alpha (inverse function).</p> <p>For linear schedule: alpha = (1 - 2eps) * (1 - t) + eps Solving for t: t = 1 - (alpha - eps) / (1 - 2eps)</p> Source code in <code>src/discrete_diffusion/noise_schedules/linear.py</code> <pre><code>def inv(self, alpha: torch.Tensor) -&gt; torch.Tensor:\n  \"\"\"Return t such that alpha_t(t) = alpha (inverse function).\n\n  For linear schedule: alpha = (1 - 2*eps) * (1 - t) + eps\n  Solving for t: t = 1 - (alpha - eps) / (1 - 2*eps)\n  \"\"\"\n  return 1 - (alpha - self.eps) / (1 - 2 * self.eps)\n</code></pre>"},{"location":"reference/noise_schedules/linear/#discrete_diffusion.noise_schedules.linear.LinearNoiseSchedule.rate_scale_factor","title":"<code>rate_scale_factor(t)</code>","text":"<p>Return alpha_prime_t(t) / (1 - alpha_t(t)) for FlexMDM compatibility.</p> <p>This is used in computing rate-based losses and sampling probabilities.</p> Source code in <code>src/discrete_diffusion/noise_schedules/linear.py</code> <pre><code>def rate_scale_factor(self, t: torch.Tensor) -&gt; torch.Tensor:\n  \"\"\"Return alpha_prime_t(t) / (1 - alpha_t(t)) for FlexMDM compatibility.\n\n  This is used in computing rate-based losses and sampling probabilities.\n  \"\"\"\n  return self.alpha_prime_t(t) / (1 - self.alpha_t(t))\n</code></pre>"},{"location":"reference/noise_schedules/linear/#discrete_diffusion.noise_schedules.linear.LinearNoiseSchedule.sample","title":"<code>sample(shape, device)</code>","text":"<p>Sample times uniformly from [0, 1].</p> <p>For linear schedule, uniform sampling in t space is appropriate.</p> Source code in <code>src/discrete_diffusion/noise_schedules/linear.py</code> <pre><code>def sample(self, shape: tuple, device: torch.device) -&gt; torch.Tensor:\n  \"\"\"Sample times uniformly from [0, 1].\n\n  For linear schedule, uniform sampling in t space is appropriate.\n  \"\"\"\n  return torch.rand(shape, device=device)\n</code></pre>"},{"location":"reference/noise_schedules/linear/#discrete_diffusion.noise_schedules.linear.LinearNoiseSchedule.sample_truncated","title":"<code>sample_truncated(threshold, shape, device)</code>","text":"<p>Sample times uniformly from [threshold, 1].</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>Tensor</code> <p>Lower bound(s) for time sampling (can be batched)</p> required <code>shape</code> <code>tuple</code> <p>Shape of samples to generate</p> required <code>device</code> <code>device</code> <p>Device for tensor creation</p> required Source code in <code>src/discrete_diffusion/noise_schedules/linear.py</code> <pre><code>def sample_truncated(self, threshold: torch.Tensor, shape: tuple, \n                     device: torch.device) -&gt; torch.Tensor:\n  \"\"\"Sample times uniformly from [threshold, 1].\n\n  Args:\n    threshold: Lower bound(s) for time sampling (can be batched)\n    shape: Shape of samples to generate\n    device: Device for tensor creation\n  \"\"\"\n  uniform = torch.rand(shape, device=device)\n  # Convert threshold to alpha space and back for proper truncation\n  threshold_alpha = self.alpha_t(threshold)\n  # Sample uniformly between threshold_alpha and 0 (alpha at t=1)\n  sampled_alpha = uniform * (0 - threshold_alpha) + threshold_alpha\n  # Convert back to time space\n  return self.inv(sampled_alpha.clamp(min=self.eps))\n</code></pre>"},{"location":"reference/noise_schedules/log_linear/","title":"Log-Linear Schedule","text":""},{"location":"reference/noise_schedules/log_linear/#discrete_diffusion.noise_schedules.log_linear","title":"<code>discrete_diffusion.noise_schedules.log_linear</code>","text":"<p>Log-linear noise schedule implementation.</p>"},{"location":"reference/noise_schedules/log_linear/#discrete_diffusion.noise_schedules.log_linear.LogLinear","title":"<code>LogLinear</code>","text":"<p>               Bases: <code>NoiseSchedule</code></p> <p>Log-linear noise schedule: alpha(t) = 1 - (1-eps)*t.</p> Source code in <code>src/discrete_diffusion/noise_schedules/log_linear.py</code> <pre><code>class LogLinear(NoiseSchedule):\n  \"\"\"Log-linear noise schedule: alpha(t) = 1 - (1-eps)*t.\"\"\"\n\n  def __init__(self, eps: float = 1e-3, **kwargs):\n    super().__init__()\n    self.eps = float(eps)\n\n  def alpha_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    scaled_t = (1 - self.eps) * t\n    return 1 - scaled_t\n\n  def alpha_prime_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    return -(1 - self.eps) * torch.ones_like(t)\n</code></pre>"},{"location":"reference/sampling/absorbing/","title":"Absorbing Sampling","text":""},{"location":"reference/sampling/absorbing/#discrete_diffusion.sampling.absorbing","title":"<code>discrete_diffusion.sampling.absorbing</code>","text":"<p>Absorbing-state sampler for MDLM.</p>"},{"location":"reference/sampling/absorbing/#discrete_diffusion.sampling.absorbing.AbsorbingSampler","title":"<code>AbsorbingSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Sampler that mirrors Diffusion.generate_samples() for absorbing models.</p> Source code in <code>src/discrete_diffusion/sampling/absorbing.py</code> <pre><code>class AbsorbingSampler(Sampler):\n  \"\"\"Sampler that mirrors Diffusion.generate_samples() for absorbing models.\"\"\"\n\n  def __init__(self, config, forward_process=None):\n    self.config = config\n    self.forward_process = forward_process\n\n  def compute_posterior(self, model, x, t, dt, p_x0=None,\n                        noise_removal_step=False):\n    alpha_t = model.noise.alpha_t(t)\n    if noise_removal_step:\n      alpha_s = torch.ones_like(alpha_t)\n    else:\n      alpha_s = model.noise.alpha_t(t - dt)\n    assert alpha_t.ndim == 2\n    if p_x0 is None:\n      log_p_x0 = model.forward(\n        x, model._sigma_from_alphat(alpha_t))\n      if self.config.sampling.use_float64:\n        log_p_x0 = log_p_x0.to(torch.float64)\n      p_x0 = log_p_x0.exp()\n\n    sampled_x0 = sample_categorical(p_x0)\n    prob_denoise = (alpha_s - alpha_t) / (1 - alpha_t)\n    should_denoise_draw = (\n      torch.rand_like(x, dtype=torch.float64, device=x.device)\n      &lt; prob_denoise)\n    is_masked = (x == model.mask_id)\n    should_denoise_mask = is_masked &amp; should_denoise_draw\n    _x = torch.where(should_denoise_mask, sampled_x0, x)\n    out = torch.where(x != model.mask_id, x, _x)\n    return p_x0, out\n\n  @torch.no_grad()\n  def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n    if num_steps is None:\n      num_steps = self.config.sampling.steps\n    x = model.prior_sample(num_samples, model.num_tokens)\n    inject_bos = self.config.sampling.inject_bos if inject_bos is None else inject_bos\n    if inject_bos:\n      x[:, 0] = model.tokenizer.bos_token_id\n\n    timesteps = torch.linspace(1, eps, num_steps + 1, device=model.device)\n    dt = (1 - eps) / num_steps\n    p_x0_cache = None\n    predictor = self.config.sampling.predictor\n\n    for i in range(num_steps):\n      t = timesteps[i] * torch.ones(\n        x.shape[0], 1, device=model.device)\n      if predictor == 'ddpm':\n        _, x = self.compute_posterior(\n          model=model, x=x, t=t, dt=dt, p_x0=None)\n      elif predictor == 'ddpm_cache':\n        p_x0_cache, x_next = self.compute_posterior(\n          model=model, x=x, t=t, dt=dt, p_x0=p_x0_cache)\n        if (not torch.allclose(x_next, x)\n            or model.time_conditioning):\n          p_x0_cache = None\n        x = x_next\n      else:\n        raise ValueError(f'Unsupported predictor: {predictor}')\n\n    t0 = timesteps[-1] * torch.ones(x.shape[0], 1, device=model.device)\n\n    _, x = self.compute_posterior(\n      model=model, x=x, t=t0, dt=None,\n      p_x0=p_x0_cache,\n      noise_removal_step=True)\n\n    return x\n</code></pre>"},{"location":"reference/sampling/ar/","title":"Autoregressive Sampling","text":""},{"location":"reference/sampling/ar/#discrete_diffusion.sampling.ar","title":"<code>discrete_diffusion.sampling.ar</code>","text":"<p>Autoregressive sampler for AR model.</p>"},{"location":"reference/sampling/ar/#discrete_diffusion.sampling.ar.ARSampler","title":"<code>ARSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Sampler for autoregressive language models.</p> Source code in <code>src/discrete_diffusion/sampling/ar.py</code> <pre><code>class ARSampler(Sampler):\n  \"\"\"Sampler for autoregressive language models.\"\"\"\n\n  def __init__(self, config, forward_process=None):\n    self.config = config\n\n  @torch.no_grad()\n  def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n    \"\"\"Generate samples autoregressively from left to right.\n\n    Args:\n      model: The AR model instance.\n      num_samples: Number of samples to generate.\n      num_steps: Unused for AR (kept for API compatibility).\n      eps: Unused for AR (kept for API compatibility).\n      inject_bos: Whether to inject BOS token at position 0.\n\n    Returns:\n      Generated token sequences of shape [num_samples, num_tokens].\n    \"\"\"\n    del num_steps, eps  # Unused for AR\n\n    # Precompute token buffer\n    num_pred_tokens = model.num_tokens - 1\n    x = torch.zeros(\n      (num_samples, num_pred_tokens + 1),\n      dtype=torch.long,\n      device=model.device)\n    if inject_bos:\n      x[:, 0] = model.tokenizer.bos_token_id\n\n    # Precompute Gumbel noise for sampling\n    noise = (torch.distributions.Gumbel(0, 1)\n             .sample((num_samples, num_pred_tokens, model.vocab_size))\n             .to(model.device))\n    if self.config.sampling.use_float64:\n      noise = noise.to(torch.float64)\n\n    # Generate tokens autoregressively\n    for i in range(num_pred_tokens):\n      output = model.backbone(x[:, :i + 1], None)\n      output[:, :, model.mask_id] = model.neg_infinity\n      output = output.log_softmax(-1)\n      y = (output[:, -1, :] + noise[:, i, :]).argmax(-1)\n      x[:, i + 1] = y\n\n    return x\n</code></pre>"},{"location":"reference/sampling/ar/#discrete_diffusion.sampling.ar.ARSampler.generate","title":"<code>generate(model, *, num_samples, num_steps, eps, inject_bos)</code>","text":"<p>Generate samples autoregressively from left to right.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>The AR model instance.</p> required <code>num_samples</code> <p>Number of samples to generate.</p> required <code>num_steps</code> <p>Unused for AR (kept for API compatibility).</p> required <code>eps</code> <p>Unused for AR (kept for API compatibility).</p> required <code>inject_bos</code> <p>Whether to inject BOS token at position 0.</p> required <p>Returns:</p> Type Description <p>Generated token sequences of shape [num_samples, num_tokens].</p> Source code in <code>src/discrete_diffusion/sampling/ar.py</code> <pre><code>@torch.no_grad()\ndef generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n  \"\"\"Generate samples autoregressively from left to right.\n\n  Args:\n    model: The AR model instance.\n    num_samples: Number of samples to generate.\n    num_steps: Unused for AR (kept for API compatibility).\n    eps: Unused for AR (kept for API compatibility).\n    inject_bos: Whether to inject BOS token at position 0.\n\n  Returns:\n    Generated token sequences of shape [num_samples, num_tokens].\n  \"\"\"\n  del num_steps, eps  # Unused for AR\n\n  # Precompute token buffer\n  num_pred_tokens = model.num_tokens - 1\n  x = torch.zeros(\n    (num_samples, num_pred_tokens + 1),\n    dtype=torch.long,\n    device=model.device)\n  if inject_bos:\n    x[:, 0] = model.tokenizer.bos_token_id\n\n  # Precompute Gumbel noise for sampling\n  noise = (torch.distributions.Gumbel(0, 1)\n           .sample((num_samples, num_pred_tokens, model.vocab_size))\n           .to(model.device))\n  if self.config.sampling.use_float64:\n    noise = noise.to(torch.float64)\n\n  # Generate tokens autoregressively\n  for i in range(num_pred_tokens):\n    output = model.backbone(x[:, :i + 1], None)\n    output[:, :, model.mask_id] = model.neg_infinity\n    output = output.log_softmax(-1)\n    y = (output[:, -1, :] + noise[:, i, :]).argmax(-1)\n    x[:, i + 1] = y\n\n  return x\n</code></pre>"},{"location":"reference/sampling/base/","title":"Base Sampling","text":""},{"location":"reference/sampling/base/#discrete_diffusion.sampling.base","title":"<code>discrete_diffusion.sampling.base</code>","text":"<p>Sampler interface for discrete diffusion generation routines.</p>"},{"location":"reference/sampling/base/#discrete_diffusion.sampling.base.Sampler","title":"<code>Sampler</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base interface defining hooks used by all samplers.</p> <p>Samplers orchestrate the iterative generation process, managing the transition from noise to clean data.</p> Source code in <code>src/discrete_diffusion/sampling/base.py</code> <pre><code>class Sampler(ABC):\n  \"\"\"Base interface defining hooks used by all samplers.\n\n  Samplers orchestrate the iterative generation process, managing the\n  transition from noise to clean data.\n  \"\"\"\n\n  @abstractmethod\n  def generate(self, model: Any, *, num_samples: int, num_steps: int, eps: float,\n               inject_bos: bool) -&gt; Any:\n    \"\"\"Generate new samples from the provided model.\n\n    Args:\n        model: The trained model to sample from.\n        num_samples: Number of samples to generate.\n        num_steps: Number of sampling steps.\n        eps: Small epsilon for numerical stability or time bounds.\n        inject_bos: Whether to inject a Beginning-Of-Sequence token.\n\n    Returns:\n        Tensor: Generated samples.\n    \"\"\"\n    raise NotImplementedError\n\n  def compute_posterior(self, x: Any, t: Any, dt: Any, p_x0_cache: Optional[Any]) -&gt; Any:\n    \"\"\"Optional posterior computation hook for samplers that need incremental steps.\"\"\"\n    raise NotImplementedError\n\n  def step_analytic(self, x: Any, t: Any, dt: Any) -&gt; Any:\n    \"\"\"Optional analytic update hook for samplers that support closed-form steps.\"\"\"\n    raise NotImplementedError\n\n  def denoise(self, x: Any, t: Any) -&gt; Any:\n    \"\"\"Optional denoiser update hook for samplers that clean up predictions.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/sampling/base/#discrete_diffusion.sampling.base.Sampler.compute_posterior","title":"<code>compute_posterior(x, t, dt, p_x0_cache)</code>","text":"<p>Optional posterior computation hook for samplers that need incremental steps.</p> Source code in <code>src/discrete_diffusion/sampling/base.py</code> <pre><code>def compute_posterior(self, x: Any, t: Any, dt: Any, p_x0_cache: Optional[Any]) -&gt; Any:\n  \"\"\"Optional posterior computation hook for samplers that need incremental steps.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/sampling/base/#discrete_diffusion.sampling.base.Sampler.denoise","title":"<code>denoise(x, t)</code>","text":"<p>Optional denoiser update hook for samplers that clean up predictions.</p> Source code in <code>src/discrete_diffusion/sampling/base.py</code> <pre><code>def denoise(self, x: Any, t: Any) -&gt; Any:\n  \"\"\"Optional denoiser update hook for samplers that clean up predictions.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/sampling/base/#discrete_diffusion.sampling.base.Sampler.generate","title":"<code>generate(model, *, num_samples, num_steps, eps, inject_bos)</code>  <code>abstractmethod</code>","text":"<p>Generate new samples from the provided model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Any</code> <p>The trained model to sample from.</p> required <code>num_samples</code> <code>int</code> <p>Number of samples to generate.</p> required <code>num_steps</code> <code>int</code> <p>Number of sampling steps.</p> required <code>eps</code> <code>float</code> <p>Small epsilon for numerical stability or time bounds.</p> required <code>inject_bos</code> <code>bool</code> <p>Whether to inject a Beginning-Of-Sequence token.</p> required <p>Returns:</p> Name Type Description <code>Tensor</code> <code>Any</code> <p>Generated samples.</p> Source code in <code>src/discrete_diffusion/sampling/base.py</code> <pre><code>@abstractmethod\ndef generate(self, model: Any, *, num_samples: int, num_steps: int, eps: float,\n             inject_bos: bool) -&gt; Any:\n  \"\"\"Generate new samples from the provided model.\n\n  Args:\n      model: The trained model to sample from.\n      num_samples: Number of samples to generate.\n      num_steps: Number of sampling steps.\n      eps: Small epsilon for numerical stability or time bounds.\n      inject_bos: Whether to inject a Beginning-Of-Sequence token.\n\n  Returns:\n      Tensor: Generated samples.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/sampling/base/#discrete_diffusion.sampling.base.Sampler.step_analytic","title":"<code>step_analytic(x, t, dt)</code>","text":"<p>Optional analytic update hook for samplers that support closed-form steps.</p> Source code in <code>src/discrete_diffusion/sampling/base.py</code> <pre><code>def step_analytic(self, x: Any, t: Any, dt: Any) -&gt; Any:\n  \"\"\"Optional analytic update hook for samplers that support closed-form steps.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"reference/sampling/bd3lm/","title":"BD3LM Sampling","text":""},{"location":"reference/sampling/bd3lm/#discrete_diffusion.sampling.bd3lm","title":"<code>discrete_diffusion.sampling.bd3lm</code>","text":"<p>Sampler implementation for BD3LM block-diffusion models.</p>"},{"location":"reference/sampling/bd3lm/#discrete_diffusion.sampling.bd3lm.BD3LMSampler","title":"<code>BD3LMSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Sampler that mirrors BD3LM's legacy sampling helpers.</p> Source code in <code>src/discrete_diffusion/sampling/bd3lm.py</code> <pre><code>class BD3LMSampler(Sampler):\n  \"\"\"Sampler that mirrors BD3LM's legacy sampling helpers.\"\"\"\n\n  def __init__(self, config, forward_process=None) -&gt; None:\n    self.config = config\n\n  def _nucleus_sample(self, model, p_x0: torch.Tensor) -&gt; torch.Tensor:\n    p = getattr(self.config.sampling, 'p_nucleus', 1.0)\n    if p == 1.0:\n      return p_x0\n    block_size = model.block_size\n    p_x0_block = p_x0[:, -block_size:].clone()\n    sorted_probs, sorted_indices = p_x0_block.sort(dim=-1, descending=True)\n    cum_probs = sorted_probs.cumsum(dim=-1)\n    nucleus_mask = cum_probs &lt;= p\n    nucleus_mask[..., 0] = 1\n    sorted_probs = sorted_probs * nucleus_mask\n    p_x0_block.scatter_(-1, sorted_indices, sorted_probs)\n    p_x0_block /= p_x0_block.sum(-1, keepdim=True)\n    p_x0[:, -block_size:] = p_x0_block\n    return p_x0\n\n  def compute_posterior(self, model, x, t, dt, p_x0=None):\n    _, move_chance_t = model.noise.forward(t)\n    _, move_chance_s = model.noise.forward(t - dt)\n    sigma_t = model._sigma_from_p(move_chance_t)\n    move_chance_t = move_chance_t[:, None]\n    move_chance_s = move_chance_s[:, None]\n    mask_prob = move_chance_s / move_chance_t\n\n    if p_x0 is None:\n      if getattr(self.config.sampling, 'kv_cache', False):\n        p_x0 = model.forward(\n          x[:, -model.block_size:], sigma_t,\n          sample_mode=True).to(torch.float64)\n      else:\n        p_x0 = model.forward(x, sigma_t, sample_mode=True).to(torch.float64)\n        p_x0 = p_x0[:, -model.block_size:]\n      p_x0 = p_x0.exp()\n      p_x0 = self._nucleus_sample(model, p_x0)\n\n    if getattr(self.config.sampling, 'first_hitting', True):\n      x_block = sample_categorical(p_x0)\n      mask_region = (x[:, -model.block_size:] == model.mask_id)\n      num_masked = mask_region.sum(-1)\n      replace_idx = []\n      for row_mask in mask_region:\n        positions = torch.nonzero(row_mask, as_tuple=False).squeeze(-1)\n        if positions.numel() == 0:\n          replace_idx.append(torch.tensor(0, device=x.device))\n        else:\n          choice = torch.randint(\n            0, positions.numel(), (1,), device=x.device).squeeze()\n          replace_idx.append(positions[choice])\n      replace_idx = torch.stack(replace_idx)\n      mask = (torch.arange(model.block_size, device=x.device)\n              == replace_idx[:, None]).to(x_block.dtype)\n      x_block = x_block * mask + x[:, -model.block_size:] * (1 - mask)\n    else:\n      q_xs = p_x0 * (1 - mask_prob)\n      q_xs[:, :, model.mask_id] = mask_prob.squeeze(-1)\n      x_block = sample_categorical(q_xs)\n    copy_flag = (x[:, -model.block_size:] != model.mask_id).to(x.dtype)\n    x_block = copy_flag * x[:, -model.block_size:] + (1 - copy_flag) * x_block\n    x_new = torch.cat((x[:, :-model.block_size], x_block), dim=-1)\n\n    if (getattr(self.config.sampling, 'kv_cache', False)\n        and model.mask_id not in x_block):\n      _ = model.forward(x_block, sigma_t, sample_mode=True, store_kv=True)\n\n    if not torch.allclose(x_new, x):\n      return None, x_new\n    return p_x0, x_new\n\n\n  def _compute_entropy(self, x):\n    _, counts = torch.unique(x, return_counts=True, sorted=False)\n    entropy = torch.special.entr(counts.float() / counts.sum()).sum()\n    return entropy\n\n  def _check_stop_conds(self, model, x):\n    stop = False\n    truncate_idx = None\n    entropy = self._compute_entropy(x[:, -256:])\n    if entropy &lt; 4:\n      stop = True\n    if getattr(self.config.sampling, 'var_length', False):\n      eos_positions = torch.where(x == model.tokenizer.eos_token_id)\n      if len(eos_positions[0]) &gt; 1:\n        stop = True\n        truncate_idx = min(eos_positions[1][1] + 1, x.shape[1])\n      if entropy &lt; 4:\n        stop = True\n        truncate_idx = x.shape[1] - 256\n    if truncate_idx is not None:\n      x = x[:, :truncate_idx]\n      if x.ndim == 1:\n        x = x.unsqueeze(0)\n    return stop, x\n\n  def _semi_ar_sampler(self, model, num_steps, seqlen, inject_bos):\n    n_samples = 1\n    ones = torch.ones((n_samples, 1), dtype=model.dtype, device=model.device)\n    if getattr(self.config.sampling, 'kv_cache', False):\n      reset_fn = getattr(model.backbone, 'reset_kv_cache', None)\n      if callable(reset_fn):\n        reset_fn()\n    sampling_steps = 0\n    mdlm_semi_ar = (\n      getattr(self.config.algo, 'name', '') == 'mdlm'\n      and self.config.model.length &gt; model.block_size)\n    num_strides = seqlen // model.block_size\n    x_accum = None\n\n    for stride_num in range(num_strides):\n      if stride_num == 0:\n        x_accum = model.prior_sample(n_samples, model.block_size)\n        if inject_bos:\n          x_accum[:, 0] = model.tokenizer.bos_token_id\n      else:\n        stride = 512 if (mdlm_semi_ar and stride_num &gt; 0) else model.block_size\n        x = model.prior_sample(n_samples, stride)\n        x_accum = torch.cat((x_accum, x), dim=1)\n\n      end_idx = (stride_num + 1) * model.block_size\n      start_idx = max(end_idx - 1024, 0)\n      fwd_idx = torch.arange(start_idx, end_idx, device=model.device)\n      if mdlm_semi_ar and stride_num &gt; 0:\n        fwd_idx = torch.arange(\n          512 * stride_num,\n          512 * stride_num + model.block_size,\n          device=model.device)\n\n      dt = 1 / max(num_steps, 1)\n      p_x0_cache = None\n      timesteps = torch.linspace(1, 0, num_steps, device=model.device)\n      current_t = torch.tensor(1.0, device=model.device, dtype=torch.float32)\n\n      for idx in range(num_steps):\n        if model.mask_id not in x_accum:\n          break\n        if getattr(self.config.sampling, 'first_hitting', True):\n          u = np.random.rand()\n          num_masked = (x_accum[:, fwd_idx] == model.mask_id).sum(-1).item()\n          num_masked = max(num_masked, 1)\n          current_t *= u ** (1 / num_masked)\n        else:\n          current_t = timesteps[idx]\n        p_x0_cache, x_next = self.compute_posterior(\n          model=model,\n          x=x_accum[:, fwd_idx],\n          t=current_t * ones,\n          dt=dt,\n          p_x0=p_x0_cache)\n        if p_x0_cache is None:\n          sampling_steps += 1\n        x_accum[:, fwd_idx] = x_next\n\n      if x_accum.shape[1] &gt; 256:\n        stop, x_accum = self._check_stop_conds(model, x_accum)\n        if stop:\n          return None, None\n    return x_accum, sampling_steps\n\n\n  def _sample_once(self, model, num_steps, eps, inject_bos):\n    seqlen = self.config.model.length\n    attempts = 0\n    max_attempts = 10\n    while attempts &lt; max_attempts:\n      sample, nfes = self._semi_ar_sampler(\n        model=model,\n        num_steps=num_steps,\n        seqlen=seqlen,\n        inject_bos=inject_bos)\n      if sample is not None:\n        return sample, nfes\n      attempts += 1\n    raise ValueError('Sampling failed.')\n\n  def _update_metrics(self, model, nfes):\n    if hasattr(model.metrics, 'nfes'):\n      model.metrics.nfes.update(nfes)\n    if hasattr(model.metrics, 'gen_nfes'):\n      model.metrics.gen_nfes.append(nfes)\n\n  @torch.no_grad()\n  def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n    if num_samples is None:\n      num_samples = self.config.loader.eval_batch_size\n    if num_steps is None:\n      num_steps = getattr(self.config.algo, 'T', 0)\n    if inject_bos is None:\n      inject_bos = getattr(self.config.sampling, 'inject_bos', True)\n\n    samples = []\n    nfes_records = []\n    for _ in range(num_samples):\n      sample, nfes = self._sample_once(\n        model=model,\n        num_steps=num_steps,\n        eps=eps,\n        inject_bos=inject_bos)\n      samples.append(sample)\n      if nfes is not None:\n        nfes_records.append(nfes)\n        self._update_metrics(model, nfes)\n    return torch.cat(samples, dim=0)\n</code></pre>"},{"location":"reference/sampling/candi/","title":"CANDI Sampling","text":""},{"location":"reference/sampling/candi/#discrete_diffusion.sampling.candi_sampler","title":"<code>discrete_diffusion.sampling.candi_sampler</code>","text":"<p>Hybrid sampler for CANDI.</p>"},{"location":"reference/sampling/candi/#discrete_diffusion.sampling.candi_sampler.CANDI_Sampler","title":"<code>CANDI_Sampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Base inference method that implements helper functions needed for CANDI</p> Source code in <code>src/discrete_diffusion/sampling/candi_sampler.py</code> <pre><code>class CANDI_Sampler(Sampler):\n    \"\"\"Base inference method that implements helper functions needed for CANDI\"\"\"\n\n    def __init__(self, config, forward_process=None, **kwargs):\n        self.config = config\n        self.forward_process = forward_process\n        self.num_steps = config.sampling.steps\n        self.step_size = getattr(config.sampling, 'step_size', 1.0)\n\n\n    def _continuous_step(\n        self,\n        model,\n        x: torch.Tensor,\n        time_t: torch.Tensor,\n        time_s: torch.Tensor,\n        sigma_s: torch.Tensor,\n        sigma_t: torch.Tensor,\n        embedding_cache: torch.Tensor,\n        reveal_mask: torch.Tensor = None,\n    ) -&gt; torch.Tensor:\n        dt = sigma_s - sigma_t\n        time_t_vec = torch.ones(x.shape[0], device=x.device) * time_t.item()\n        sigma_t_vec = torch.ones(x.shape[0], device=x.device) * sigma_t.item()\n        if reveal_mask is None:\n            reveal_mask = torch.zeros(x.shape[:-1], device=x.device)\n        cond_denoised = model.forward(\n            xt=x,\n            discrete_noise=time_t_vec,\n            reveal_mask=reveal_mask,\n            continuous_noise=sigma_t_vec,\n            embedding=embedding_cache,\n        ).double()\n\n        denoised = cond_denoised.exp()\n        x0_hat = sample_categorical(denoised)\n        embedding_hat = model.backbone.get_embedding(x0_hat)\n        d = (embedding_cache - embedding_hat) / (sigma_t**2)\n        new_embedding_cache = embedding_cache - dt * d * self.step_size\n        return new_embedding_cache, x0_hat\n\n    def _discrete_step(\n        self, x0_hat, xt, t, dt, prev_clean_mask, noise_removal_step=False\n    ):\n        if noise_removal_step:\n            s = 0\n        else:\n            s = t - dt\n\n        unmask = (\n            torch.rand(prev_clean_mask.shape, device=prev_clean_mask.device)\n            &lt; (t - s) / t\n        )\n        xt[~prev_clean_mask] = x0_hat[~prev_clean_mask]\n        new_clean_mask = prev_clean_mask | unmask\n        return xt, new_clean_mask\n\n    @torch.no_grad()\n    def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n        if num_steps is None:\n            num_steps = self.config.sampling.steps\n\n        x = model.prior_sample(num_samples, model.num_tokens)\n        embedding_cache = model.backbone.get_embedding(x)\n        timesteps = torch.linspace(0.999, eps, num_steps + 1, device=model.device)\n        continuous_noise = model.noise.sigma_t(timesteps)\n        clean_mask = torch.zeros(\n            (num_samples, model.num_tokens), device=x.device, dtype=torch.bool\n        )\n        dt = (1 - eps) / (num_steps)\n\n        self.max_sigma = continuous_noise.max().item()\n        x = x.argmax(dim=-1)\n        if inject_bos:\n            x[:, 0] = model.tokenizer.bos_token_id\n            embedding_cache[:, 0] = model.backbone.get_embedding(x[:, :1]).squeeze(1)\n            clean_mask[:, 0] = True\n        for i in range(num_steps):\n            t = timesteps[i]\n            s = timesteps[i + 1]\n\n            sigma_s = continuous_noise[i]\n            sigma_t = continuous_noise[i + 1]\n            embedding_cache, x0_hat = self._continuous_step(\n                model=model, \n                x=x,\n                time_t=t,\n                time_s=s,\n                sigma_s=sigma_s,\n                sigma_t=sigma_t,\n                reveal_mask=clean_mask.float(),\n                embedding_cache=embedding_cache,\n            )\n            x, clean_mask = self._discrete_step(\n                x0_hat, x, t, dt, prev_clean_mask=clean_mask, noise_removal_step=False\n            )\n        return x\n</code></pre>"},{"location":"reference/sampling/flexmdm/","title":"FlexMDM Sampling","text":""},{"location":"reference/sampling/flexmdm/#discrete_diffusion.sampling.flexmdm_anyorder","title":"<code>discrete_diffusion.sampling.flexmdm_anyorder</code>","text":"<p>FlexMDM Any-Order Sampler.</p> <p>This module implements the Euler sampling procedure for FlexMDM's any-order mask insertion flow, which jointly samples token content and sequence length.</p>"},{"location":"reference/sampling/flexmdm/#discrete_diffusion.sampling.flexmdm_anyorder.FlexMDMAnyOrderSampler","title":"<code>FlexMDMAnyOrderSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Sampler for FlexMDM any-order mask insertion flow.</p> <p>This implements Euler sampling for a joint process that both unmasks tokens and inserts new tokens (changing sequence length).</p> Source code in <code>src/discrete_diffusion/sampling/flexmdm_anyorder.py</code> <pre><code>class FlexMDMAnyOrderSampler(Sampler):\n  \"\"\"Sampler for FlexMDM any-order mask insertion flow.\n\n  This implements Euler sampling for a joint process that both unmasks\n  tokens and inserts new tokens (changing sequence length).\n  \"\"\"\n\n  def __init__(self, config, forward_process=None):\n    self.config = config\n\n  @torch.no_grad()\n  def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n    \"\"\"Generate samples using Euler sampling.\n\n    Args:\n      model: FlexMDM model with interpolant\n      num_samples: Number of samples to generate\n      num_steps: Number of sampling steps\n      eps: Small constant (unused, kept for interface compatibility)\n      inject_bos: Whether to inject BOS token at position 0.\n\n    Returns:\n      Generated token sequences [num_samples, max_length]\n    \"\"\"\n    del eps  # Unused\n\n    device = model.device\n    max_length = model.num_tokens\n    batch_size = num_samples\n\n    # Special tokens\n    mask_token = model.tokenizer.mask_token_id\n    pad_token = model.tokenizer.pad_token_id\n\n    # Initialize with all padding\n    xt = torch.full(\n      (batch_size, max_length), pad_token, dtype=torch.int64, device=device\n    )\n    if inject_bos:\n      xt[:, 0] = model.tokenizer.bos_token_id\n\n    dt = 1.0 / num_steps\n    t = torch.zeros(batch_size, device=device)\n\n    # Precompute indices for scatter operations\n    batch_idx_L = (\n      torch.arange(batch_size, device=device)\n      .view(batch_size, 1)\n      .expand(batch_size, max_length)\n    )\n    pos_idx_L = (\n      torch.arange(max_length, device=device)\n      .view(1, max_length)\n      .expand(batch_size, max_length)\n    )\n\n    for step_idx in range(num_steps):\n      # Get model predictions\n      prediction = model.forward(xt, t)\n      pred_rate = model.interpolant.to_actual_rate(xt, prediction, t)\n      unmask_rate = pred_rate.unmask_rate  # [B, L, V]\n      len_rate = pred_rate.length_rate  # [B, L+1]\n\n      # \u2014\u2014\u2014 Unmask step (Euler) \u2014\u2014\u2014\n      mask_pos = (xt == mask_token).nonzero(as_tuple=True)\n\n      # Zero out rates for non-masked positions\n      unmask_rate[xt != mask_token] = 0\n      # Zero out mask-to-mask transitions at masked positions\n      unmask_rate[*mask_pos, mask_token] = 0\n      # Set diagonal (stay at mask) to make rows sum to 0\n      unmask_rate[*mask_pos, mask_token] = -unmask_rate[*mask_pos, :].sum(\n        dim=1\n      )\n\n      # Convert rates to transition probabilities\n      trans_prob = (unmask_rate * dt).clamp(0.0, 1.0)\n\n      # Add \"stay\" probability for current tokens\n      _xt = xt.clone()\n      _xt[xt == pad_token] = mask_token\n      trans_prob.scatter_add_(\n        2,\n        _xt.unsqueeze(-1),\n        torch.ones_like(_xt.unsqueeze(-1), dtype=trans_prob.dtype),\n      )\n\n      # On final step, remove mask token from sampling\n      if step_idx == num_steps - 1:\n        trans_prob[*mask_pos, mask_token] = 0.0\n\n      # Sample new tokens\n      new_xt = _sample_tokens(trans_prob)\n      new_xt[xt == pad_token] = pad_token\n      new_xt = torch.where((xt != mask_token) &amp; (xt != pad_token), xt, new_xt)\n\n      # \u2014\u2014\u2014 Insertion step (only if not final step) \u2014\u2014\u2014\n      if step_idx != num_steps - 1:\n        # Sample number of tokens to insert at each gap\n        ext = torch.bernoulli((len_rate * dt).clamp(0.0, 1.0)).long()  # [B, L+1]\n\n        xt_len = xt.ne(pad_token).sum(dim=1)  # [B]\n\n        # Only insert at valid gaps (before current length)\n        gaps = torch.arange(max_length + 1, device=device).view(1, -1)\n        ext = ext * (gaps &lt;= xt_len.view(batch_size, 1)).long()\n\n        total_ext = ext.sum(dim=1)\n\n        # Check if insertion would exceed max_length\n        valid = xt_len + total_ext &lt;= max_length\n        ext = ext * valid.view(batch_size, 1).long()\n\n        # Compute cumulative extensions\n        ext_ex = ext.int().cumsum(dim=1)  # [B, L+1]\n        new_len = xt_len + total_ext  # [B]\n\n        # Create new sequence with insertions\n        xt_tmp = torch.full_like(xt, pad_token)\n        mask_fill = pos_idx_L &lt; new_len.view(batch_size, 1)\n        xt_tmp[mask_fill] = mask_token\n\n        # Scatter original tokens to new positions\n        new_pos_orig = pos_idx_L + ext_ex[:, :max_length]  # [B, L]\n        orig_mask = pos_idx_L &lt; xt_len.view(batch_size, 1)\n        flat_b = batch_idx_L[orig_mask]\n        flat_p = new_pos_orig[orig_mask]\n        xt_tmp[flat_b, flat_p] = new_xt[orig_mask]\n      else:\n        # Final step: no insertion\n        xt_tmp = new_xt\n\n      xt = xt_tmp\n      t = t + dt\n\n    return xt\n</code></pre>"},{"location":"reference/sampling/flexmdm/#discrete_diffusion.sampling.flexmdm_anyorder.FlexMDMAnyOrderSampler.generate","title":"<code>generate(model, *, num_samples, num_steps, eps, inject_bos)</code>","text":"<p>Generate samples using Euler sampling.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>FlexMDM model with interpolant</p> required <code>num_samples</code> <p>Number of samples to generate</p> required <code>num_steps</code> <p>Number of sampling steps</p> required <code>eps</code> <p>Small constant (unused, kept for interface compatibility)</p> required <code>inject_bos</code> <p>Whether to inject BOS token at position 0.</p> required <p>Returns:</p> Type Description <p>Generated token sequences [num_samples, max_length]</p> Source code in <code>src/discrete_diffusion/sampling/flexmdm_anyorder.py</code> <pre><code>@torch.no_grad()\ndef generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n  \"\"\"Generate samples using Euler sampling.\n\n  Args:\n    model: FlexMDM model with interpolant\n    num_samples: Number of samples to generate\n    num_steps: Number of sampling steps\n    eps: Small constant (unused, kept for interface compatibility)\n    inject_bos: Whether to inject BOS token at position 0.\n\n  Returns:\n    Generated token sequences [num_samples, max_length]\n  \"\"\"\n  del eps  # Unused\n\n  device = model.device\n  max_length = model.num_tokens\n  batch_size = num_samples\n\n  # Special tokens\n  mask_token = model.tokenizer.mask_token_id\n  pad_token = model.tokenizer.pad_token_id\n\n  # Initialize with all padding\n  xt = torch.full(\n    (batch_size, max_length), pad_token, dtype=torch.int64, device=device\n  )\n  if inject_bos:\n    xt[:, 0] = model.tokenizer.bos_token_id\n\n  dt = 1.0 / num_steps\n  t = torch.zeros(batch_size, device=device)\n\n  # Precompute indices for scatter operations\n  batch_idx_L = (\n    torch.arange(batch_size, device=device)\n    .view(batch_size, 1)\n    .expand(batch_size, max_length)\n  )\n  pos_idx_L = (\n    torch.arange(max_length, device=device)\n    .view(1, max_length)\n    .expand(batch_size, max_length)\n  )\n\n  for step_idx in range(num_steps):\n    # Get model predictions\n    prediction = model.forward(xt, t)\n    pred_rate = model.interpolant.to_actual_rate(xt, prediction, t)\n    unmask_rate = pred_rate.unmask_rate  # [B, L, V]\n    len_rate = pred_rate.length_rate  # [B, L+1]\n\n    # \u2014\u2014\u2014 Unmask step (Euler) \u2014\u2014\u2014\n    mask_pos = (xt == mask_token).nonzero(as_tuple=True)\n\n    # Zero out rates for non-masked positions\n    unmask_rate[xt != mask_token] = 0\n    # Zero out mask-to-mask transitions at masked positions\n    unmask_rate[*mask_pos, mask_token] = 0\n    # Set diagonal (stay at mask) to make rows sum to 0\n    unmask_rate[*mask_pos, mask_token] = -unmask_rate[*mask_pos, :].sum(\n      dim=1\n    )\n\n    # Convert rates to transition probabilities\n    trans_prob = (unmask_rate * dt).clamp(0.0, 1.0)\n\n    # Add \"stay\" probability for current tokens\n    _xt = xt.clone()\n    _xt[xt == pad_token] = mask_token\n    trans_prob.scatter_add_(\n      2,\n      _xt.unsqueeze(-1),\n      torch.ones_like(_xt.unsqueeze(-1), dtype=trans_prob.dtype),\n    )\n\n    # On final step, remove mask token from sampling\n    if step_idx == num_steps - 1:\n      trans_prob[*mask_pos, mask_token] = 0.0\n\n    # Sample new tokens\n    new_xt = _sample_tokens(trans_prob)\n    new_xt[xt == pad_token] = pad_token\n    new_xt = torch.where((xt != mask_token) &amp; (xt != pad_token), xt, new_xt)\n\n    # \u2014\u2014\u2014 Insertion step (only if not final step) \u2014\u2014\u2014\n    if step_idx != num_steps - 1:\n      # Sample number of tokens to insert at each gap\n      ext = torch.bernoulli((len_rate * dt).clamp(0.0, 1.0)).long()  # [B, L+1]\n\n      xt_len = xt.ne(pad_token).sum(dim=1)  # [B]\n\n      # Only insert at valid gaps (before current length)\n      gaps = torch.arange(max_length + 1, device=device).view(1, -1)\n      ext = ext * (gaps &lt;= xt_len.view(batch_size, 1)).long()\n\n      total_ext = ext.sum(dim=1)\n\n      # Check if insertion would exceed max_length\n      valid = xt_len + total_ext &lt;= max_length\n      ext = ext * valid.view(batch_size, 1).long()\n\n      # Compute cumulative extensions\n      ext_ex = ext.int().cumsum(dim=1)  # [B, L+1]\n      new_len = xt_len + total_ext  # [B]\n\n      # Create new sequence with insertions\n      xt_tmp = torch.full_like(xt, pad_token)\n      mask_fill = pos_idx_L &lt; new_len.view(batch_size, 1)\n      xt_tmp[mask_fill] = mask_token\n\n      # Scatter original tokens to new positions\n      new_pos_orig = pos_idx_L + ext_ex[:, :max_length]  # [B, L]\n      orig_mask = pos_idx_L &lt; xt_len.view(batch_size, 1)\n      flat_b = batch_idx_L[orig_mask]\n      flat_p = new_pos_orig[orig_mask]\n      xt_tmp[flat_b, flat_p] = new_xt[orig_mask]\n    else:\n      # Final step: no insertion\n      xt_tmp = new_xt\n\n    xt = xt_tmp\n    t = t + dt\n\n  return xt\n</code></pre>"},{"location":"reference/sampling/gidd/","title":"GIDD Sampling","text":""},{"location":"reference/sampling/gidd/#discrete_diffusion.sampling.gidd","title":"<code>discrete_diffusion.sampling.gidd</code>","text":"<p>GIDD sampler for hybrid diffusion models.</p>"},{"location":"reference/sampling/gidd/#discrete_diffusion.sampling.gidd.GIDDSampler","title":"<code>GIDDSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Sampler for GIDD (Generalized Iterative Discrete Diffusion) models.</p> Source code in <code>src/discrete_diffusion/sampling/gidd.py</code> <pre><code>class GIDDSampler(Sampler):\n  \"\"\"Sampler for GIDD (Generalized Iterative Discrete Diffusion) models.\"\"\"\n\n  def __init__(self, config, forward_process=None):\n    self.config = config\n\n  def compute_posterior(self, model, z_t, t, s):\n    \"\"\"Compute posterior q(z_s | z_t, x_0) for GIDD.\n\n    Args:\n      model: The GIDD model instance.\n      z_t: Current noisy samples at time t.\n      t: Current timestep.\n      s: Next (less noisy) timestep.\n\n    Returns:\n      Samples from the posterior distribution.\n    \"\"\"\n    # Get model prediction (logits)\n    sigma_t = model._sigma_from_alphat(model._loglinear.alpha_t(t))\n    sigma_t = model._process_sigma(sigma_t)\n    logits = model.backbone(z_t, sigma_t)\n\n    # Mask out the mask token from predictions\n    logits = logits.clone()\n    logits[..., model.mask_id] = model.neg_infinity\n    probs = logits.softmax(-1)\n\n    # Get noise schedule values\n    q_s = model.hybrid_noise.probs_at_t(probs, s)\n    q_t = model.hybrid_noise.probs_at_t(probs, t)\n    q_zt = q_t.gather(-1, z_t.unsqueeze(-1))\n\n    alpha_t, beta_pi_t = model.hybrid_noise.get_alpha_betapi(t)\n    alpha_s, beta_pi_s = model.hybrid_noise.get_alpha_betapi(s)\n\n    # Compute transition probabilities\n    alpha_ts = alpha_t / alpha_s\n    beta_pi_ts = beta_pi_t - alpha_t / alpha_s * beta_pi_s\n\n    vz_t = F.one_hot(z_t, num_classes=model.vocab_size)\n    beta_pi_ts_at_zt = beta_pi_ts.unsqueeze(1).expand_as(vz_t).gather(\n      -1, z_t.unsqueeze(-1))\n    q_ts = (alpha_ts * vz_t + beta_pi_ts_at_zt)\n\n    # Compute posterior\n    q_st = q_ts * q_s / q_zt\n\n    # Optional: apply minimum probability threshold\n    min_p = getattr(self.config.sampling, 'min_p', 0.0)\n    if min_p &gt; 0.0:\n      is_small = (q_st &lt; min_p).float()\n      q_st = (1 - is_small) * q_st\n      q_st = q_st / q_st.sum(-1, keepdim=True)\n\n    return sample_categorical(q_st)\n\n  @torch.no_grad()\n  def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n    \"\"\"Generate samples using GIDD reverse diffusion process.\n\n    Args:\n      model: The GIDD model instance.\n      num_samples: Number of samples to generate.\n      num_steps: Number of denoising steps.\n      eps: Minimum timestep value (epsilon).\n      inject_bos: Whether to inject BOS token at position 0.\n\n    Returns:\n      Generated token sequences of shape [num_samples, num_tokens].\n    \"\"\"\n    if num_steps is None:\n      num_steps = self.config.sampling.steps\n    if eps is None:\n      eps = getattr(self.config.algo, 't_eps', 1e-4)\n\n    # Sample from the prior (fully masked)\n    z_t = model.hybrid_noise.sample_prior(\n      (num_samples, model.num_tokens))\n    if inject_bos:\n      z_t[:, 0] = model.tokenizer.bos_token_id\n\n    # Create timestep schedule from 1-eps to eps\n    timesteps = torch.linspace(\n      1 - eps, eps, num_steps + 1, device=model.device)\n\n    # Iteratively denoise\n    for i in range(num_steps):\n      t = timesteps[i] * torch.ones(\n        num_samples, device=model.device)\n      s = timesteps[i + 1] * torch.ones(\n        num_samples, device=model.device)\n\n      z_t = self.compute_posterior(model, z_t, t, s)\n\n    return z_t\n</code></pre>"},{"location":"reference/sampling/gidd/#discrete_diffusion.sampling.gidd.GIDDSampler.compute_posterior","title":"<code>compute_posterior(model, z_t, t, s)</code>","text":"<p>Compute posterior q(z_s | z_t, x_0) for GIDD.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>The GIDD model instance.</p> required <code>z_t</code> <p>Current noisy samples at time t.</p> required <code>t</code> <p>Current timestep.</p> required <code>s</code> <p>Next (less noisy) timestep.</p> required <p>Returns:</p> Type Description <p>Samples from the posterior distribution.</p> Source code in <code>src/discrete_diffusion/sampling/gidd.py</code> <pre><code>def compute_posterior(self, model, z_t, t, s):\n  \"\"\"Compute posterior q(z_s | z_t, x_0) for GIDD.\n\n  Args:\n    model: The GIDD model instance.\n    z_t: Current noisy samples at time t.\n    t: Current timestep.\n    s: Next (less noisy) timestep.\n\n  Returns:\n    Samples from the posterior distribution.\n  \"\"\"\n  # Get model prediction (logits)\n  sigma_t = model._sigma_from_alphat(model._loglinear.alpha_t(t))\n  sigma_t = model._process_sigma(sigma_t)\n  logits = model.backbone(z_t, sigma_t)\n\n  # Mask out the mask token from predictions\n  logits = logits.clone()\n  logits[..., model.mask_id] = model.neg_infinity\n  probs = logits.softmax(-1)\n\n  # Get noise schedule values\n  q_s = model.hybrid_noise.probs_at_t(probs, s)\n  q_t = model.hybrid_noise.probs_at_t(probs, t)\n  q_zt = q_t.gather(-1, z_t.unsqueeze(-1))\n\n  alpha_t, beta_pi_t = model.hybrid_noise.get_alpha_betapi(t)\n  alpha_s, beta_pi_s = model.hybrid_noise.get_alpha_betapi(s)\n\n  # Compute transition probabilities\n  alpha_ts = alpha_t / alpha_s\n  beta_pi_ts = beta_pi_t - alpha_t / alpha_s * beta_pi_s\n\n  vz_t = F.one_hot(z_t, num_classes=model.vocab_size)\n  beta_pi_ts_at_zt = beta_pi_ts.unsqueeze(1).expand_as(vz_t).gather(\n    -1, z_t.unsqueeze(-1))\n  q_ts = (alpha_ts * vz_t + beta_pi_ts_at_zt)\n\n  # Compute posterior\n  q_st = q_ts * q_s / q_zt\n\n  # Optional: apply minimum probability threshold\n  min_p = getattr(self.config.sampling, 'min_p', 0.0)\n  if min_p &gt; 0.0:\n    is_small = (q_st &lt; min_p).float()\n    q_st = (1 - is_small) * q_st\n    q_st = q_st / q_st.sum(-1, keepdim=True)\n\n  return sample_categorical(q_st)\n</code></pre>"},{"location":"reference/sampling/gidd/#discrete_diffusion.sampling.gidd.GIDDSampler.generate","title":"<code>generate(model, *, num_samples, num_steps, eps, inject_bos)</code>","text":"<p>Generate samples using GIDD reverse diffusion process.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>The GIDD model instance.</p> required <code>num_samples</code> <p>Number of samples to generate.</p> required <code>num_steps</code> <p>Number of denoising steps.</p> required <code>eps</code> <p>Minimum timestep value (epsilon).</p> required <code>inject_bos</code> <p>Whether to inject BOS token at position 0.</p> required <p>Returns:</p> Type Description <p>Generated token sequences of shape [num_samples, num_tokens].</p> Source code in <code>src/discrete_diffusion/sampling/gidd.py</code> <pre><code>@torch.no_grad()\ndef generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n  \"\"\"Generate samples using GIDD reverse diffusion process.\n\n  Args:\n    model: The GIDD model instance.\n    num_samples: Number of samples to generate.\n    num_steps: Number of denoising steps.\n    eps: Minimum timestep value (epsilon).\n    inject_bos: Whether to inject BOS token at position 0.\n\n  Returns:\n    Generated token sequences of shape [num_samples, num_tokens].\n  \"\"\"\n  if num_steps is None:\n    num_steps = self.config.sampling.steps\n  if eps is None:\n    eps = getattr(self.config.algo, 't_eps', 1e-4)\n\n  # Sample from the prior (fully masked)\n  z_t = model.hybrid_noise.sample_prior(\n    (num_samples, model.num_tokens))\n  if inject_bos:\n    z_t[:, 0] = model.tokenizer.bos_token_id\n\n  # Create timestep schedule from 1-eps to eps\n  timesteps = torch.linspace(\n    1 - eps, eps, num_steps + 1, device=model.device)\n\n  # Iteratively denoise\n  for i in range(num_steps):\n    t = timesteps[i] * torch.ones(\n      num_samples, device=model.device)\n    s = timesteps[i + 1] * torch.ones(\n      num_samples, device=model.device)\n\n    z_t = self.compute_posterior(model, z_t, t, s)\n\n  return z_t\n</code></pre>"},{"location":"reference/sampling/partition/","title":"Partition Sampling","text":""},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition","title":"<code>discrete_diffusion.sampling.partition</code>","text":"<p>Partition sampler for PartitionMDLM with multiple sampling modes.</p>"},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition.PartitionSampler","title":"<code>PartitionSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Sampler for PartitionMDLM with naive and efficient sampling modes.</p> <p>Supports: - 'naive': Standard DDPM updates with group_idxs tracking - 'efficient-uniform': Uniform token denoising schedule - 'efficient-non-uniform': Binomial token denoising schedule</p> Source code in <code>src/discrete_diffusion/sampling/partition.py</code> <pre><code>class PartitionSampler(Sampler):\n  \"\"\"Sampler for PartitionMDLM with naive and efficient sampling modes.\n\n  Supports:\n  - 'naive': Standard DDPM updates with group_idxs tracking\n  - 'efficient-uniform': Uniform token denoising schedule\n  - 'efficient-non-uniform': Binomial token denoising schedule\n  \"\"\"\n\n  def __init__(self, config, forward_process=None):\n    self.config = config\n\n  def compute_posterior(self, model, x, t, dt, p_x0=None, group_idxs=None,\n                        noise_removal_step=False):\n    \"\"\"Compute posterior with group_idxs support for partition tracking.\"\"\"\n    alpha_t = model.noise.alpha_t(t)\n    if noise_removal_step:\n      alpha_s = torch.ones_like(alpha_t)\n    else:\n      alpha_s = model.noise.alpha_t(t - dt)\n    assert alpha_t.ndim == 2\n    if p_x0 is None:\n      log_p_x0 = model.forward(\n        x,\n        model._sigma_from_alphat(alpha_t),\n        group_idxs=group_idxs)\n      if self.config.sampling.use_float64:\n        log_p_x0 = log_p_x0.to(torch.float64)\n      p_x0 = log_p_x0.exp()\n\n    sampled_x0 = sample_categorical(p_x0)\n    prob_denoise = (alpha_s - alpha_t) / (1 - alpha_t)\n    should_denoise_draw = torch.rand_like(x, dtype=torch.float64) &lt; prob_denoise\n    is_masked = (x == model.mask_id)\n    should_denoise_mask = is_masked &amp; should_denoise_draw\n    _x = torch.where(should_denoise_mask, sampled_x0, x)\n\n    if group_idxs is not None:\n      out = torch.where(group_idxs == 0, x, _x)\n      group_idxs = torch.where(out == x,\n                               group_idxs,\n                               torch.logical_not(group_idxs))\n      return p_x0, out, group_idxs\n    else:\n      out = torch.where(x != model.mask_id, x, _x)\n      return p_x0, out\n\n  def compute_posterior_efficient(self, model, x, t, dt, p_x0,\n                                  clean_positions, noisy_positions,\n                                  concrete_lengths):\n    \"\"\"Efficient posterior computation for position-based denoising.\"\"\"\n    alpha_t = model.noise.alpha_t(t)\n    assert alpha_t.ndim == 2\n    if p_x0 is None:\n      log_p_x0 = model.forward(\n        x,\n        model._sigma_from_alphat(alpha_t),\n        clean_positions=clean_positions,\n        noisy_positions=noisy_positions,\n        concrete_lengths=concrete_lengths,\n        use_inference_mode=True)\n      if self.config.sampling.use_float64:\n        log_p_x0 = log_p_x0.to(torch.float64)\n      p_x0 = log_p_x0.exp()\n\n    sampled_x0 = sample_categorical(p_x0)\n    return sampled_x0\n\n  @torch.no_grad()\n  def generate_naive(self, model, *, num_samples, num_steps, eps, inject_bos):\n    \"\"\"Naive generation with group tracking (standard DDPM).\"\"\"\n    if num_steps is None:\n      num_steps = self.config.sampling.steps\n    x = model.prior_sample(num_samples, model.num_tokens)\n    if inject_bos is None:\n      inject_bos = self.config.sampling.inject_bos\n    if not inject_bos:\n      raise ValueError(\"Partition MDLM requires inject_bos=True\")\n    x[:, 0] = model.tokenizer.bos_token_id\n\n    timesteps = torch.linspace(1, eps, num_steps + 1, device=model.device)\n    dt = (1 - eps) / num_steps\n    p_x0_cache = None\n    predictor = self.config.sampling.predictor\n\n    # Group 0: unmasked, group 1: masked\n    group_idxs = torch.ones_like(x, dtype=int)\n    group_idxs[:, 0] = 0\n\n    for i in range(num_steps):\n      t = timesteps[i] * torch.ones(x.shape[0], 1, device=model.device)\n      if predictor == 'ddpm':\n        _, x, group_idxs = self.compute_posterior(\n          model=model, x=x, t=t, dt=dt, p_x0=None, group_idxs=group_idxs)\n      elif predictor == 'ddpm_cache':\n        p_x0_cache, x_next, group_idxs = self.compute_posterior(\n          model=model, x=x, t=t, dt=dt, p_x0=p_x0_cache, \n          group_idxs=group_idxs)\n        if (not torch.allclose(x_next, x) or model.time_conditioning):\n          p_x0_cache = None\n        x = x_next\n      else:\n        raise ValueError(f'Unsupported predictor: {predictor}')\n\n    t0 = timesteps[-1] * torch.ones(x.shape[0], 1, device=model.device)\n    _, x, _ = self.compute_posterior(model=model, x=x, t=t0, dt=None,\n                                     p_x0=p_x0_cache,\n                                     noise_removal_step=True,\n                                     group_idxs=group_idxs)\n    return x\n\n  @torch.no_grad()\n  def generate_efficient_uniform(self, model, *, num_samples, num_steps, eps, inject_bos):\n    \"\"\"Efficient uniform generation (fixed tokens per step).\"\"\"\n    if num_steps is None:\n      num_steps = self.config.sampling.steps\n\n    if inject_bos is None:\n      inject_bos = self.config.sampling.inject_bos\n    if not inject_bos:\n      raise ValueError(\"Partition MDLM requires inject_bos=True\")\n\n    x = torch.full(size=(num_samples, 1), \n                   fill_value=model.tokenizer.bos_token_id, \n                   device=model.device)\n\n    timesteps = torch.linspace(1, eps, num_steps + 1, device=model.device)\n    dt = (1 - eps) / num_steps\n\n    clean_positions = torch.zeros(size=(num_samples, 1), \n                                  device=model.device, \n                                  dtype=torch.int64)\n    noisy_positions = torch.arange(start=1, \n                                   end=self.config.model.length, \n                                   device=model.device, \n                                   dtype=torch.int64)[None\n                                    ].repeat(num_samples, 1)\n    # Random permutation\n    rand = torch.rand_like(noisy_positions, dtype=torch.float32)\n    shuffled_indices = rand.argsort(dim=-1)\n    noisy_positions = torch.gather(noisy_positions, dim=-1, \n                                   index=shuffled_indices)\n    concrete_lengths = torch.ones(size=(num_samples,), \n                                  device=model.device, \n                                  dtype=torch.int64)\n\n    if self.config.model.length % num_steps != 0:\n      raise ValueError(f\"Length {self.config.model.length} must be divisible by steps {num_steps}\")\n\n    n_tok_per_normal_step = self.config.model.length // num_steps\n    all_n_tok_per_step = torch.full(size=(num_steps,), \n                                fill_value=n_tok_per_normal_step)\n    # Last step might need more tokens\n    all_n_tok_per_step[-1] += (self.config.model.length \n                           - num_steps * n_tok_per_normal_step)\n\n    for t, n_tok_per_step in zip(timesteps[:-1], all_n_tok_per_step):\n      t = t * torch.ones(x.shape[0], 1, device=model.device)\n      noisy_pos_input = noisy_positions[:, :n_tok_per_step]\n      denoised_token_values = self.compute_posterior_efficient(\n         model=model, x=x, t=t, dt=dt, p_x0=None, \n         clean_positions=clean_positions, \n         noisy_positions=noisy_pos_input, \n         concrete_lengths=concrete_lengths)\n      x = torch.cat([x, denoised_token_values], dim=1)\n      clean_positions = torch.cat([clean_positions, noisy_pos_input], dim=1)\n      noisy_positions = noisy_positions[:, n_tok_per_step:]\n      concrete_lengths += n_tok_per_step\n\n    # Reorder to original positions\n    out = torch.empty_like(x).scatter_(dim=-1, index=clean_positions, src=x)\n    return out\n\n  def _gen_eff_non_unif_post_process(self, x, concrete_lengths, \n    n_denoise_per_seq, denoised_token_values, clean_positions, \n    noisy_positions, noisy_pos_input):\n    \"\"\"Post-process for non-uniform efficient generation.\"\"\"\n    new_concrete_lengths = concrete_lengths + n_denoise_per_seq\n    n_tok_to_add = new_concrete_lengths.max() - x.shape[1]\n    if n_tok_to_add &gt; 0:\n      pad = torch.zeros(size=(x.shape[0], n_tok_to_add), \n                        dtype=x.dtype, device=x.device)\n      x = torch.cat([x, pad], dim=1)\n      clean_positions = torch.cat([clean_positions, pad], dim=1)\n\n    for i in range(x.shape[0]):\n      if n_denoise_per_seq[i] == 0:\n        continue\n      x[i, concrete_lengths[i]: new_concrete_lengths[i]] = \\\n            denoised_token_values[i, :n_denoise_per_seq[i]]\n      clean_positions[i, concrete_lengths[i]:new_concrete_lengths[i]] = \\\n            noisy_pos_input[i, :n_denoise_per_seq[i]]\n      noisy_positions[i, :noisy_positions.shape[1] - n_denoise_per_seq[i]] = \\\n        noisy_positions[i, n_denoise_per_seq[i]:].clone()\n\n    return x, clean_positions, new_concrete_lengths\n\n  @torch.no_grad()\n  def generate_efficient_non_uniform(self, model, *, num_samples, num_steps, eps, inject_bos):\n    \"\"\"Efficient non-uniform generation (binomial tokens per step).\"\"\"\n    if num_steps is None:\n      num_steps = self.config.sampling.steps\n\n    if inject_bos is None:\n      inject_bos = self.config.sampling.inject_bos\n    if not inject_bos:\n      raise ValueError(\"Partition MDLM requires inject_bos=True\")\n\n    x = torch.full(size=(num_samples, 1), \n                   fill_value=model.tokenizer.bos_token_id, \n                   device=model.device)\n\n    timesteps = torch.linspace(1, eps, num_steps + 1, device=model.device)\n    dt = (1 - eps) / num_steps\n\n    clean_positions = torch.zeros(size=(num_samples, 1), \n                                  device=model.device, \n                                  dtype=torch.int64)\n    noisy_positions = torch.arange(start=1, \n                                   end=self.config.model.length, \n                                   device=model.device, \n                                   dtype=torch.int64)[None\n                                    ].repeat(num_samples, 1)\n    # Random permutation\n    rand = torch.rand_like(noisy_positions, dtype=torch.float32)\n    shuffled_indices = rand.argsort(dim=-1)\n    noisy_positions = torch.gather(noisy_positions, dim=-1, \n                                   index=shuffled_indices)\n    concrete_lengths = torch.ones(size=(num_samples,), \n                                  device=model.device, \n                                  dtype=torch.int64)\n\n    alpha_t = model.noise.alpha_t(timesteps[0])\n    alpha_s = model.noise.alpha_t(timesteps[0] - dt)\n    prob_denoise = (alpha_s - alpha_t) / (1 - alpha_t)\n\n    for t in timesteps[:-1]:\n      t = t * torch.ones(x.shape[0], 1, device=model.device)\n      bin_count = torch.ones(size=(num_samples,), \n                             device=prob_denoise.device)\n      bin_count *= self.config.model.length\n      n_denoise_per_seq = torch.binomial(count=bin_count, \n                                         prob=prob_denoise).to(int)\n      n_denoise_per_seq = torch.min(n_denoise_per_seq, \n                self.config.model.length - concrete_lengths)\n      denoise_seq_len = torch.max(n_denoise_per_seq).item()\n      if denoise_seq_len == 0:\n        continue\n\n      noisy_pos_input = noisy_positions[:, :denoise_seq_len]\n      denoised_token_values = self.compute_posterior_efficient(\n         model=model, x=x, t=t, dt=dt, p_x0=None, \n         clean_positions=clean_positions, \n         noisy_positions=noisy_pos_input, \n         concrete_lengths=concrete_lengths)\n\n      (x, clean_positions, concrete_lengths) = \\\n        self._gen_eff_non_unif_post_process(x, concrete_lengths, \n        n_denoise_per_seq, denoised_token_values, clean_positions, \n        noisy_positions, noisy_pos_input)\n\n    # Final denoising of remaining masked tokens\n    if not torch.all(concrete_lengths == self.config.model.length):\n      n_denoise_per_seq = self.config.model.length - concrete_lengths\n      noisy_pos_input = noisy_positions[:, :self.config.model.length - concrete_lengths.min()]\n      denoised_token_values = self.compute_posterior_efficient(\n         model=model, x=x, t=t, dt=dt, p_x0=None, \n         clean_positions=clean_positions, \n         noisy_positions=noisy_pos_input, \n         concrete_lengths=concrete_lengths)\n      (x, clean_positions, concrete_lengths) = \\\n        self._gen_eff_non_unif_post_process(x, concrete_lengths, \n        n_denoise_per_seq, denoised_token_values, clean_positions, \n        noisy_positions, noisy_pos_input)\n\n    # Reorder to original positions\n    out = torch.empty_like(x).scatter_(dim=-1, index=clean_positions, src=x)\n    return out\n\n  @torch.no_grad()\n  def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n    \"\"\"Generate samples using configured sampling mode.\"\"\"\n    # Get sampling mode from model config\n    sampling_mode = getattr(model, 'sampling_mode', 'naive')\n\n    if sampling_mode == 'naive':\n      return self.generate_naive(\n        model, num_samples=num_samples, num_steps=num_steps, \n        eps=eps, inject_bos=inject_bos)\n    elif sampling_mode == 'efficient-uniform':\n      return self.generate_efficient_uniform(\n        model, num_samples=num_samples, num_steps=num_steps, \n        eps=eps, inject_bos=inject_bos)\n    elif sampling_mode == 'efficient-non-uniform':\n      return self.generate_efficient_non_uniform(\n        model, num_samples=num_samples, num_steps=num_steps, \n        eps=eps, inject_bos=inject_bos)\n    else:\n      raise ValueError(f'Unknown sampling mode: {sampling_mode}')\n</code></pre>"},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition.PartitionSampler.compute_posterior","title":"<code>compute_posterior(model, x, t, dt, p_x0=None, group_idxs=None, noise_removal_step=False)</code>","text":"<p>Compute posterior with group_idxs support for partition tracking.</p> Source code in <code>src/discrete_diffusion/sampling/partition.py</code> <pre><code>def compute_posterior(self, model, x, t, dt, p_x0=None, group_idxs=None,\n                      noise_removal_step=False):\n  \"\"\"Compute posterior with group_idxs support for partition tracking.\"\"\"\n  alpha_t = model.noise.alpha_t(t)\n  if noise_removal_step:\n    alpha_s = torch.ones_like(alpha_t)\n  else:\n    alpha_s = model.noise.alpha_t(t - dt)\n  assert alpha_t.ndim == 2\n  if p_x0 is None:\n    log_p_x0 = model.forward(\n      x,\n      model._sigma_from_alphat(alpha_t),\n      group_idxs=group_idxs)\n    if self.config.sampling.use_float64:\n      log_p_x0 = log_p_x0.to(torch.float64)\n    p_x0 = log_p_x0.exp()\n\n  sampled_x0 = sample_categorical(p_x0)\n  prob_denoise = (alpha_s - alpha_t) / (1 - alpha_t)\n  should_denoise_draw = torch.rand_like(x, dtype=torch.float64) &lt; prob_denoise\n  is_masked = (x == model.mask_id)\n  should_denoise_mask = is_masked &amp; should_denoise_draw\n  _x = torch.where(should_denoise_mask, sampled_x0, x)\n\n  if group_idxs is not None:\n    out = torch.where(group_idxs == 0, x, _x)\n    group_idxs = torch.where(out == x,\n                             group_idxs,\n                             torch.logical_not(group_idxs))\n    return p_x0, out, group_idxs\n  else:\n    out = torch.where(x != model.mask_id, x, _x)\n    return p_x0, out\n</code></pre>"},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition.PartitionSampler.compute_posterior_efficient","title":"<code>compute_posterior_efficient(model, x, t, dt, p_x0, clean_positions, noisy_positions, concrete_lengths)</code>","text":"<p>Efficient posterior computation for position-based denoising.</p> Source code in <code>src/discrete_diffusion/sampling/partition.py</code> <pre><code>def compute_posterior_efficient(self, model, x, t, dt, p_x0,\n                                clean_positions, noisy_positions,\n                                concrete_lengths):\n  \"\"\"Efficient posterior computation for position-based denoising.\"\"\"\n  alpha_t = model.noise.alpha_t(t)\n  assert alpha_t.ndim == 2\n  if p_x0 is None:\n    log_p_x0 = model.forward(\n      x,\n      model._sigma_from_alphat(alpha_t),\n      clean_positions=clean_positions,\n      noisy_positions=noisy_positions,\n      concrete_lengths=concrete_lengths,\n      use_inference_mode=True)\n    if self.config.sampling.use_float64:\n      log_p_x0 = log_p_x0.to(torch.float64)\n    p_x0 = log_p_x0.exp()\n\n  sampled_x0 = sample_categorical(p_x0)\n  return sampled_x0\n</code></pre>"},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition.PartitionSampler.generate","title":"<code>generate(model, *, num_samples, num_steps, eps, inject_bos)</code>","text":"<p>Generate samples using configured sampling mode.</p> Source code in <code>src/discrete_diffusion/sampling/partition.py</code> <pre><code>@torch.no_grad()\ndef generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n  \"\"\"Generate samples using configured sampling mode.\"\"\"\n  # Get sampling mode from model config\n  sampling_mode = getattr(model, 'sampling_mode', 'naive')\n\n  if sampling_mode == 'naive':\n    return self.generate_naive(\n      model, num_samples=num_samples, num_steps=num_steps, \n      eps=eps, inject_bos=inject_bos)\n  elif sampling_mode == 'efficient-uniform':\n    return self.generate_efficient_uniform(\n      model, num_samples=num_samples, num_steps=num_steps, \n      eps=eps, inject_bos=inject_bos)\n  elif sampling_mode == 'efficient-non-uniform':\n    return self.generate_efficient_non_uniform(\n      model, num_samples=num_samples, num_steps=num_steps, \n      eps=eps, inject_bos=inject_bos)\n  else:\n    raise ValueError(f'Unknown sampling mode: {sampling_mode}')\n</code></pre>"},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition.PartitionSampler.generate_efficient_non_uniform","title":"<code>generate_efficient_non_uniform(model, *, num_samples, num_steps, eps, inject_bos)</code>","text":"<p>Efficient non-uniform generation (binomial tokens per step).</p> Source code in <code>src/discrete_diffusion/sampling/partition.py</code> <pre><code>@torch.no_grad()\ndef generate_efficient_non_uniform(self, model, *, num_samples, num_steps, eps, inject_bos):\n  \"\"\"Efficient non-uniform generation (binomial tokens per step).\"\"\"\n  if num_steps is None:\n    num_steps = self.config.sampling.steps\n\n  if inject_bos is None:\n    inject_bos = self.config.sampling.inject_bos\n  if not inject_bos:\n    raise ValueError(\"Partition MDLM requires inject_bos=True\")\n\n  x = torch.full(size=(num_samples, 1), \n                 fill_value=model.tokenizer.bos_token_id, \n                 device=model.device)\n\n  timesteps = torch.linspace(1, eps, num_steps + 1, device=model.device)\n  dt = (1 - eps) / num_steps\n\n  clean_positions = torch.zeros(size=(num_samples, 1), \n                                device=model.device, \n                                dtype=torch.int64)\n  noisy_positions = torch.arange(start=1, \n                                 end=self.config.model.length, \n                                 device=model.device, \n                                 dtype=torch.int64)[None\n                                  ].repeat(num_samples, 1)\n  # Random permutation\n  rand = torch.rand_like(noisy_positions, dtype=torch.float32)\n  shuffled_indices = rand.argsort(dim=-1)\n  noisy_positions = torch.gather(noisy_positions, dim=-1, \n                                 index=shuffled_indices)\n  concrete_lengths = torch.ones(size=(num_samples,), \n                                device=model.device, \n                                dtype=torch.int64)\n\n  alpha_t = model.noise.alpha_t(timesteps[0])\n  alpha_s = model.noise.alpha_t(timesteps[0] - dt)\n  prob_denoise = (alpha_s - alpha_t) / (1 - alpha_t)\n\n  for t in timesteps[:-1]:\n    t = t * torch.ones(x.shape[0], 1, device=model.device)\n    bin_count = torch.ones(size=(num_samples,), \n                           device=prob_denoise.device)\n    bin_count *= self.config.model.length\n    n_denoise_per_seq = torch.binomial(count=bin_count, \n                                       prob=prob_denoise).to(int)\n    n_denoise_per_seq = torch.min(n_denoise_per_seq, \n              self.config.model.length - concrete_lengths)\n    denoise_seq_len = torch.max(n_denoise_per_seq).item()\n    if denoise_seq_len == 0:\n      continue\n\n    noisy_pos_input = noisy_positions[:, :denoise_seq_len]\n    denoised_token_values = self.compute_posterior_efficient(\n       model=model, x=x, t=t, dt=dt, p_x0=None, \n       clean_positions=clean_positions, \n       noisy_positions=noisy_pos_input, \n       concrete_lengths=concrete_lengths)\n\n    (x, clean_positions, concrete_lengths) = \\\n      self._gen_eff_non_unif_post_process(x, concrete_lengths, \n      n_denoise_per_seq, denoised_token_values, clean_positions, \n      noisy_positions, noisy_pos_input)\n\n  # Final denoising of remaining masked tokens\n  if not torch.all(concrete_lengths == self.config.model.length):\n    n_denoise_per_seq = self.config.model.length - concrete_lengths\n    noisy_pos_input = noisy_positions[:, :self.config.model.length - concrete_lengths.min()]\n    denoised_token_values = self.compute_posterior_efficient(\n       model=model, x=x, t=t, dt=dt, p_x0=None, \n       clean_positions=clean_positions, \n       noisy_positions=noisy_pos_input, \n       concrete_lengths=concrete_lengths)\n    (x, clean_positions, concrete_lengths) = \\\n      self._gen_eff_non_unif_post_process(x, concrete_lengths, \n      n_denoise_per_seq, denoised_token_values, clean_positions, \n      noisy_positions, noisy_pos_input)\n\n  # Reorder to original positions\n  out = torch.empty_like(x).scatter_(dim=-1, index=clean_positions, src=x)\n  return out\n</code></pre>"},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition.PartitionSampler.generate_efficient_uniform","title":"<code>generate_efficient_uniform(model, *, num_samples, num_steps, eps, inject_bos)</code>","text":"<p>Efficient uniform generation (fixed tokens per step).</p> Source code in <code>src/discrete_diffusion/sampling/partition.py</code> <pre><code>@torch.no_grad()\ndef generate_efficient_uniform(self, model, *, num_samples, num_steps, eps, inject_bos):\n  \"\"\"Efficient uniform generation (fixed tokens per step).\"\"\"\n  if num_steps is None:\n    num_steps = self.config.sampling.steps\n\n  if inject_bos is None:\n    inject_bos = self.config.sampling.inject_bos\n  if not inject_bos:\n    raise ValueError(\"Partition MDLM requires inject_bos=True\")\n\n  x = torch.full(size=(num_samples, 1), \n                 fill_value=model.tokenizer.bos_token_id, \n                 device=model.device)\n\n  timesteps = torch.linspace(1, eps, num_steps + 1, device=model.device)\n  dt = (1 - eps) / num_steps\n\n  clean_positions = torch.zeros(size=(num_samples, 1), \n                                device=model.device, \n                                dtype=torch.int64)\n  noisy_positions = torch.arange(start=1, \n                                 end=self.config.model.length, \n                                 device=model.device, \n                                 dtype=torch.int64)[None\n                                  ].repeat(num_samples, 1)\n  # Random permutation\n  rand = torch.rand_like(noisy_positions, dtype=torch.float32)\n  shuffled_indices = rand.argsort(dim=-1)\n  noisy_positions = torch.gather(noisy_positions, dim=-1, \n                                 index=shuffled_indices)\n  concrete_lengths = torch.ones(size=(num_samples,), \n                                device=model.device, \n                                dtype=torch.int64)\n\n  if self.config.model.length % num_steps != 0:\n    raise ValueError(f\"Length {self.config.model.length} must be divisible by steps {num_steps}\")\n\n  n_tok_per_normal_step = self.config.model.length // num_steps\n  all_n_tok_per_step = torch.full(size=(num_steps,), \n                              fill_value=n_tok_per_normal_step)\n  # Last step might need more tokens\n  all_n_tok_per_step[-1] += (self.config.model.length \n                         - num_steps * n_tok_per_normal_step)\n\n  for t, n_tok_per_step in zip(timesteps[:-1], all_n_tok_per_step):\n    t = t * torch.ones(x.shape[0], 1, device=model.device)\n    noisy_pos_input = noisy_positions[:, :n_tok_per_step]\n    denoised_token_values = self.compute_posterior_efficient(\n       model=model, x=x, t=t, dt=dt, p_x0=None, \n       clean_positions=clean_positions, \n       noisy_positions=noisy_pos_input, \n       concrete_lengths=concrete_lengths)\n    x = torch.cat([x, denoised_token_values], dim=1)\n    clean_positions = torch.cat([clean_positions, noisy_pos_input], dim=1)\n    noisy_positions = noisy_positions[:, n_tok_per_step:]\n    concrete_lengths += n_tok_per_step\n\n  # Reorder to original positions\n  out = torch.empty_like(x).scatter_(dim=-1, index=clean_positions, src=x)\n  return out\n</code></pre>"},{"location":"reference/sampling/partition/#discrete_diffusion.sampling.partition.PartitionSampler.generate_naive","title":"<code>generate_naive(model, *, num_samples, num_steps, eps, inject_bos)</code>","text":"<p>Naive generation with group tracking (standard DDPM).</p> Source code in <code>src/discrete_diffusion/sampling/partition.py</code> <pre><code>@torch.no_grad()\ndef generate_naive(self, model, *, num_samples, num_steps, eps, inject_bos):\n  \"\"\"Naive generation with group tracking (standard DDPM).\"\"\"\n  if num_steps is None:\n    num_steps = self.config.sampling.steps\n  x = model.prior_sample(num_samples, model.num_tokens)\n  if inject_bos is None:\n    inject_bos = self.config.sampling.inject_bos\n  if not inject_bos:\n    raise ValueError(\"Partition MDLM requires inject_bos=True\")\n  x[:, 0] = model.tokenizer.bos_token_id\n\n  timesteps = torch.linspace(1, eps, num_steps + 1, device=model.device)\n  dt = (1 - eps) / num_steps\n  p_x0_cache = None\n  predictor = self.config.sampling.predictor\n\n  # Group 0: unmasked, group 1: masked\n  group_idxs = torch.ones_like(x, dtype=int)\n  group_idxs[:, 0] = 0\n\n  for i in range(num_steps):\n    t = timesteps[i] * torch.ones(x.shape[0], 1, device=model.device)\n    if predictor == 'ddpm':\n      _, x, group_idxs = self.compute_posterior(\n        model=model, x=x, t=t, dt=dt, p_x0=None, group_idxs=group_idxs)\n    elif predictor == 'ddpm_cache':\n      p_x0_cache, x_next, group_idxs = self.compute_posterior(\n        model=model, x=x, t=t, dt=dt, p_x0=p_x0_cache, \n        group_idxs=group_idxs)\n      if (not torch.allclose(x_next, x) or model.time_conditioning):\n        p_x0_cache = None\n      x = x_next\n    else:\n      raise ValueError(f'Unsupported predictor: {predictor}')\n\n  t0 = timesteps[-1] * torch.ones(x.shape[0], 1, device=model.device)\n  _, x, _ = self.compute_posterior(model=model, x=x, t=t0, dt=None,\n                                   p_x0=p_x0_cache,\n                                   noise_removal_step=True,\n                                   group_idxs=group_idxs)\n  return x\n</code></pre>"},{"location":"reference/sampling/uniform/","title":"Uniform Sampling","text":""},{"location":"reference/sampling/uniform/#discrete_diffusion.sampling.uniform","title":"<code>discrete_diffusion.sampling.uniform</code>","text":"<p>Uniform (UDLM) sampler abstraction.</p>"},{"location":"reference/sampling/uniform/#discrete_diffusion.sampling.uniform.UniformSampler","title":"<code>UniformSampler</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Sampler whose updates mirror UDLM's uniform transition.</p> Source code in <code>src/discrete_diffusion/sampling/uniform.py</code> <pre><code>class UniformSampler(Sampler):\n  \"\"\"Sampler whose updates mirror UDLM's uniform transition.\"\"\"\n\n  def __init__(self, config, forward_process=None):\n    self.config = config\n\n  def compute_posterior(self, model, x, t, dt, p_x0=None,\n                        noise_removal_step=False):\n    alpha_t = model.noise.alpha_t(t)\n    if noise_removal_step:\n      alpha_s = torch.ones_like(alpha_t)\n    else:\n      alpha_s = model.noise.alpha_t(t - dt)\n    if p_x0 is None:\n      sigma_t = model._sigma_from_alphat(alpha_t)\n      log_p_x0 = model.forward(xt=x, sigma=sigma_t)\n      if self.config.sampling.use_float64:\n        log_p_x0 = log_p_x0.to(torch.float64)\n      p_x0 = log_p_x0.exp()\n\n    V = model.vocab_size\n    alpha_t3 = alpha_t[..., None]\n    alpha_s3 = alpha_s[..., None]\n    alpha_ts = alpha_t3 / alpha_s3\n    xt_one_hot = F.one_hot(x, V)\n    limiting = model.limiting_distribution.view(1, 1, -1)\n\n    numerator = (\n      (alpha_t3 * V * p_x0 * xt_one_hot)\n      + ((alpha_ts - alpha_t3) * xt_one_hot)\n      + ((alpha_s3 - alpha_t3) * p_x0)\n      + ((1 - alpha_ts) * (1 - alpha_s3) * limiting)\n    )\n    denom = (\n      (alpha_t3 * V * torch.gather(p_x0, -1, x[..., None]))\n      + (1 - alpha_t3)\n    )\n    q_xs = numerator / denom\n\n    xs = sample_categorical(q_xs)\n    return p_x0, xs\n\n  @torch.no_grad()\n  def generate(self, model, *, num_samples, num_steps, eps, inject_bos):\n    if num_steps is None:\n      num_steps = self.config.sampling.steps\n    x = model.prior_sample(num_samples, model.num_tokens)\n    if inject_bos is None:\n      inject_bos = self.config.sampling.inject_bos\n    if inject_bos:\n      x[:, 0] = model.tokenizer.bos_token_id\n\n    timesteps = torch.linspace(\n      1, eps, num_steps + 1, device=model.device)\n    dt = (1 - eps) / num_steps\n    p_x0_cache = None\n    predictor = self.config.sampling.predictor\n\n    for i in range(num_steps):\n      t = timesteps[i] * torch.ones(\n        x.shape[0], 1, device=model.device)\n      if predictor == 'ddpm':\n        _, x = self.compute_posterior(\n          model=model, x=x, t=t, dt=dt, p_x0=None)\n      elif predictor == 'ddpm_cache':\n        p_x0_cache, x_next = self.compute_posterior(\n          model=model, x=x, t=t, dt=dt, p_x0=p_x0_cache)\n        if (not torch.allclose(x_next, x)\n            or model.time_conditioning):\n          p_x0_cache = None\n        x = x_next\n      else:\n        raise ValueError(\n          f'Uniform sampler only supports ddpm predictors, got {predictor}')\n\n    t0 = timesteps[-1] * torch.ones(x.shape[0], 1,\n                                    device=model.device)\n    _, x = self.compute_posterior(\n      model=model, x=x, t=t0, dt=None, p_x0=p_x0_cache,\n      noise_removal_step=True)\n    return x\n</code></pre>"}]}